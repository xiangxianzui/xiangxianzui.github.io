[{"title":"elastic-job分片策略","url":"/2019/12/elastic-job%E5%88%86%E7%89%87%E7%AD%96%E7%95%A5/","content":"<h2 id=\"elastic-job分片策略\"><a href=\"#elastic-job分片策略\" class=\"headerlink\" title=\"elastic-job分片策略\"></a>elastic-job分片策略</h2><p>elastic-job在选举出主节点后，会由这个主节点进行作业分片，也就是要把每个作业的每个分片按照某种策略分配到各个作业执行节点上去。elastic-job默认提供了三种分片策略：</p>\n<ul>\n<li>AverageAllocationJobShardingStrategy：基于平均分配算法的分片策略</li>\n<li>OdevitySortByNameJobShardingStrategy：根据作业名的哈希值奇偶数决定IP升降序算法的分片策略</li>\n<li>RotateServerByNameJobShardingStrategy：根据作业名的哈希值对服务器列表进行轮转的分片策略</li>\n</ul>\n<p>可以通过在配置作业的时候指定<code>job-sharding-strategy-class</code>来选择分片策略。</p>\n<p>对于只有一个分片的作业，或者分片数小于作业执行节点数的作业，以上三种分片策略都会把分片分配到某一台或几台节点上去，会有固定的几台节点完全得不到分片，而elastic-job只有在节点变动（如加机器、节点崩溃退出）的时候才会重新分片，这就意味着如果初始分片不均匀的话，整个系统负载不均衡的情况就会一直存在。</p>\n<p>为了解决这个问题，我设计了一个基于一致性哈希算法的分片策略<code>ConsistentHashJobShardingStrategy</code>。先将执行实例均匀地分布到给定区间，然后将作业分片映射到同一区间，根据落在区间中的位置来决定分配到哪个执行实例。</p>\n<p>下面举例说明：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">假设作业执行实例个数为3，作业分片数为2</div><div class=\"line\">* 首先将3个实例哈希到[0,N-1]，设定N=100，则分别映射到0、33、66</div><div class=\"line\">* 再计算2个作业分片的哈希值，如果在[0,32]之间则分配给实例1，[33,65]之间分配给实例2，[66,99]之间分配给实例3</div></pre></td></tr></table></figure>\n<p>这样可以尽量避免不同的作业映射到同一个执行实例上而导致实例间负载不均。</p>\n<p>具体代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ConsistentHashJobShardingStrategy</span> <span class=\"keyword\">implements</span> <span class=\"title\">JobShardingStrategy</span> </span>&#123;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">/**</span></div><div class=\"line\">     * 允许的最多执行实例的个数</div><div class=\"line\">     */</div><div class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> N = <span class=\"number\">100</span>;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"meta\">@Override</span></div><div class=\"line\">    <span class=\"keyword\">public</span> Map&lt;JobInstance, List&lt;Integer&gt;&gt; sharding(<span class=\"keyword\">final</span> List&lt;JobInstance&gt; jobInstances, <span class=\"keyword\">final</span> String jobName, <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> shardingTotalCount) &#123;</div><div class=\"line\">        <span class=\"keyword\">if</span> (jobInstances.isEmpty()) &#123;</div><div class=\"line\">            <span class=\"keyword\">return</span> Collections.emptyMap();</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">int</span> instanceNum = jobInstances.size();</div><div class=\"line\">        <span class=\"keyword\">if</span> (instanceNum &gt; N) &#123;</div><div class=\"line\">            <span class=\"comment\">// should not reach here</span></div><div class=\"line\">            <span class=\"keyword\">return</span> Collections.emptyMap();</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">int</span> gap = N / instanceNum;</div><div class=\"line\"><span class=\"comment\">//        int pos = 0;</span></div><div class=\"line\"><span class=\"comment\">//        Map&lt;JobInstance, Integer&gt; instanceMap = new LinkedHashMap&lt;&gt;(instanceNum, 1);</span></div><div class=\"line\"><span class=\"comment\">//        for (JobInstance jobInstance : jobInstances) &#123;</span></div><div class=\"line\"><span class=\"comment\">//            instanceMap.put(jobInstance, pos);</span></div><div class=\"line\"><span class=\"comment\">//            pos += gap;</span></div><div class=\"line\"><span class=\"comment\">//        &#125;</span></div><div class=\"line\"></div><div class=\"line\">        Map&lt;JobInstance, List&lt;Integer&gt;&gt; resultMap = <span class=\"keyword\">new</span> LinkedHashMap&lt;&gt;();</div><div class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> shardIdx = <span class=\"number\">0</span>; shardIdx &lt; shardingTotalCount; shardIdx++) &#123;</div><div class=\"line\">            <span class=\"keyword\">int</span> shardHash = hash(jobName, shardIdx);</div><div class=\"line\">            <span class=\"keyword\">int</span> select = shardHash / gap;</div><div class=\"line\">            <span class=\"keyword\">if</span> (shardHash == N - <span class=\"number\">1</span>) &#123;</div><div class=\"line\">                select = select - <span class=\"number\">1</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">            JobInstance selectJobInstance = jobInstances.get(select);</div><div class=\"line\">            <span class=\"keyword\">if</span> (resultMap.containsKey(selectJobInstance)) &#123;</div><div class=\"line\">                resultMap.get(selectJobInstance).add(shardIdx);</div><div class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">                List&lt;Integer&gt; shardList = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</div><div class=\"line\">                shardList.add(shardIdx);</div><div class=\"line\">                resultMap.put(selectJobInstance, shardList);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> resultMap;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">/**</span></div><div class=\"line\">     * <span class=\"doctag\">@param</span> jobName 作业名</div><div class=\"line\">     * <span class=\"doctag\">@param</span> shardIdx 分片索引</div><div class=\"line\">     * <span class=\"doctag\">@return</span> 计算作业分片的hash值，范围[0,N-1]</div><div class=\"line\">     */</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">int</span> <span class=\"title\">hash</span><span class=\"params\">(<span class=\"keyword\">final</span> String jobName, <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> shardIdx)</span> </span>&#123;</div><div class=\"line\">        String shardJobName = jobName + shardIdx;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">int</span> hash = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; shardJobName.length(); i++) &#123;</div><div class=\"line\">            hash += Math.abs(shardJobName.charAt(i) - <span class=\"string\">'0'</span>);</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> hash % N;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>","categories":["Work"],"tags":["分布式","作业调度","elastic-job"]},{"title":"ssh认证原理","url":"/2019/10/ssh%E8%AE%A4%E8%AF%81%E5%8E%9F%E7%90%86/","content":"<h2 id=\"ssh认证原理\"><a href=\"#ssh认证原理\" class=\"headerlink\" title=\"ssh认证原理\"></a>ssh认证原理</h2><p>通过ssh从客户端登入服务端需要身份认证，ssh主要提供了密码认证和公钥认证两种方式。</p>\n<p>下图是PAC的ssh连接管理界面，可以看Authentication一栏下的User/Password和Private Key，前者就是密码认证，后者其实就是公钥认证，只不过需要告诉PAC在哪里可以找到私钥。</p>\n<p><img src=\"PAC.png\" alt=\"PAC连接管理界面\"></p>\n<h3 id=\"密码认证\"><a href=\"#密码认证\" class=\"headerlink\" title=\"密码认证\"></a>密码认证</h3><p>密码认证需要ssh client携带用户名和密码传递给ssh server，server端需要配置<code>PasswordAuthentication</code>为<code>yes</code>，否则不允许通过密码认证登录服务器。</p>\n<p>生产环境下建议关闭密码认证：</p>\n<ol>\n<li>虽然用户名和密码都被<code>session key</code>加密后再传输给server端，但是依然有被暴力破解的风险；</li>\n<li>如果集群中所有机器都使用相同的密码，那么一台机器被破解整个集群将被全部破解；</li>\n<li>如果不同机器使用不同的密码，那么给维护带来困难，客户端需要记住不同机器的密码，这也势必导致设置的密码十分简单，增大了被破解的风险。</li>\n</ol>\n<p>登录命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># -l 指定用户名</span></div><div class=\"line\"><span class=\"comment\"># -p 指定端口</span></div><div class=\"line\"><span class=\"comment\"># 输入下面的命令后根据提示输入密码就可以登录到对应的服务器了</span></div><div class=\"line\">ssh <span class=\"_\">-l</span> username -p 22 0.0.0.0</div></pre></td></tr></table></figure>\n<p>关于<code>session key</code> :</p>\n<blockquote>\n<p>Session keys are the “shared keys” described above and are randomly generated by both the client and the server during establishment of a connection. Both the client and host use the same session key to encrypt and decrypt data although a different key is used for the send and receive channels. Session keys are generated after host authentication is successfully performed but before user authentication so that usernames and passwords can be sent encrypted. These keys may be replaced at regular intervals (e.g., every one to two hours) during the session and are destroyed at its conclusion.</p>\n</blockquote>\n<h3 id=\"公钥认证\"><a href=\"#公钥认证\" class=\"headerlink\" title=\"公钥认证\"></a>公钥认证</h3><p>相比于密码认证需要用户名和密码，公钥认证是通过公私密钥对来认证身份的。</p>\n<p>现在你想在本地登录目标机器，首先需要在本地生成公私秘钥对（下图是GitHub上关于生成秘钥对的教程）</p>\n<p><img src=\"生成密钥对.png\" alt=\"GitHub生成密钥对教程\"></p>\n<p>可以看到第4步需要输入passphrase，这个passphrase是私钥的密码，也可以不设置，但是最好设置，因为一旦私钥泄露，或者别人使用你的私人电脑，别人就能登录使用你的私钥登录远程服务器了。</p>\n<p>本地生成公私秘钥对后，需要把公钥添加到目标服务器对应用户的<code>.ssh</code>目录下的<code>authorized_keys</code>文件中，然后在ssh登录过程中，客户端携带被passphrase解密过的私钥以及用户名向目标服务器发起认证请求，目标服务器的ssh daemon进程检查<code>authorized_keys</code>中的Public Key尝试与私钥匹配，如果任一匹配成功则认证通过，如果全部匹配失败则认证不通过。</p>\n<p>公钥认证比密码认证更加安全，只有当passphrase和私钥同时泄露时才会被盗用登录，而且二者同时泄露的可能性是很低的；另外，集群中的不同服务器可以使用相同的公私密钥对，所以只需设置一个passphrase即可，你尽可以设置一个强度高的passphrase。公钥认证的缺点是每次登录的时候都需要输入passphrase，比较麻烦，于是就有了下面的ssh agent。</p>\n<h4 id=\"使用ssh-agent的公钥认证\"><a href=\"#使用ssh-agent的公钥认证\" class=\"headerlink\" title=\"使用ssh agent的公钥认证\"></a>使用ssh agent的公钥认证</h4><p>“懒是人类社会发展的第一生产力”，此言不虚。为了避免每次登录的时候输入passphrase，ssh agent应运而生。agent是一个独立的进程，可以通过<code>ssh-add</code>命令将私钥交给agent保管，同时将passphrase告诉agent，那么agent就会把解密后的私钥放到内存里，下次登录时ssh client会向agent索要私钥，然后带着私钥向目标服务器发送登录请求，这样就省去了输入passphrase的麻烦。</p>\n<h4 id=\"使用ssh-agent-forwarding的公钥认证\"><a href=\"#使用ssh-agent-forwarding的公钥认证\" class=\"headerlink\" title=\"使用ssh agent forwarding的公钥认证\"></a>使用ssh agent forwarding的公钥认证</h4><p>如果你想从本地PC登录到服务器A，利用上面的公钥认证就能解决。但如果你还想从服务器A登录到服务器B，你需要在A生成公私密钥对，把公钥添加到B的<code>authorized_keys</code>文件中，然后在服务器A上<code>ssh-add</code>将私钥交给ssh agent保管，这样太麻烦了，有没有简单点的方式？</p>\n<p>于是就有了ssh agent forwarding</p>\n<p>首先通过本地PC登录到服务器A，接着在服务器A ssh登录服务器B，正常流程是A的ssh client向A的agent索要私钥，但是A并没有本地PC的私钥，于是A的sshd进程将请求转发给本地PC的agent，本地PC的agent将私钥作为响应传递给A，接下来A就拿着本地PC的私钥向服务器B发送ssh登录请求，B检查其<code>authorized_keys</code>中的公钥看是否能够与私钥匹配。这样就实现了在服务器A免密登录服务器B。</p>\n<p>forwarding可以通过设置<code>ForwardAgent</code>为<code>yes</code>来开启，默认关闭。</p>\n<blockquote>\n<p>参考：</p>\n<p><a href=\"https://blog.csdn.net/mr_raptor/article/details/51779339\" target=\"_blank\" rel=\"external\">https://blog.csdn.net/mr_raptor/article/details/51779339</a></p>\n<p><a href=\"https://www.vandyke.com/solutions/ssh_overview/index.html\" target=\"_blank\" rel=\"external\">https://www.vandyke.com/solutions/ssh_overview/index.html</a></p>\n<p><a href=\"http://www.unixwiz.net/techtips/ssh-agent-forwarding.html\" target=\"_blank\" rel=\"external\">http://www.unixwiz.net/techtips/ssh-agent-forwarding.html</a></p>\n</blockquote>\n","categories":["Work"],"tags":["ssh"]},{"title":"elastic-job事件追踪改造","url":"/2019/08/elastic-job%E4%BA%8B%E4%BB%B6%E8%BF%BD%E8%B8%AA%E6%94%B9%E9%80%A0/","content":"<p>在整个作业执行的过程中，elastic-job对作业的状态、执行情况做了事件追踪，用于查询、统计和监控。事件总线JobEventBus中注册了两种事件，分别是JobStatusTraceEvent和JobExecutionEvent，分别对应作业状态和触发来源。elastic-job会在作业执行过程中向事件总线实时发送事件追踪信息，JobEventBus接收追踪信息后会写入DB。</p>\n<p><img src=\"事件追踪.png\" alt=\"事件追踪\"></p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>JobStatusTraceEvent和JobExecutionEvent分别对应mysql中的两张表，可能会带来一些问题：</p>\n<ul>\n<li>每个作业执行到不同阶段都会将追踪事件写入db，而elastic-job并没有提供定期清理功能，除非手动删除，否则两张表将会慢慢地变得非常庞大。</li>\n<li>事件追踪表对业务有一定程度的入侵。如果事件追踪表与业务表使用不同的数据源，那么在业务代码里就要为事件追踪单独配置一个数据源；而跟业务使用同一个数据源显然是不合理的。</li>\n<li>elastic-job每接入一个业务工程，都要配置一个数据源，接入麻烦，而且不易于管理。</li>\n</ul>\n<h3 id=\"改造\"><a href=\"#改造\" class=\"headerlink\" title=\"改造\"></a>改造</h3><p>针对上面的问题，改造思路主要是不要写db，而是写日志文件，将日志文件传输到ELK，进行统一的查询和问题排查。</p>\n<p>在elastic-job-lite-2.1.5版本中，做如下修改：</p>\n<p>在elastic-job-common中的elastic-job-common-core模块中，在com.dangdang.ddframe.job.event下创建log目录，新建下面三个文件：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* JobEventLogConfiguration.java */</span></div><div class=\"line\"><span class=\"meta\">@RequiredArgsConstructor</span></div><div class=\"line\"><span class=\"meta\">@Getter</span></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JobEventLogConfiguration</span> <span class=\"keyword\">extends</span> <span class=\"title\">JobEventLogIdentity</span> <span class=\"keyword\">implements</span> <span class=\"title\">JobEventConfiguration</span>, <span class=\"title\">Serializable</span> </span>&#123;</div><div class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> serialVersionUID = <span class=\"number\">7770747203483712815L</span>;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"meta\">@Override</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> JobEventListener <span class=\"title\">createJobEventListener</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> JobEventListenerConfigurationException </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> JobEventLogListener();</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/* JobEventLogListener.java */</span></div><div class=\"line\"><span class=\"meta\">@Slf</span>4j(topic = <span class=\"string\">\"ElasticJobEventTrace\"</span>)</div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JobEventLogListener</span> <span class=\"keyword\">extends</span> <span class=\"title\">JobEventLogIdentity</span> <span class=\"keyword\">implements</span> <span class=\"title\">JobEventListener</span> </span>&#123;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">JobEventLogListener</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"meta\">@Override</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">listen</span><span class=\"params\">(JobExecutionEvent jobExecutionEvent)</span> </span>&#123;</div><div class=\"line\">        log.info(<span class=\"string\">\"[JobExecutionEvent] &#123;&#125;\"</span>, JSON.toJSONString(jobExecutionEvent));</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"meta\">@Override</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">listen</span><span class=\"params\">(JobStatusTraceEvent jobStatusTraceEvent)</span> </span>&#123;</div><div class=\"line\">        log.info(<span class=\"string\">\"[JobStatusTraceEvent] &#123;&#125;\"</span>, JSON.toJSONString(jobStatusTraceEvent));</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/* JobEventLogIdentity.java */</span></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JobEventLogIdentity</span> <span class=\"keyword\">implements</span> <span class=\"title\">JobEventIdentity</span> </span>&#123;</div><div class=\"line\">    <span class=\"meta\">@Override</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getIdentity</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"log\"</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>JobEventLogListener监听JobEventBus上的发布事件，当有新的追踪事件发布时，就会打印日志。</p>\n<p>那么如何将默认的写db换成写日志呢？</p>\n<p>首先在job.xsd中添加一个<code>use-log-for-event-trace</code>标签，默认为false</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">&lt;xsd:attribute name=&quot;use-log-for-event-trace&quot; type=&quot;xsd:string&quot; default=&quot;false&quot;/&gt;</div></pre></td></tr></table></figure>\n<p>然后在BaseJobBeanDefinitionParserTag.java中记录这个标签的key</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">public static final String USE_LOG_FOR_EVENT_TRACE_ATTRIBUTE = &quot;use-log-for-event-trace&quot;;</div></pre></td></tr></table></figure>\n<p>AbstractJobBeanDefinitionParser.java负责解析elastic-job的配置文件，生成相应的bean，其中createJobEventConfig方法就是生成事件追踪配置bean的，将此方法修改成下面这样：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> BeanDefinition <span class=\"title\">createJobEventConfig</span><span class=\"params\">(<span class=\"keyword\">final</span> Element element)</span> </span>&#123;</div><div class=\"line\">        String eventTraceDataSourceName = element.getAttribute(EVENT_TRACE_RDB_DATA_SOURCE_ATTRIBUTE);</div><div class=\"line\">        <span class=\"keyword\">if</span> (!Strings.isNullOrEmpty(eventTraceDataSourceName)) &#123;</div><div class=\"line\">            BeanDefinitionBuilder factory = BeanDefinitionBuilder.rootBeanDefinition(JobEventRdbConfiguration.class);</div><div class=\"line\">            factory.addConstructorArgReference(eventTraceDataSourceName);</div><div class=\"line\">            <span class=\"keyword\">return</span> factory.getBeanDefinition();</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        String useLogForEventTrace = element.getAttribute(USE_LOG_FOR_EVENT_TRACE_ATTRIBUTE);</div><div class=\"line\">        <span class=\"keyword\">if</span> (!Strings.isNullOrEmpty(useLogForEventTrace) &amp;&amp; <span class=\"string\">\"true\"</span>.equals(useLogForEventTrace)) &#123;</div><div class=\"line\">            BeanDefinitionBuilder factory = BeanDefinitionBuilder.rootBeanDefinition(JobEventLogConfiguration.class);</div><div class=\"line\">            <span class=\"keyword\">return</span> factory.getBeanDefinition();</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<p>意思就是先检查作业配置，看有没有配置<code>event-trace-rdb-data-source</code>，如果有，就按照原有的写db的方式记录追踪事件，如果没有，再看有没有配置<code>use-log-for-event-trace</code>，然后按照JobEventLogConfiguration初始化事件追踪配置bean</p>\n","categories":["Work"],"tags":["分布式","作业调度","elastic-job"]},{"title":"分布式链路追踪zipkin&brave","url":"/2019/08/%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AAzipkin-brave/","content":"<h3 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h3><p>在微服务系统中，各个微服务之间通过http、rpc等方式相互调用，形成了一个调用网络。当微服务系统逐渐庞大，有成百上千个微服务，这个调用网络就会变得非常庞杂。为了能够知道一次请求经过了哪些服务，经过的先后顺序是怎样的，以及在每个服务停留了多长时间，我们需要一个调用链路的追踪工具来帮我们收集这些信息，以便于理清服务链路、定位服务的短板所在。</p>\n<h3 id=\"zipkin\"><a href=\"#zipkin\" class=\"headerlink\" title=\"zipkin\"></a>zipkin</h3><p>zipkin就是一个这样的追踪工具。zipkin是典型的C/S架构，zipkin-client负责埋点、采样，将调用轨迹发送给zipkin-server，zipkin-server负责收集数据并存储，再暴露API给Web UI，进行调用链路的展示。</p>\n<p><img src=\"zipkin-arch.png\" alt=\"zipkin architecture\"></p>\n<p>zipkin-server包含四个组件，分别是collector、storage、search、web UI</p>\n<ul>\n<li>collector 就是信息收集器,作为一个守护进程，它会时刻等待客户端传递过来的追踪数据，对这些数据进行验证、存储以及创建查询需要的索引。</li>\n<li>storage  是存储组件。zipkin 默认直接将数据存在内存中，此外支持使用Cassandra、ElasticSearch 和 Mysql。</li>\n<li>search 是一个查询进程，它提供了简单的JSON API来供外部调用查询。</li>\n<li><p>web UI 是zipkin的服务端展示平台，主要调用search提供的接口，用图表将链路信息清晰地展示给开发人员。</p>\n<p>zipkin-client的java实现是brave，上图中的Instrumented reporter指的是集成了brave </p>\n</li>\n</ul>\n<h3 id=\"brave\"><a href=\"#brave\" class=\"headerlink\" title=\"brave\"></a>brave</h3><p>brave是对<a href=\"https://bigbully.github.io/Dapper-translation/\" target=\"_blank\" rel=\"external\">Dapper</a>的一个java实现（Dapper 勇敢(荷语)）</p>\n<h4 id=\"核心概念\"><a href=\"#核心概念\" class=\"headerlink\" title=\"核心概念\"></a>核心概念</h4><ul>\n<li><p>Span：span是brave向zipkin-server上报的最基本单位，包含span id、时间戳、、调用时长、tag信息等，代表一个调用过程</p>\n</li>\n<li><p>Trace：一个trace由多个span组成，代表一次请求的整体调用链路</p>\n<p><img src=\"trace-id.png\" alt=\"Trace Info propagation\"></p>\n<p>上图可以简化成树形结构：</p>\n</li>\n</ul>\n<p><img src=\"parents.png\" alt=\"Parent child relationship\"></p>\n<h4 id=\"Instrumentations\"><a href=\"#Instrumentations\" class=\"headerlink\" title=\"Instrumentations\"></a>Instrumentations</h4><p>brave对不同的调用过程都进行了针对性实现：</p>\n<p><img src=\"instrumentations.png\" alt=\"brave instrumentations\"></p>\n<h3 id=\"sleuth\"><a href=\"#sleuth\" class=\"headerlink\" title=\"sleuth\"></a>sleuth</h3><p>spring-cloud-sleuth 2.0是对brave的封装，以便于在spring cloud中接入</p>\n<h3 id=\"Loss-amp-Benefit\"><a href=\"#Loss-amp-Benefit\" class=\"headerlink\" title=\"Loss &amp; Benefit\"></a>Loss &amp; Benefit</h3><p>分布式链路追踪带来的好处无需多说，带来的坏处就是增加了额外的系统开销，zipkin-client是要嵌入到业务代码中的，而且要将调用轨迹发给zipkin-server增加了网络开销，因此，sleuth提供了方便的配置，让开发者可以自定义采样率，而且也可选择不给zipkin-server发送调用轨迹。</p>\n","categories":["Work"],"tags":["分布式","zipkin","brave","sleuth"]},{"title":"分布式数据库下的大表分页查询","url":"/2019/08/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8B%E7%9A%84%E5%A4%A7%E8%A1%A8%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/","content":"<p>我们对外提供的/video/list接口会对某用户下所有的视频列表进行分页查询，而vod_video表是一个具有亿级数据量的大表，任何一个对此表的查询都应该慎重对待。</p>\n<h3 id=\"分布式数据库大表查询的常见问题\"><a href=\"#分布式数据库大表查询的常见问题\" class=\"headerlink\" title=\"分布式数据库大表查询的常见问题\"></a>分布式数据库大表查询的常见问题</h3><p>vod_video表的schema像这样：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"string\">`vod_video`</span> (</div><div class=\"line\">  <span class=\"string\">`vid`</span> <span class=\"built_in\">bigint</span>(<span class=\"number\">20</span>) <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频ID，自增主键'</span>,</div><div class=\"line\">  <span class=\"string\">`video_name`</span> <span class=\"built_in\">varchar</span>(<span class=\"number\">256</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频文件名称'</span>,</div><div class=\"line\">  <span class=\"string\">`description`</span> <span class=\"built_in\">varchar</span>(<span class=\"number\">256</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频简介'</span>,</div><div class=\"line\">  <span class=\"string\">`duration`</span> <span class=\"built_in\">bigint</span>(<span class=\"number\">20</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频时间长度（秒）'</span>,</div><div class=\"line\">  <span class=\"string\">`width`</span> <span class=\"built_in\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'0'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频宽度'</span>,</div><div class=\"line\">  <span class=\"string\">`height`</span> <span class=\"built_in\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'0'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频高度'</span>,</div><div class=\"line\">  <span class=\"string\">`initial_size`</span> <span class=\"built_in\">bigint</span>(<span class=\"number\">20</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'原始视频文件大小'</span>,</div><div class=\"line\">  <span class=\"string\">`uid`</span> <span class=\"built_in\">bigint</span>(<span class=\"number\">20</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频所属用户的id'</span>,</div><div class=\"line\">  <span class=\"string\">`type_id`</span> <span class=\"built_in\">bigint</span>(<span class=\"number\">20</span>) <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频所属的分类ID'</span>,</div><div class=\"line\">  <span class=\"string\">`create_time`</span> <span class=\"built_in\">bigint</span>(<span class=\"number\">20</span>) <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频创建时间'</span>,</div><div class=\"line\">  <span class=\"string\">`update_time`</span> <span class=\"built_in\">bigint</span>(<span class=\"number\">20</span>) <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'视频更新时间'</span>,</div><div class=\"line\">  <span class=\"string\">`db_create_time`</span> <span class=\"keyword\">timestamp</span> <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'2000-01-01 00:00:00'</span>,</div><div class=\"line\">  <span class=\"string\">`db_update_time`</span> <span class=\"keyword\">timestamp</span> <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">CURRENT_TIMESTAMP</span> <span class=\"keyword\">ON</span> <span class=\"keyword\">UPDATE</span> <span class=\"keyword\">CURRENT_TIMESTAMP</span>,</div><div class=\"line\">  PRIMARY <span class=\"keyword\">KEY</span> (<span class=\"string\">`vid`</span>),</div><div class=\"line\">  <span class=\"keyword\">KEY</span> <span class=\"string\">`idx_uid_ctime`</span> (<span class=\"string\">`uid`</span>, <span class=\"string\">`create_time`</span>),</div><div class=\"line\">) <span class=\"keyword\">ENGINE</span>=<span class=\"keyword\">InnoDB</span> <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">CHARSET</span>=utf8 <span class=\"keyword\">COMMENT</span>=<span class=\"string\">'视频表'</span> <span class=\"comment\">/* BF=vid, POLICY=user, STARTID=8001, AUTO_INCREMENT_COLUMN=vid, ASSIGNIDTYPE=USB */</span>;</div></pre></td></tr></table></figure>\n<p>由于均衡字段vid的存在，vod_video表中的数据得以相对均匀地分布在各个数据节点(dbn)上，当客户端查询select <em> from vod_video order by create_time desc limit n offset m时，QS会向每个dbn发送select </em> from vod_video order by create_time desc limit n+m，也就是说每个dbn节点最多会返回(n+m)条数据，所有返回的数据会在QS再做一次merge sort，如果(n+m)很大，那么merge sort的数据集就会很大，一方面会增加排序时间，另一方面也会使QS的网卡流量瞬间飙升，甚至可能超过最大阈值。</p>\n<p><img src=\"ddb架构图.png\" alt=\"ddb架构图\"></p>\n<p>如果按照上面做法，直接将limit n offset m丢给ddb，当用户的查询分页数很大，而且用户下的视频量很大时，每个dbn的返回数量会非常大，严重影响性能。所以需要进行优化。</p>\n<p>下面说明优化后的做法。</p>\n<h3 id=\"跳跃式查询\"><a href=\"#跳跃式查询\" class=\"headerlink\" title=\"跳跃式查询\"></a>跳跃式查询</h3><p>假设有个查询场景，用户查的offset是3万，limit是500，为避免offset过大，我们先查3次，每次的offset是1万limit是1，定位到3万offset的起始位置，然后把这个起始位置带到where条件里面再查下面的500条，如下图所示(图中v1~v30500按视频创建时间create_time降序排列)</p>\n<p><img src=\"跳跃式查询.png\" alt=\"跳跃式查询\"></p>\n<p>我们的目标是拿到v30001~v30500的数据。</p>\n<ul>\n<li>首先，select vid, create_time from vod_video where create_time&lt;=32503651200000 limit 1 offset 9999拿到v10000；</li>\n<li>然后，select vid, create_time from vod_video where create_time&lt;=c1 limit 1 offset 10000拿到v20000；</li>\n<li>接着，select vid, create_time from vod_video where create_time&lt;=c2 limit 1 offset 10000拿到v30000；</li>\n<li>最后，select * from vod_video where create_time&lt;=c3 limit 500 offset 1拿到v30001~v30500</li>\n</ul>\n<p>这其实是利用了create_time进行跳跃式查询，逐渐逼近v30000，最后再一次取出目标数据。每次查询的offset都不超过10000，不会出现offset过大导致的查询性能下降以及QS网卡流量过大的问题。</p>\n<p>当然，这种方法有一个小瑕疵，就是如果有create_time相等的视频，那么每次分页取出的视频可能会有少部分重叠。一方面，create_time是毫秒级别的，所以这种情况产生的概率比较小；另一方面，这种情况其实也相当于是为了提升查询效率的一个tradeoff，在概率较小的情况下是可以接受的，而且用户也可以做一次根据vid的去重来处理这种情况。</p>\n","categories":["Work"],"tags":["分布式数据库"]},{"title":"dubbo优雅下线分析","url":"/2019/08/dubbo%E4%BC%98%E9%9B%85%E4%B8%8B%E7%BA%BF%E5%88%86%E6%9E%90/","content":"<h3 id=\"问题背景\"><a href=\"#问题背景\" class=\"headerlink\" title=\"问题背景\"></a>问题背景</h3><p>我们微服务之间的远程调用使用的是dubbo框架（版本2.4.9），在最近几次服务的发布中，我们发现在dubbo provider服务的重启过程中，如果此时正处于业务的高峰期，短时间内会有大量的rpc调用失败，如果consumer侧没有重试机制或本地兜底策略的话，很可能导致业务异常。</p>\n<p>为了解决上述问题，我们有必要知道我们服务上下线过程中，dubbo究竟做了哪些事情。</p>\n<h3 id=\"服务上线\"><a href=\"#服务上线\" class=\"headerlink\" title=\"服务上线\"></a>服务上线</h3><p>首先看在上线过程中，dubbo是如何做到服务的注册和发现的。dubbo的架构如下图：</p>\n<p><img src=\"architecture.png\" alt=\"Dubbo Architecture\"></p>\n<p>对于provider，dubbo会监听Spring容器的启动刷新事件(ContextRefreshedEvent)，调用export()方法暴露服务。在使用zk作为注册中心的前提下，export()方法按顺序做下面3件事。</p>\n<ul>\n<li>URL装配：读取provider端配置，根据约定好的协议将服务装配成URL的形式</li>\n<li>协议暴露：所谓协议暴露，简单来说就是先创建NettyServer，然后给每个URL创建一个本地方法的代理，并将二者映射起来，NettyServer接收请求会调用对应的本地方法</li>\n<li>向zk注册节点：将装配好的URL通过zkClient注册到zk节点中，完成服务的暴露</li>\n</ul>\n<p>对于consumer，dubbo根据consumer侧的配置选择订阅provider的某几个服务。订阅操作包含两个动作，一是consumer本身在zk的consumer节点下注册；二是创建监听器来感知zk节点的变化。provider上下线时会引起对应zk节点的变化，监听器感知到节点变化后，会调用NotifyListener的notify方法，更新内存中的provider列表；与此同时，consumer还会将最新的provider列表写入<code>~/.dubbo</code>目录下的文件中，这样做可以保证在zk挂掉的情况下，consumer依然能通过本地的缓存文件找到provider的地址。拿到provider列表后，接下来consumer就可以根据约定好的协议进行远程调用了，当然在这一步还可以做负载均衡。</p>\n<h3 id=\"服务下线\"><a href=\"#服务下线\" class=\"headerlink\" title=\"服务下线\"></a>服务下线</h3><h4 id=\"what-dubbo-expected\"><a href=\"#what-dubbo-expected\" class=\"headerlink\" title=\"what dubbo expected\"></a>what dubbo expected</h4><p>我们服务下线过程中，dubbo有两处代码来处理dubbo的下线。一处是ServiceBean中的detroy()方法，由spring在销毁bean的时候调用；另一处是AbstractConfig中的DubboShutdownHook，是JVM退出时的钩子线程，会在JVM退出之前执行。</p>\n<p>先看ServiceBean的detroy()方法（具体可以看AbstractRegistryFactory、ZookeeperRegistry、FailbackRegistry、AbstractRegistry）。对consumer来说，destroy()方法就是上面订阅过程的逆，即unsubscribe，首先关闭节点监听器，然后会删除zk中的consumer节点。对于provider来说，就是删除zk中的provider节点，这样的话，监听到节点删除的consumer就会更新内存中的provider列表，对于新的rpc请求就不会调用已被删除的provider了。</p>\n<p>下面着重看一下DubboShutdownHook，主要调的是<code>ProtocolConfig.detroyAll()</code>，这是dubbo优雅下线的核心逻辑。</p>\n<p><img src=\"ProtocolConfig.png\" alt=\"ProtocolConfig.detroyAll()\"></p>\n<p><code>AbstractRegistryFactory.destroyAll()</code>方法与上面ServiceBean的detroy()方法类似，仅仅多了一步zkClient的关闭。由于dubbo支持多协议，所以会遍历所有协议调用<code>protocol.destroy()</code>，我们只使用了dubbo协议，所以看<code>DubboProtocol.destroy()</code>。</p>\n<p><img src=\"DubboProtocol.png\" alt=\"DubboProtocol.destroy()\"></p>\n<p>可以看到是先关闭provider再关闭consumer，如果先关闭consumer后provider，那么上游服务的请求依然能够被provider处理，如果provider依赖下游服务，会导致调用链路的失败。</p>\n<p>进入<code>server.close(int timeout)</code>，实际是<code>HeaderExchangeServer.close(int timeout)</code>方法。<code>sendChannelReadOnlyEvent()</code>向consumer发送readonly信号，目的是告诉consumer不要再向我发送请求了，前面提到consumer在zk挂掉的情况下依然可以读取本地缓存获取provider列表，readonly信号的存在为consumer提供了另一种剔除provider的方式。接下来while循环里等待已经正在运行的任务执行完毕或者超时，超时时间用户可配置、默认10秒。最后会停止与consumer的心跳，关闭NettyServer。</p>\n<p><img src=\"HeaderExchangeServer.png\" alt=\"HeaderExchangeServer.close()\"></p>\n<p>进入<code>client.close()</code>，实际调用<code>HeaderExchangeClient.close()</code>方法。这个比较简单，就是停止与provider的心跳，然后关闭NettyClient。</p>\n<p>以上就是从spring销毁到JVM退出的过程中dubbo（v2.4.9）做的所有操作。可以看到，spring销毁中的<code>ServiceBean.detroy()</code>和DubboShutdownHook中的<code>ProtocolConfig.destroyAll()</code>有重合的操作－摘除zk节点，而DubboShutdownHook还进行了关闭zk连接、协议销毁、等待已提交任务执行完毕、停止心跳等动作。如果按照这一系列步骤执行下去，为什么还会出现开头说的问题呢？两种可能：(1)以上流程并未像dubbo设计的那样真正的走完；(2)以上流程存在缺陷。</p>\n<h4 id=\"what-actually-happens\"><a href=\"#what-actually-happens\" class=\"headerlink\" title=\"what actually happens\"></a>what actually happens</h4><p>实际上，在我们服务发布的过程中，DubboShutdownHook并没有得到执行。</p>\n<p>我们服务的发布（发布=下线＋tomcat重启）操作都是通过NDP完成的。点击NDP上的“发布”按钮，首先NDP会调用/health/offline接口，nginx在进行健康检查时发现状态是403就会把这台机器从upstream踢掉；接下来关闭tomcat进程，调用的命令是<code>./catalina.sh stop 5 -force</code>，意思是最多等待5秒，如果tomcat进程依然存在，就强制杀掉(kill -9)；最后再重新启动tomcat。</p>\n<p><img src=\"NDP发布日志.png\" alt=\"NDP发布日志\"></p>\n<p>Java的API文档中介绍了JVM会在何时正常退出：</p>\n<blockquote>\n<p>The Java virtual machine <em>shuts down</em> in response to two kinds of events:</p>\n<ul>\n<li>The program <em>exits</em> normally, when the last non-daemon thread exits or when the <code>exit</code>(equivalently, <a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/System.html#exit-int-\" target=\"_blank\" rel=\"external\"><code>System.exit</code></a>) method is invoked, or</li>\n<li>The virtual machine is <em>terminated</em> in response to a user interrupt, such as typing <code>^C</code>, or a system-wide event, such as user logoff or system shutdown.</li>\n</ul>\n</blockquote>\n<p>可以看到，tomcat无法正常停止，被超时强杀掉了，JVM没有正常退出，所以DubboShutdownHook不会被执行。</p>\n<h4 id=\"tomcat进程为什么无法正常停止？\"><a href=\"#tomcat进程为什么无法正常停止？\" class=\"headerlink\" title=\"tomcat进程为什么无法正常停止？\"></a>tomcat进程为什么无法正常停止？</h4><p>可以看一下我们服务的历史发布日志，大多数服务的tomcat都不能stop in time，而这些服务无一例外都用了dubbo，这个锅肯定是要dubbo背了。</p>\n<p>我们看com.alibaba.dubbo.remoting.transport.netty.NettyClient中的两段代码：</p>\n<p><img src=\"构造NioClientSocketChannelFactory.png\" alt=\"构造NioClientSocketChannelFactory\"></p>\n<p>上面是为netty创建boss线程池和worker线程池。注释里提到了一个netty内存泄露的bug，在大量创建和关闭channelFactory时会引起堆外内存的大量泄露，从而引发OOM。dubbo为了避免频繁的创建和关闭，将channelFactory设置成了static，与此同时将下图doClose()方法中的释放资源的操作注释掉了（bootstrap.releaseExternalResources()最终会调用channelFactory.releaseExternalResources()），channelFactory不会被显式关闭。</p>\n<p><img src=\"注释doClose方法.png\" alt=\"注释doClose()方法\"></p>\n<p>看NioClientSocketChannelFactory的构造函数发现，除了创建了boss和worker两个线程池之外，还创建了一个HashedWheelTimer定时器线程，而这个线程是非daemon的。由于这个非daemon的线程没有被显式地关闭，导致JVM一直不会退出。tomcat只能关闭自己起的线程，servlet容器内部应用创建的线程是无法被tomcat关闭的，应该由应用自己管理和关闭，因此，即使tomcat容器被销毁了，但进程依然还在。</p>\n<p>小结一下，dubbo在销毁的过程中为了规避netty内存泄露的bug，没有显式地释放HashedWheelTimer线程资源，JVM无法正常退出，导致DubboShutdownHook没有被执行。换句话说，dubbo的代码没有以它设计时所期待的那样运行，精心设计的优雅下线根本没被执行，dubbo说这全TM怪netty。。。</p>\n<h3 id=\"优化DubboShutdownHook\"><a href=\"#优化DubboShutdownHook\" class=\"headerlink\" title=\"优化DubboShutdownHook\"></a>优化DubboShutdownHook</h3><p>假设我们可以在tomcat关闭的时候手动关闭HashedWheelTimer（通过反射），也就是说这时候一切会按照dubbo的“计划”执行，DubboShutdownHook也会执行了，那么本文开头说的那个问题是不是就解决了呢？</p>\n<p>还是看<code>ProtocolConfig.destroyAll()</code>，有两个优化点。</p>\n<ul>\n<li>provider摘掉zk节点后，理论上consumer收到通知会立即更新provider列表，但因为provider从注册中心撤销服务和consumer将其从服务列表中删除并不是原子操作，如果集群规模过大，可能导致上游consumer的服务列表还未更新完成，provider这时发现当前没有进行中的调用就立马关闭服务暴露，导致上游consumer调用该服务失败。所以，dubbo默认的这种优雅停机方案，需要建立在上游consumer有重试机制的基础之上，但由于consumer增加重试特性会增加故障时的雪崩风险，所以大多数分布式服务不愿意增加服务内部之间的重试机制。问题的本质上是因为provider摘除zk节点没有给consumer足够的时间来更新服务列表，简单的解决方式是在摘除zk节点之后、销毁协议之前，主动sleep一段时间，sleep这段时间内provider依然能够处理来自未来得及更新provider列表的consumer的请求，极大地减小调用失败的概率。</li>\n<li><code>DubboProtocol.destroy()</code>方法中，当provider对外关闭暴露并且已有任务执行完成之后，理论上此时可以立即关闭consumer，即代码中的<code>client.close()</code>，因为既然上游服务的调用已全部处理完成、且不再有新的调用过来，那么理论上此时下游的服务也已经执行完成。但是考虑到业务中可能有其他类型的请求调用了下游的rpc服务（例如定时任务），立即关闭client可能导致这部分调用失败。因此，应调用<code>client.close(int timeout)</code>方法，等待这部分调用执行完成。</li>\n</ul>\n<p>最终，改动以下两处代码：</p>\n<p><code>ProtocolConfig.destroyAll()</code>：</p>\n<p><img src=\"DubboShutdownHook优化1.png\" alt=\"DubboShutdownHook优化1\"></p>\n<p><code>DubboProtocol.detroy()</code>：</p>\n<p><img src=\"DubboShutdownHook优化2.png\" alt=\"DubboShutdownHook优化2\"></p>\n<p>为了验证上述改动的可行性，我做了一个简单的对比实验。</p>\n<p>我在本地部署了2个provider和1个consumer，zk也部在本地。provider侧暴露dubboTest()方法，该方法简单地sleep 1秒然后返回；consumer侧同时起200个线程模拟200路并发，每个线程内都是一个死循环，不断调用dubboTest()，相当于持续200路并发。中途手动关闭1个provider，然后统计consumer侧rpc调用异常的次数。</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>不执行DubboShutdownHook</th>\n<th>执行现有DubboShutdownHook</th>\n<th>执行优化DubboShutdownHook</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>异常次数</td>\n<td>89</td>\n<td>49</td>\n<td>31</td>\n</tr>\n</tbody>\n</table>\n<p>我们服务的现状就是不执行DubboShutdownHook，可以看到异常次数是最多的；执行本版本dubbo提供的hook后异常减少了将近一半，执行优化后的hook后异常数进一步减少，说明执行hook的效果还是比较明显的。但是执行优化后hook的效果没那么明显，原因可能是：provider、consumer、zk都部署在本地，通信速度快，consumer侧更新provider列表的速度快。另外，持续200路并发，按照负载均衡，大约每个provider同时承载100路并发，线上监控显示我们线上rpc调用的瞬时并发在100路左右，而且线上集群provider的个数一般在4个左右，平均每个provider承载25路左右，能进一步消化负载，所以线上的测试效果会更好。关于优化的真实效果可通过后续压测得出。</p>\n","categories":["Work"],"tags":["dubbo","分布式","tomcat"]},{"title":"Enable TLSv1.2 in JDK7","url":"/2019/04/Enable-TLSv1-2-in-JDK7/","content":"<p>最近发现我们线上服务器向用户服务器发送https请求被拒绝的现象，原因是用户服务器设置的https协议是只支持TLSv1.2的请求，而我们服务器发送https请求使用的是TLSv1，用户服务器拒绝握手。</p>\n","categories":["Work"],"tags":["https"]},{"title":"Light-weight 'ping' to Mysql Server","url":"/2019/02/Light-weight-ping-to-Mysql-Server/","content":"<p>The MySQL JDBC driver (Connector/J) provides a ping mechanism.</p>\n<p>If you do a SQL query prepended with /<em> ping </em>/ such as:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">/* ping */ SELECT 1</div></pre></td></tr></table></figure>\n<p>This will actually cause the driver send a ping to the server and return a fake, light-weight, result set.</p>\n<blockquote>\n<p>摘自<a href=\"https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-usagenotes-j2ee-concepts-connection-pooling.html#idm139975764832048\" target=\"_blank\" rel=\"external\">https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-usagenotes-j2ee-concepts-connection-pooling.html#idm139975764832048</a></p>\n</blockquote>\n<p>MySQL Connector/J can validate the connection by executing a lightweight ping against a server. In the case of load-balanced connections, this is performed against all active pooled internal connections that are retained. This is beneficial to Java applications using connection pools, as the pool can use this feature to validate connections. Depending on your connection pool and configuration, this validation can be carried out at different times:</p>\n<ol>\n<li>Before the pool returns a connection to the application.</li>\n<li>When the application returns a connection to the pool.</li>\n<li>During periodic checks of idle connections.</li>\n</ol>\n<p>To use this feature, specify a validation query in your connection pool that starts with <code>/* ping */</code>. Note that the syntax must be exactly as specified. This will cause the driver send a ping to the server and return a dummy lightweight result set. When using a <code>ReplicationConnection</code> or <code>LoadBalancedConnection</code>, the ping will be sent across all active connections.</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">protected</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> String PING_MARKER = <span class=\"string\">\"/* ping */\"</span>;</div><div class=\"line\">... </div><div class=\"line\"><span class=\"keyword\">if</span> (sql.charAt(<span class=\"number\">0</span>) == <span class=\"string\">'/'</span>) &#123; </div><div class=\"line\">\t<span class=\"keyword\">if</span> (sql.startsWith(PING_MARKER)) &#123; </div><div class=\"line\">\t\tdoPingInstead(); </div><div class=\"line\">\t\t...</div></pre></td></tr></table></figure>\n<p>All of the previous statements will issue a normal <code>SELECT</code> statement and will <strong>not</strong> be transformed into the lightweight ping. Further, for load-balanced connections, the statement will be executed against one connection in the internal pool, rather than validating each underlying physical connection. This results in the non-active physical connections assuming a stale state, and they may die. If Connector/J then re-balances, it might select a dead connection, resulting in an exception being passed to the application. To help prevent this, you can use <code>loadBalanceValidateConnectionOnSwapServer</code> to validate the connection before use.</p>\n<p>If your Connector/J deployment uses a connection pool that allows you to specify a validation query, take advantage of it, but ensure that the query starts <em>exactly</em> with <code>/* ping */</code>. This is particularly important if you are using the load-balancing or replication-aware features of Connector/J, as it will help keep alive connections which otherwise will go stale and die, causing problems later.</p>\n","categories":["Work"],"tags":["Mysql"]},{"title":"HttpDNS原理","url":"/2019/02/HttpDNS%E5%8E%9F%E7%90%86/","content":"<blockquote>\n<p>转载自：<a href=\"https://cloud.tencent.com/developer/article/1035562\" target=\"_blank\" rel=\"external\">https://cloud.tencent.com/developer/article/1035562</a></p>\n</blockquote>\n<p>但凡使用域名来给用户提供服务的互联网企业，都或多或少地无法避免在有中国特色的互联网环境中遭遇到各种域名被缓存、用户跨网访问缓慢等问题。那么对于腾讯这样的域名数量在10万级别的互联网公司来讲，域名解析异常的情况到底有多严重呢？每天腾讯的分布式域名解析监测系统在不停地对全国所有的重点LocalDNS进行探测，腾讯域名在全国各地的日解析异常量是已经超过了80万条。这给腾讯的业务带来了巨大的损失。为此腾讯建立了专业的团队与各个运营商进行了深度沟通，但是由于各种原因，处理效率及效果均不能达到腾讯各业务部门的需求。除了和运营商进行沟通，有没有一种技术上的方案，能从根源上解决域名解析异常及用户访问跨网的问题呢？</p>\n<h1 id=\"一、问题根源：\"><a href=\"#一、问题根源：\" class=\"headerlink\" title=\"一、问题根源：\"></a><strong>一、问题根源：</strong></h1><p>要解决问题，我们得先得了解下现在国内各ISP的LocalDNS的基本情况。国内运营商LocalDNS造成的用户访问异常可以归为下三类：</p>\n<h2 id=\"1、域名缓存：\"><a href=\"#1、域名缓存：\" class=\"headerlink\" title=\"1、域名缓存：\"></a>1、域名缓存：</h2><p>域名缓存很好理解，就是LocalDNS缓存了腾讯的域名的解析结果，不向腾讯权威DNS发起递归，示意图如下：</p>\n<p><img src=\"kjod1407ai.png\" alt=\"img\"></p>\n<p>为何LocalDNS要把域名解析结果进行缓存呢？原因有以下几个：</p>\n<p>（1）保证用户访问流量在本网内消化：国内的各互联网接入运营商的带宽资源、网间结算费用、IDC机房分布、网内ICP资源分布等存在较大差异。为了保证网内用户的访问质量，同时减少跨网结算，运营商在网内搭建了内容缓存服务器，通过把域名强行指向内容缓存服务器的IP地址，就实现了把本地本网流量完全留在了本地的目的。</p>\n<p>（2）推送广告：有部分LocalDNS会把部分域名解析结果的所指向的内容缓存，并替换成第三方广告联盟的广告。</p>\n<p>​    这种类型的行为就是我们常说的域名缓存，域名缓存会导致用户产生以下的访问异常：</p>\n<p>A、仅对80端口的http服务做了缓存，如果域名是通过https协议或其它端口提供服务的，用户访问就会出现失败。比如支付服务、游戏通过指定端口连接connect server服务等。</p>\n<p>B、缓存服务器的运维水平参差不齐，时有出现缓存服务器故障导致用户访问异常的问题。</p>\n<h2 id=\"2、解析转发：\"><a href=\"#2、解析转发：\" class=\"headerlink\" title=\"2、解析转发：\"></a>2、解析转发：</h2><p>除了域名缓存以外，运营商的LocalDNS还存在解析转发的现象。解析转发是指运营商自身不进行域名递归解析，而是把域名解析请求转发到其它运营商的递归DNS上的行为。正常的LocalDNS递归解析过程是这样的：</p>\n<p><img src=\"jhwvjv0dox.png\" alt=\"img\"></p>\n<p>而部分小运营商为了节省资源，就直接将解析请求转发到了其它运营的递归LocalDNS上去了：</p>\n<p><img src=\"lea2fi8v6o.png\" alt=\"img\"></p>\n<p>这样的直接后果就是腾讯权威DNS收到的域名解析请求的来源IP就成了其它运营商的IP，最终导致用户流量被导向了错误的IDC，用户访问变慢。</p>\n<h2 id=\"3、LocalDNS递归出口NAT：\"><a href=\"#3、LocalDNS递归出口NAT：\" class=\"headerlink\" title=\"3、LocalDNS递归出口NAT：\"></a>3、LocalDNS递归出口NAT：</h2><p>LocalDNS递归出口NAT指的是运营商的LocalDNS按照标准的DNS协议进行递归，但是因为在网络上存在多出口且配置了目标路由NAT，结果导致LocalDNS最终进行递归解析的时候的出口IP就有概率不为本网的IP地址：</p>\n<p><img src=\"n1uwh9m7ls.png\" alt=\"img\"></p>\n<p>这样的直接后果就是GSLB DNS收到的域名解析请求的来源IP还是成了其它运营商的IP，最终导致用户流量被导向了错误的IDC，用户访问变慢。</p>\n<h1 id=\"二、现有的解决方案及存在的问题：\"><a href=\"#二、现有的解决方案及存在的问题：\" class=\"headerlink\" title=\"二、现有的解决方案及存在的问题：\"></a><strong>二、现有的解决方案及存在的问题：</strong></h1><p>运营商的LocalDNS解析域名异常，给对用户访问腾讯业务的体验造成了非常大的损害。那么我们是如何处理这些域名解析异常的问题的呢？</p>\n<h2 id=\"1、实时监控-商务推动：\"><a href=\"#1、实时监控-商务推动：\" class=\"headerlink\" title=\"1、实时监控+商务推动：\"></a>1、实时监控+商务推动：</h2><p>这种方案是目前腾讯的运营团队一直在使用的方案。这种方案就是周期比较长，毕竟通过行政手段来推动运营商来解决这个问题是比较耗时的。另外我们通过大数据分析，得出的结论是Top 3的问题用户均为移动互联网用户。对于这部分用户，我们有什么技术手段可以解决以上的问题呢？</p>\n<h2 id=\"2、绕过自动分配DNS，使用114dns或Google-public-DNS：\"><a href=\"#2、绕过自动分配DNS，使用114dns或Google-public-DNS：\" class=\"headerlink\" title=\"2、绕过自动分配DNS，使用114dns或Google public DNS：\"></a>2、绕过自动分配DNS，使用114dns或Google public DNS：</h2><p>这个方案看上去很美好，114dns是国内最大的中立缓存DNS，而Google又是秉承不作恶理念的互联网工程帝国巨鳄，而且腾讯的权威DNS又支持edns-client-subnet功能，能直接识别使用Google publicDNS解析腾讯域名的用户的IP地址，不会出现流量调度失效。但是问题来了：</p>\n<p>（1）如何在用户侧构造域名请求：对于PC端的客户端来说，构造一个标准的DNS请求包并不算什么难事。但在移动端要向一个指定的LocalDNS上发送标准的DNS请求包，而且要兼容各种iOS和android的版本的话，技术上是可行的，只是兼容的成本会很高。</p>\n<p>（2）推动用户修改配置极高：如果要推动用户手动修改PC的DNS配置的话，在PC端和手机客户端的WiFI下面还算勉强可行。但是要用户修改在移动互联网环境下的DNS配置，其难度不言而喻。</p>\n<h2 id=\"3、完全抛弃域名，自建connectcenter进行流量调度：\"><a href=\"#3、完全抛弃域名，自建connectcenter进行流量调度：\" class=\"headerlink\" title=\"3、完全抛弃域名，自建connectcenter进行流量调度：\"></a>3、完全抛弃域名，自建connectcenter进行流量调度：</h2><p>如果要采用这种这种方案的话，首先你就得要拿到一份准确的IP地址库来判断用户的归属，然后再制定个协议搭个connect center来做调度，然后再对接入层做调度改造。这种方案和2种方案一样，不是不能做，只是成本会比较高，尤其对于腾讯这种业务规模如此庞大的公司而言。</p>\n<h2 id=\"三、利用HttpDNS解决用户域名解析异常：\"><a href=\"#三、利用HttpDNS解决用户域名解析异常：\" class=\"headerlink\" title=\"三、利用HttpDNS解决用户域名解析异常：\"></a><strong>三、利用HttpDNS解决用户域名解析异常：</strong></h2><p>既然上面的方案都存在那么多的问题，那有没有一种调度精准、成本低廉、配置方便的基于域名的流量调度系统呢？答案是肯定的。腾讯公司的GSLB 团队推出了一种全新的域名解析调度系统：HttpDNS。HttpDNS是为移动客户端量身定做的基于Http协议和域名解析的流量调度解决方案，专治LocalDNS解析异常以及流量调度不准。详细介绍如下：</p>\n<p>（1）HttpDNS基本原理：</p>\n<p><img src=\"plmq0zuo5y.png\" alt=\"img\"></p>\n<p>HttpDNS的原理非常简单，主要有两步：</p>\n<p>A、客户端直接访问HttpDNS接口，获取业务在域名配置管理系统上配置的访问延迟最优的IP。（基于容灾考虑，还是保留次选使用运营商LocalDNS解析域名的方式）</p>\n<p>B、客户端向获取到的IP后就向直接往此IP发送业务协议请求。以Http请求为例，通过在header中指定host字段，向HttpDNS返回的IP发送标准的Http请求即可。</p>\n<p>（2）HttpDNS优势：</p>\n<p>从原理上来讲，HttpDNS只是将域名解析的协议由DNS协议换成了Http协议，并不复杂。但是这一微小的转换，却带来了无数的收益：</p>\n<p>A、根治域名解析异常：由于绕过了运营商的LocalDNS，用户解析域名的请求通过Http协议直接透传到了腾讯的HttpDNS服务器IP上，用户在客户端的域名解析请求将不会遭受到域名解析异常的困扰。</p>\n<p>B、调度精准：HttpDNS能直接获取到用户IP，通过结合腾讯自有专利技术生成的IP地址库以及测速系统，可以保证将用户引导的访问最快的IDC节点上。</p>\n<p>C、实现成本低廉：接入HttpDNS的业务仅需要对客户端接入层做少量改造，无需用户手机进行root或越狱；而且由于Http协议请求构造非常简单，兼容各版本的移动操作系统更不成问题；另外HttpDNS的后端配置完全复用现有权威DNS配置，管理成本也非常低。总而言之，就是以最小的改造成本，解决了业务遭受域名解析异常的问题，并满足业务精确流量调度的需求。</p>\n<p>D、扩展性强：HttpDNS提供可靠的域名解析服务，业务可将自有调度逻辑与HttpDNS返回结果结合，实现更精细化的流量调度。比如指定版本的客户端连接请求的IP地址，指定网络类型的用户连接指定的IP地址等。</p>\n<p>​        当然各位可能会问：用户将首选的域名解析方式切换到了HttpDNS，那么HttpDNS的高可用又是如何保证的呢？另外不同运营商的用户访问到同一个HttpDNS的服务IP，用户的访问延迟如何保证？</p>\n<p>为了保证高可用及提升用户体验，HttpDNS通过接入了腾讯公网交换平台的BGP Anycast网络，与全国多个主流运营商建立了BGP互联，保证了这些运营商的用户能够快速地访问到HttpDNS服务；另外HttpDNS在多个数据中心进行了部署，任意一个节点发生故障时均能无缝切换到备份节点，保证用户解析正常。</p>\n<h2 id=\"四、接入效果及未来展望：\"><a href=\"#四、接入效果及未来展望：\" class=\"headerlink\" title=\"四、接入效果及未来展望：\"></a><strong>四、接入效果及未来展望：</strong></h2><p>当前HttpDNS已在腾讯内部接入了多个业务，覆盖数亿用户，并已持续稳定运行超过一年时间。而接入了HttpDNS的业务在用户访问体验方面都有了非常大的提升。以某个接入HttpDNS的业务为例，该业务仅通过接入HttpDNS，在未做任何其它优化的情况下，用户平均访问延迟下降超过10%，访问失败率下降了超过五分之一，用户访问体验的效果提升非常显著。另外腾讯的HttpDNS服务除了在腾讯内部被广泛使用以外，也受到了业务同行的肯定。国内最大的publicDNS服务商114dns在受到腾讯DNS的启发下，也推出了HttpDNS服务。</p>\n<p>在未来的日子里，腾讯GSLB团队将会在腾讯内部进一步推广HttpDNS服务，并将在实际业务的需求下对HttpDNS服务进行升级，如提供更为通用、安全、简单的接入协议，进一步提升接入用户的网络访问体验等等。希望HttpDNS能为各位在解决域名解析异常及全局流量调度失效方面提供一个简单、可行的思路，也欢迎各位业界同行与腾讯一起，就如何进行更精准的全局流量调度方面进行更为深入的讨论!</p>\n","categories":["Work"],"tags":["HttpDNS"]},{"title":"nginx location匹配规则","url":"/2019/02/nginx-location%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99/","content":"<p>nginx location匹配规则：<a href=\"https://segmentfault.com/a/1190000013267839\" target=\"_blank\" rel=\"external\">https://segmentfault.com/a/1190000013267839</a></p>\n","categories":["Work"],"tags":["nginx"]},{"title":"Ubuntu 14.04常用工具","url":"/2019/02/Ubuntu-14-04%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/","content":"<p>记录下能在Ubuntu 14.04下使用的、个人认为比较好用的几款工具。</p>\n<p>Markdown编辑器：Typora</p>\n<p>diff：Meld</p>\n<p>画图：draw.io</p>\n<p>Todo list：Nitro、Go for it!</p>\n<p>Git GUI：Gitkraken</p>\n<p>云笔记：Wiznote（试用期后收费），Simplenote（免费）</p>\n<p>远程连接：PAC</p>\n<p>截图：shutter</p>\n<p>多屏键鼠共享：synergy</p>\n<p>论文写作：Texmaker + texlive</p>\n<p>程序员交流IM：Gitter</p>\n<p>流媒体播放：VLC media player</p>\n<p>Redis客户端GUI：Redis Desktop Manager</p>\n<p>VPN客户端：openvpn、EasyConnect</p>\n<p>Http请求：Postman</p>\n<p>抓包：Charles、Wireshark</p>\n<p>命令行词典：Wudao-dict</p>\n","categories":["Tool"],"tags":["Ubuntu"]},{"title":"cache和db的一致性问题","url":"/2018/12/cache%E5%92%8Cdb%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/","content":"<h4 id=\"更新cache-db的原则\"><a href=\"#更新cache-db的原则\" class=\"headerlink\" title=\"更新cache/db的原则\"></a>更新cache/db的原则</h4><h5 id=\"读多写少的场景\"><a href=\"#读多写少的场景\" class=\"headerlink\" title=\"读多写少的场景\"></a>读多写少的场景</h5><p>读：读cache，有就返回；没有，读db，更新cache，返回</p>\n<p>写：写db，删除cache</p>\n<h5 id=\"写多读少的场景\"><a href=\"#写多读少的场景\" class=\"headerlink\" title=\"写多读少的场景\"></a>写多读少的场景</h5><blockquote>\n<p>参考：<a href=\"https://www.jianshu.com/p/496ea8bc9aa1\" target=\"_blank\" rel=\"external\">https://www.jianshu.com/p/496ea8bc9aa1</a></p>\n</blockquote>\n<h4 id=\"在事务中的顺序\"><a href=\"#在事务中的顺序\" class=\"headerlink\" title=\"在事务中的顺序\"></a>在事务中的顺序</h4><p>cache和db操作放在一个事务里的时候，要注意cache和db的更新顺序，因为rollback是针对db而言的。</p>\n<h5 id=\"先cache后db\"><a href=\"#先cache后db\" class=\"headerlink\" title=\"先cache后db\"></a>先cache后db</h5><p><img src=\"先cache后db.png\" alt=\"\"></p>\n<ul>\n<li>写cache成功 -&gt; 写db成功 -&gt; success</li>\n<li>写cache成功 -&gt; 写db失败 -&gt; db回滚 -&gt; cache改变了，db不变，造成不一致</li>\n<li>写cache失败 -&gt; db回滚 -&gt; cache不变，db也不变，一致</li>\n</ul>\n<h5 id=\"先db后cache\"><a href=\"#先db后cache\" class=\"headerlink\" title=\"先db后cache\"></a>先db后cache</h5><p><img src=\"先db后cache.png\" alt=\"\"></p>\n<ul>\n<li>写db成功 -&gt; 写cache成功 -&gt; success</li>\n<li>写db成功 -&gt; 写cache失败 -&gt; db回滚 -&gt; cache和db都不变，一致</li>\n<li>写db失败 -&gt; db回滚 -&gt; cache和db都不变，一致</li>\n</ul>\n<p>解决不一致问题的常用方法：</p>\n<p>事务</p>\n<p>悲观锁</p>\n<p>乐观锁：version</p>\n<p>分布式锁</p>\n","categories":["Work"],"tags":["cache","一致性"]},{"title":"elastic-job实现分析","url":"/2018/12/elastic-job%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/","content":"<h2 id=\"elastic-job架构分析\"><a href=\"#elastic-job架构分析\" class=\"headerlink\" title=\"elastic-job架构分析\"></a>elastic-job架构分析</h2><h3 id=\"概览\"><a href=\"#概览\" class=\"headerlink\" title=\"概览\"></a>概览</h3><p>elastic-job整体上采用去中心化调度的架构，调度和执行存在于同一节点上，使用zookeeper作为注册中心进行节点的分布式协调。zookeeper中存储了每个作业的配置信息、机器节点信息、分片信息等；每个节点通过apache curator与zk通信，调度能力依然由quartz提供。此外，elastic-job提供了console管理界面，console与各执行节点无任何交互，可以理解为一个zk client，拉取zk节点中的作业状态等并进行展示。</p>\n<p><img src=\"概览.png\" alt=\"概览\"></p>\n<p>elastic-job的部署十分简单，console由springboot开启，各机器节点引入elastic-job-lite-core.jar和elastic-job-lite-spring.jar包即可。</p>\n<h3 id=\"zk节点管理\"><a href=\"#zk节点管理\" class=\"headerlink\" title=\"zk节点管理\"></a>zk节点管理</h3><p>下图是elastic-job的zk目录结构（黄色是临时节点，蓝色是持久化的目录或节点）：</p>\n<p><img src=\"zk节点.png\" alt=\"zk节点\"></p>\n<p>下图是elastic-job与zk通信和节点操作时涉及到的主要类的简单关系图。左边的五个Node节点类对应zk的目录节点，上层通过相应的Service类进行管理；RegistryCenter封装了与zk的交互操作，通过Curator实现通信（TreeCache缓存）。</p>\n<p><img src=\"节点与zk通信.png\" alt=\"节点与zk通信\"></p>\n<h3 id=\"注册-amp-发现\"><a href=\"#注册-amp-发现\" class=\"headerlink\" title=\"注册&amp;发现\"></a>注册&amp;发现</h3><p>新节点加入时，elastic-job会把自己的ip和进程号主动写入zk的/<namespace>/<jobname>/instances/目录的<instanceid>临时节点下；节点退出时，zk在会话超时之后会把临时节点删除，也就是说某节点宕机后，最多要经过sessionTimeOut时间zk才能感知。</instanceid></jobname></namespace></p>\n<p>此外，elastic-job有RegistryCenterConnectionStateListener线程监听与zk的连接状态，当连接丢失时会调用scheduler.pauseAll()方法暂停所有job。为什么这样做？如果不这样做，节点A在下一个调度时刻到来时执行作业，而此时zk发现节点A失去连接，可能会对作业重新分片，节点A的分片被分配到了其它节点调度执行，造成重复执行，所以实质上这是一个处理节点脑裂的措施。</p>\n<p>当监听线程感知到zk重新连接了，会调用scheduler.resume()方法恢复调度。因此，如果zk挂掉，所有作业会暂停调度（不是暂停执行，正在执行的作业不会受影响，所以还是有可能重复执行），zk恢复后作业会重新恢复调度。</p>\n<h3 id=\"调度-amp-执行\"><a href=\"#调度-amp-执行\" class=\"headerlink\" title=\"调度&amp;执行\"></a>调度&amp;执行</h3><p>elastic-job中的JobScheduleController代理了quartz scheduler，调度能力由quartz提供。</p>\n<p>下面详细说明一下作业的执行过程。</p>\n<p><img src=\"作业执行过程.png\" alt=\"作业执行过程\"></p>\n<p>在调度周期到达时，首先校验本机与zk的时间误差是否在允许范围内，差值大于设定值<code>maxTimeDiffSeconds</code>会抛出异常。</p>\n<p>接着获取作业分片上下文，由于分片是由主节点负责分配的，所以如果此时发生选主，获取分片上下文操作会一直阻塞直到选主完成。</p>\n<p>接下来，根据zk中running节点是否存在判断当前是否有尚在运行中的作业，如果有，说明上次调度的作业仍未运行完成，发生了阻塞，这时会在zk中创建misfire节点，标识当前分片因阻塞而未被执行，等待下次调度执行。</p>\n<p>如果不存在尚在运行中的作业，那么执行作业逻辑。这里会根据作业分片数量是否为1来做不同的处理：如果只有1个分片，则使用单线程执行业务代码；如果多于1个分片，则使用线程池，并等待所有分片全部执行完后再统一返回。</p>\n<p>由于上次调度过程中可能有分片由于阻塞而未被执行，这次调度一并执行这些分片，并清楚misfire节点，标识misfire分片已被执行完毕。</p>\n<p>最后，如果设置了failover，则会执行失效转移逻辑（后面详细说明）。</p>\n<p>在整个作业执行的过程中，elastic-job对作业的状态、执行情况做了事件追踪。事件总线JobEventBus中注册了两种事件，分别是JobStatusTraceEvent和JobExecutionEvent，分别对应作业状态和触发来源。elastic-job会在作业执行过程中向事件总线实时发送事件追踪信息，JobEventBus接收追踪信息后会写入DB。</p>\n<h3 id=\"作业幂等\"><a href=\"#作业幂等\" class=\"headerlink\" title=\"作业幂等\"></a>作业幂等</h3><p>elastic-job可保证作业幂等，需要在LiteJobConfiguration中设置monitorExecution=true开启。下面看一下作业幂等是如何实现的。</p>\n<p>作业的执行需要以下步骤：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">registerJobBegin() <span class=\"comment\">//注册作业启动信息</span></div><div class=\"line\">...</div><div class=\"line\">process() <span class=\"comment\">//执行作业</span></div><div class=\"line\">...</div><div class=\"line\">registerJobCompleted() <span class=\"comment\">//注册作业完成信息</span></div></pre></td></tr></table></figure>\n<p>其中，process()会执行到作业的具体业务代码。registerJobBegin方法中，首先elastic-job更新内存中的作业状态为running，然后判断是否开启了monitorExecution，如果开启，就会向zk写入running临时节点，全局标示作业正在执行中。registerJobCompleted会在执行结束后，删除running节点，标示作业未在执行中。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// ExecutionService.java</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">registerJobBegin</span><span class=\"params\">(<span class=\"keyword\">final</span> ShardingContexts shardingContexts)</span> </span>&#123;</div><div class=\"line\">    JobRegistry.getInstance().setJobRunning(jobName, <span class=\"keyword\">true</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span> (!configService.load(<span class=\"keyword\">true</span>).isMonitorExecution()) &#123;</div><div class=\"line\">        <span class=\"keyword\">return</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> each : shardingContexts.getShardingItemParameters().keySet()) &#123;</div><div class=\"line\">        jobNodeStorage.fillEphemeralJobNode(ShardingNode.getRunningNode(each), <span class=\"string\">\"\"</span>);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">registerJobCompleted</span><span class=\"params\">(<span class=\"keyword\">final</span> ShardingContexts shardingContexts)</span> </span>&#123;</div><div class=\"line\">    JobRegistry.getInstance().setJobRunning(jobName, <span class=\"keyword\">false</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span> (!configService.load(<span class=\"keyword\">true</span>).isMonitorExecution()) &#123;</div><div class=\"line\">        <span class=\"keyword\">return</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> each : shardingContexts.getShardingItemParameters().keySet()) &#123;</div><div class=\"line\">        jobNodeStorage.removeJobNodeIfExisted(ShardingNode.getRunningNode(each));</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>临时节点running起到了分布式锁的作用，其它节点发现running就不会执行作业。</p>\n<p>但是，实现作业幂等是以与zk的频繁交互为代价的，如果作业的触发周期很短（如每5秒一触发）会造成running节点的频繁添加和删除，可能对性能影响较大，因此，monitorExecution不适合在短时间触发的作业中使用。</p>\n<h3 id=\"失效转移\"><a href=\"#失效转移\" class=\"headerlink\" title=\"失效转移\"></a>失效转移</h3><p>当作业节点执行作业异常崩溃时，其所分配的作业分片项在下次重新分片之前不会被重新执行。开启失效转移功能后，这部分作业分片项将被其他作业节点抓取后“执行”。</p>\n<p>所有节点会有JobCrashedJobListener监听器，监听同作业下，是否存在其它机器节点崩溃的情况。如何做到？zk中instances节点下记录了作业集群下的所有执行实例，如果某实例崩溃，zk会删除这个节点，其它节点通过监听是否有删除动作来判断节点是否崩溃。</p>\n<blockquote>\n<p>实际上，这样会把正常退出集群的节点视为崩溃进行处理。</p>\n</blockquote>\n<p>下面是失效转移的流程图：</p>\n<p><img src=\"失效转移.png\" alt=\"失效转移\"></p>\n<h3 id=\"主节点\"><a href=\"#主节点\" class=\"headerlink\" title=\"主节点\"></a>主节点</h3><p>主节点是作业维度的概念，例如集群有三个节点 <code>１</code>、<code>２</code>、<code>３</code>，存在两个作业 <code>a</code>、<code>b</code>，可能 <code>a</code> 作业的主节点是 <code>３</code>，<code>b</code> 作业的主节点是 <code>１</code>。</p>\n<p>elastic-job的选主过程使用了curator的LeaderLatch分布式锁。使用一个zk节点路径创建一个LeaderLatch，<code>start()</code> 后，调用 <code>await()</code> 等待拿到这把锁。如果有多个线程执行了相同节点路径的 LeaderLatch 的 <code>await()</code> 后，同一时刻有且仅有一个线程可以继续执行，其他线程需要等待。当该线程释放( <code>LeaderLatch.close()</code> )后，下一个线程可以拿到该锁继续执行。</p>\n<p><img src=\"LeaderLatch锁.png\" alt=\"LeaderLatch锁\"></p>\n<p>拿到锁成为主节点后执行回调，回调操作中，首先判断znode中是否已有/leader/election/instance节点，如果没有则把自己的instanceId写入instance节点，标志主节点选举完成。</p>\n<blockquote>\n<p>注意：主节点并不一定是作业的执行节点。</p>\n<p>在主节点执行的操作有：分配作业分片项、调解分布式作业不一致状态。</p>\n</blockquote>\n<h3 id=\"dump服务\"><a href=\"#dump服务\" class=\"headerlink\" title=\"dump服务\"></a>dump服务</h3><p>由于elastic-job是分布式架构，出现问题不易调试，为此提供了dump服务，打印调试信息。</p>\n<p>当作业本地 TreeCache缓存和zk数据不一致时，dump出[zkPath, zkValue, treeCachePath, treeCacheValue]。当相同时，只需 dump出[zkPath, zkValue]，方便看出本地和注册中心是否存在数据差异。</p>\n<p>除此之外，elastic-job留出接口，可以根据需求自定义调试命令。</p>\n<p>overwrite的bug: <a href=\"https://github.com/elasticjob/elastic-job-lite/issues/469\" target=\"_blank\" rel=\"external\">https://github.com/elasticjob/elastic-job-lite/issues/469</a></p>\n","categories":["Work"],"tags":["分布式","作业调度","elastic-job"]},{"title":"xxl-job实现分析","url":"/2018/12/xxl-job%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/","content":"<h2 id=\"xxl-job架构分析\"><a href=\"#xxl-job架构分析\" class=\"headerlink\" title=\"xxl-job架构分析\"></a>xxl-job架构分析</h2><h3 id=\"概览\"><a href=\"#概览\" class=\"headerlink\" title=\"概览\"></a>概览</h3><p>xxl-job整体上采用中心化调度的思想，将调度和执行完全解耦。调度中心专门进行任务的调度和下发，还提供了一个web console进行可视化的管理；执行器接收执行请求，专注于业务代码的执行。</p>\n<p><img src=\"概览.png\" alt=\"架构概览\"></p>\n<p>xxl-job的部署十分简单：调度中心是springboot项目，引入xxl-job-admin.jar和xxl-job-core.jar即可；执行器只需引入xxl-job-core.jar包。</p>\n<h3 id=\"注册-amp-发现\"><a href=\"#注册-amp-发现\" class=\"headerlink\" title=\"注册&amp;发现\"></a>注册&amp;发现</h3><p>由于xxl-job是中心化架构，每个执行器都知悉调度中心的地址，而调度中心并不能立即感知新加入或退出的执行器，因此“注册”是执行器的主动行为，“发现”是调度中心的被动行为。</p>\n<p><img src=\"注册发现.png\" alt=\"注册&amp;发现\"></p>\n<p>执行器启动后会起一个注册线程ExecutorRegistryThread，每30s向调度中心发送注册心跳，这是个rpc调用（xxl-job提供了简单的rpc框架，其底层通信协议是http）。调度中心收到请求后解析XxlRpcRequest，校验通信accessToken，解析出执行的方法名和参数，进行反射调用执行注册操作。XXL_JOB_QRTZ_TRIGGER_REGISTRY表维护了所有注册过的执行器信息，包括执行器ip、所属AppName、注册类型、注册时间等，调度中心有个注册监控daemon线程，定期扫描这张表，删除所有注册时间在90s之前的记录，所以说REGISTRY表实际上维护了所有online执行器的信息。</p>\n<h3 id=\"任务触发\"><a href=\"#任务触发\" class=\"headerlink\" title=\"任务触发\"></a>任务触发</h3><p>任务触发有两种方式：</p>\n<ul>\n<li>调度触发：调度周期自动触发执行</li>\n<li>手动触发：控制台手动强制触发执行</li>\n</ul>\n<p>无论哪种方式，都是通过调度中心的JobTriggerPoolHelper触发线程池触发执行的。</p>\n<p><img src=\"任务触发流程.png\" alt=\"任务触发流程\"></p>\n<p>（jobInfo在表XXL_JOB_QRTZ_TRIGGER_LOG，jobGroup在表XXL_JOB_QRTZ_TRIGGER_GROUP）</p>\n<p>jobInfo包含jobId、路由策略、对应的业务类名称、重试次数等，jobGroup包含job对应的组（即AppName），调度中心根据路由策略确定执行器的ip地址后，封装调度请求，丢进线程池执行。</p>\n<p>调度请求中的触发参数举例如下：</p>\n<figure class=\"highlight\"><table><tr><td class=\"code\"><pre><div class=\"line\">TriggerParam &#123;</div><div class=\"line\">\t  jobId = 2, </div><div class=\"line\">\t  executorHandler = 'demoJobHandler', </div><div class=\"line\">\t  executorParams = '', </div><div class=\"line\">\t  executorBlockStrategy = 'SERIAL_EXECUTION', </div><div class=\"line\">\t  executorTimeout = 0, </div><div class=\"line\">\t  logId = 97, </div><div class=\"line\">\t  logDateTim = 1543392370996, </div><div class=\"line\">\t  glueType = 'BEAN', </div><div class=\"line\">\t  glueSource = '', </div><div class=\"line\">\t  glueUpdatetime = 1542701641000, </div><div class=\"line\">\t  broadcastIndex = 0, </div><div class=\"line\">\t  broadcastTotal = 1</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>执行器收到调度请求后，解析出执行具体任务的业务类名，在此例中就是’demoJobHandler’。执行器根据类名找到执行该业务类的线程实例，如何找到？执行器在启动初始化时，扫描所有@JobHandler注解的业务类，为每个业务类创建一个专用的jobThread，然后把业务类和jobThread的对应关系记录在全局的hashmap中，这样根据类名即可找到对应线程。</p>\n<p><img src=\"触发队列和回调队列.png\" alt=\"触发队列和回调队列\"></p>\n<p>我们知道，1个执行器中有n种job类型，每种job对应1个专用jobThread，这个jobThread会把执行请求push到触发队列triggerQueue中；执行器还有一个全局的回调线程callbackThread，对应一个全局的回调队列callbackQueue。jobThread每次从triggerQueue捞取任务触发请求，执行业务类（比如demoJobHandler）的execute方法执行业务代码，将执行结果push到callbackQueue中；callbackThread从队列捞取执行结果，向调度中心回调（rpc调用调度中心的callback方法）执行结果。xxl-job这样就实现了任务执行和结果返回的异步化。</p>\n<h3 id=\"路由策略\"><a href=\"#路由策略\" class=\"headerlink\" title=\"路由策略\"></a>路由策略</h3><p>xxl-job提供了丰富的路由策略，包括第一个、最后一个、轮询、随机、一致性HASH、最不经常使用、最近最久未使用、故障转移、忙碌转移等。这里着重说明故障转移和忙碌转移。</p>\n<h5 id=\"故障转移\"><a href=\"#故障转移\" class=\"headerlink\" title=\"故障转移\"></a>故障转移</h5><p>设置路由策略为故障转移后，调度中心在触发任务之前，会向任务对应的所有执行器循环发送探活请求，收到某执行器的OK响应后就确定将该执行器作为这次任务的执行机器。</p>\n<h5 id=\"忙碌转移\"><a href=\"#忙碌转移\" class=\"headerlink\" title=\"忙碌转移\"></a>忙碌转移</h5><p>与故障转移类似，调度中心触发任务之前，向所有执行器循环发送请求，询问执行器是否忙碌，选择不忙碌的执行器作为任务的执行机器（执行器通过判断自身triggerQueue是否为空来返回是否忙碌）。</p>\n<h3 id=\"失败报警-amp-失败重试\"><a href=\"#失败报警-amp-失败重试\" class=\"headerlink\" title=\"失败报警&amp;失败重试\"></a>失败报警&amp;失败重试</h3><p>调度中心有一个失败监控deamon线程monitorThread，监控失败的job，其逻辑图如下。</p>\n<p><img src=\"失败监控逻辑.png\" alt=\"失败监控逻辑\"></p>\n<p>触发线程池每次触发任务时，首先会在表XXL_JOB_QRTZ_TRIGGER_LOG中新增一条jobLog记录，即为调度日志，初始其handleCode=0；任务触发后，会把这次任务对应的jobLogId写入队列queue。失败监控线程每10s把queue中所有jobLogId取出，并写入一个ArrayList。接着从db查询jobLog信息，如果其handleCode=200（回调服务收到执行器的执行成功响应时会把handleCode更新为200，失败更新为500），说明任务执行成功；如果handleCode=0，说明还未收到回调，将jobLogId写入队列表明此job会被继续监控；如果handleCode=500，说明失败，这时就会触发失败报警，如果设置了重试，还会重新进入触发线程池重新调度执行。</p>\n<h3 id=\"日志管理\"><a href=\"#日志管理\" class=\"headerlink\" title=\"日志管理\"></a>日志管理</h3><p>xxl-job中的日志分类两类：</p>\n<ul>\n<li>调度日志</li>\n<li>执行日志</li>\n</ul>\n<p>调度日志存储在调度中心侧，对应db表为XXL_JOB_QRTZ_TRIGGER_LOG。</p>\n<p>执行日志存储在执行器侧的日志存放路径中，执行器会有一个日志清理线程根据配置的rolling策略清理、压缩日志。</p>\n<p>为了能够在Web Console看到执行日志，执行器开放了日志查询接口，用户点击按钮后拉取执行日志，从而在前端展示。</p>\n","categories":["Work"],"tags":["分布式","作业调度"]},{"title":"dns解析过程抓包分析","url":"/2018/10/dns%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90/","content":"<h2 id=\"dig-trace抓包分析：\"><a href=\"#dig-trace抓包分析：\" class=\"headerlink\" title=\"dig +trace抓包分析：\"></a>dig +trace抓包分析：</h2><p>dig +trace [hostname]命令从根服务器开始追踪一个域名的解析过程,下面结合命令输出以及wireshark抓包分析执行dig +trace命令后究竟发生了哪些事情。</p>\n<p>dig +trace www.baidu.com 抓包结果：</p>\n<p>以www.baidu.com为例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">-&gt; dig +trace www.baidu.com</div><div class=\"line\"></div><div class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.9.5-3-Ubuntu &lt;&lt;&gt;&gt; +trace www.baidu.com</div><div class=\"line\"></div><div class=\"line\">;; global options: +cmd</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\tl.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\tj.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\tf.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\tc.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\td.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\th.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\tb.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\ta.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\tk.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\te.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\tm.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\tg.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t156084\tIN\tNS\ti.root-servers.net.</div><div class=\"line\"></div><div class=\"line\">.\t\t\t85383\tIN\tRRSIG\tNS 8 0 518400 20181007220000 20180924210000 41656 . V7zlNRZHj4pGVdIoAWXtaF3K8JflOlAY/2XRcaKFgrwNSrpOM9q8E2kX fJg3wNvdlE8Ebkboi5fTe31u6W/WGeKLY8QiHoDbco9jwy3U/af3mfFq UMZq2Zvs8ekUutUSCNenxUD2OTGsweA8VP5+qjcuuWEonEYm2ITRtiWv eFH0GFYeiB+5PBQL27XtwNUEN2EYKTRw22sADXUy/UCkawpyY+YKjKCf iIe/7wrF8bgbfA6oS7k9xORVA8/wZpTTYc5Q0VwsLbX5Ifz3NzbrjBCT 29oKepzR8R6VFmgaAdMwKVod5k2lGsB6nrTwn4PBFfwRTkK4xgu0e+Xn hxxh8w==</div><div class=\"line\"></div><div class=\"line\">;; Received 1111 bytes from 127.0.1.1#53(127.0.1.1) in 88 ms</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\ta.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\tb.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\tc.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\td.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\te.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\tf.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\tg.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\th.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\ti.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\tj.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\tk.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\tl.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t172800\tIN\tNS\tm.gtld-servers.net.</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t86400\tIN\tDS\t30909 8 2 E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CF C41A5766</div><div class=\"line\"></div><div class=\"line\">com.\t\t\t86400\tIN\tRRSIG\tDS 8 1 86400 20181008050000 20180925040000 41656 . 6dL3cyu8gI6F4PhxK+M2n1Yltj8ojeBpRFTqALwjcajEu4rRURBdvDYU M2WjdBitsXxXuHt081G69i7yzshhs+z29EHGPXG/NM681FVaV/WKm7r3 Kse2w3REQQS2jLeoFT/C0LT72djwHSNRYxGq3H0dJ1kuLbbjnEg144KN CS1tqbHNRXGQNjVsvGAopZwOKSRHXcI1ypenr58tPwxe8uBr1mWu5C9x O+UC7GR9VWhokCFm1QqgHX4Y3OnIvgB1+Ih2uCdjBt/t6cUTnPD9VOof A0kWd7AUE6Ac9dwARse2UqywbOqPM/7r1LI3d4YXqnF/gUAni3x8tHvh IWhxtg==</div><div class=\"line\"></div><div class=\"line\">;; Received 1173 bytes from 198.41.0.4#53(a.root-servers.net) in 263 ms</div><div class=\"line\"></div><div class=\"line\">baidu.com.\t\t172800\tIN\tNS\tdns.baidu.com.</div><div class=\"line\"></div><div class=\"line\">baidu.com.\t\t172800\tIN\tNS\tns2.baidu.com.</div><div class=\"line\"></div><div class=\"line\">baidu.com.\t\t172800\tIN\tNS\tns3.baidu.com.</div><div class=\"line\"></div><div class=\"line\">baidu.com.\t\t172800\tIN\tNS\tns4.baidu.com.</div><div class=\"line\"></div><div class=\"line\">baidu.com.\t\t172800\tIN\tNS\tns7.baidu.com.</div><div class=\"line\"></div><div class=\"line\">CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN NSEC3 1 1 0 - CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAM</div><div class=\"line\"></div><div class=\"line\">CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN RRSIG NSEC3 8 2 86400 20180929044218 20180922033218 46475 com. KFoD2muDMMl8m5+W8I2hXz7JhFlPdju7sxXLsHT5FNNX2EHVxB3WE8aq CbSSg8Uw6PJ5+bfjU7OcMDaw5um0QBhsJzaom03jqDtsUTYbpg4+NE4l NyieExXWz8EToYtBsyHFEWWYyrBbejHHoBw2Ubn3xTrV+rQ4YDE2x3Zy aRY=</div><div class=\"line\"></div><div class=\"line\">HPVV2B5N85O7HJJRB7690IB5UVF9O9UA.com. 86400 IN NSEC3 1 1 0 - HPVVP23QUO0FP9R0A04URSICJPESKO9J NS DS RRSIG</div><div class=\"line\"></div><div class=\"line\">HPVV2B5N85O7HJJRB7690IB5UVF9O9UA.com. 86400 IN RRSIG NSEC3 8 2 86400 20180930150114 20180923135114 46475 com. 1i+9CFd2kIT+a9/qIQLqdvIiunU3fY+FXuwoqqCzIsyN6T+OBjFj19/i rgbD5R0s+3yY9t3pcZeNx1dyAhJPpOvN6S/48+1BupOYyS4HzhRSPQj9 SrbCQxght6VBBF19B0gXgT5pX95QiqNq1Ai5o2FVQBuwufP6I1odnEKd kXQ=</div><div class=\"line\"></div><div class=\"line\">;; Received 697 bytes from 192.55.83.30#53(m.gtld-servers.net) in 235 ms</div><div class=\"line\"></div><div class=\"line\">www.baidu.com.\t\t1200\tIN\tCNAME\twww.a.shifen.com.</div><div class=\"line\"></div><div class=\"line\">a.shifen.com.\t\t1200\tIN\tNS\tns2.a.shifen.com.</div><div class=\"line\"></div><div class=\"line\">a.shifen.com.\t\t1200\tIN\tNS\tns5.a.shifen.com.</div><div class=\"line\"></div><div class=\"line\">a.shifen.com.\t\t1200\tIN\tNS\tns3.a.shifen.com.</div><div class=\"line\"></div><div class=\"line\">a.shifen.com.\t\t1200\tIN\tNS\tns4.a.shifen.com.</div><div class=\"line\"></div><div class=\"line\">a.shifen.com.\t\t1200\tIN\tNS\tns1.a.shifen.com.</div><div class=\"line\"></div><div class=\"line\">;; Received 239 bytes from 220.181.37.10#53(ns3.baidu.com) in 67 ms</div></pre></td></tr></table></figure>\n<p>从dig +trace的输出结果来看，整个过程可以被分成四个部分：</p>\n<p>(1)从本地服务dnsmasq(127.0.1.1:53)得到13台根域名服务器的地址，耗时88ms</p>\n<p>(2)从其中一台根域名服务器(a.root-servers.net)得到13台通用顶级域名.com服务器的地址，耗时263ms</p>\n<p>(3)从其中一台.com域名服务器(m.gtld-servers.net)得到5台二级域名baidu.com服务器地址，耗时235ms</p>\n<p>(4)从其中一台baidu.com域名服务器(ns3.baidu.com)得知所查域名www.baidu.com的别名为www.a.shifen.com，进而得知5台三级域名a.shifen.com服务器的地址，耗时67ms</p>\n<p>下面通过wireshark对上述过程的抓包结果，来分析究竟发生了什么。</p>\n<p>首先看第一阶段：</p>\n<p>dnsmasq是linux本地的一个提供dns服务的进程，即local dns。如果ps -ef | grep dnsmasq的话会看到–listen-address=127.0.1.1，再用netstat查看端口会看到53端口，这说明dnsmasq进程监听本地回环地址127.0.1.1的53号端口</p>\n<p><img src=\"dnsmasq.png\" alt=\"img\"></p>\n<p>如下图所示，10.242.52.179是本机ip。为了得到www.baidu.com的ip地址，我们首先需要知道根域名服务器的地址，因此dnsmasq进程对外询问局域网内的DNS服务器，在这里是10.246.3.3[1-4]；我们分别向四台DNS服务器发送了一条DNS query，询问<root>跟域名服务器的ip地址；可以看到，我们接受了10.246.3.33的DNS response，与此同时拒绝了其他三台DNS服务器的应答；10.246.3.33这台机器它说它有13台根域名服务器，你想用哪台都行，丢给我们13台服务器的域名；我们拿到一堆域名一脸懵逼，因为我们并不知道它们的ip地址，于是不得不再向DNS服务器询问，老兄你刚才给我的13个根域名的ip地址都是啥啊？DNS服务器对我们有求必应，不仅告诉我们ipv4地址(A记录)，还告诉我们ipv6地址(AAAA记录)。</root></p>\n<p>第一阶段结束。</p>\n<p><img src=\"first period.png\" alt=\"img\"></p>\n<p>再看第二阶段：</p>\n<p>拿到了13个根域名服务器的ip地址后，我们选择了其中一个：a.root-servers.net(192.55.83.30)，下面我们向这台服务器询问com顶级域名服务器的地址。</p>\n<p><img src=\"second period.png\" alt=\"img\"></p>\n<p>再看第三阶段：</p>\n<p>我们选择了m.gtld-servers.net顶级域名服务器，对应ip为192.55.83.30，向它询问baidu.com域名服务器的地址。</p>\n<p><img src=\"third period.png\" alt=\"img\"></p>\n<p>最后看第四阶段：</p>\n<p>我们选择了ns3.baidu.com域名服务器，对应ip为220.181.37.10，向他询问www.baidu.com的ip地址。然而，域名服务器在它的dns记录表中发现，www.baidu.com对应的记录是一条CNAME记录，其CNAME别名为www.a.shifen.com</p>\n<p><img src=\"fourth period.png\" alt=\"img\"></p>\n<p>与此同时，ns3.baidu.com这台域名服务器还告诉我们a.shifen.com域名服务器有5个，分别是ns[1-5].a.shifen.com，这样就不用我们拿着www.a.shifen.com再从根域名服务器、.com服务器、.shifen.com费尽周折地查找了。</p>\n<p><img src=\"fourth period%201.png\" alt=\"img\"></p>\n<p>最后，我们向ns[1-5].a.shifen.com中的任意一台机器询问www.a.shifen.com的ip地址，得到的也就是www.baidu.com的ip地址了。</p>\n<h2 id=\"CNAME和A记录：\"><a href=\"#CNAME和A记录：\" class=\"headerlink\" title=\"CNAME和A记录：\"></a>CNAME和A记录：</h2><p>A(Address)记录把主机名或域名映射到IP地址，实现了域名到IP的关联</p>\n<p>CNAME(Canonical NAME)是别名记录，就是将一个或多个主机名或域名映射到另一个域名</p>\n<p>举个例子：有一台主机名为host.example.com的服务器，其对外ip为10.110.72.29；服务器提供了门户网站和邮箱两个服务，我们希望用户通过地址www.example.com和mail.example.com分别访问两个服务，那么DNS应该这样记录：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">+------------------+-------+------------------+</div><div class=\"line\">| host.example.com | A     | 10.110.72.29     |</div><div class=\"line\">+------------------+-------+------------------+</div><div class=\"line\">| www.example.com  | CNAME | host.example.com |</div><div class=\"line\">+------------------+-------+------------------+</div><div class=\"line\">| mail.example.com | CNAME | host.example.com |</div><div class=\"line\">+------------------+-------+------------------+</div></pre></td></tr></table></figure>\n<p>这样的话，www和mail服务其实都是指向了同一个ip，当主机的ip地址变更时，只需更改A记录即可。</p>\n<h2 id=\"jdk中DNS解析过程：\"><a href=\"#jdk中DNS解析过程：\" class=\"headerlink\" title=\"jdk中DNS解析过程：\"></a>jdk中DNS解析过程：</h2><p>java的DNS解析过程在java.net包下的InetAddress类中完成，核心代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> HashMap&lt;String, Void&gt; lookupTable = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> InetAddress[] getAddressesFromNameService(String host, InetAddress reqAddr)</div><div class=\"line\">        <span class=\"keyword\">throws</span> UnknownHostException</div><div class=\"line\">    &#123;</div><div class=\"line\">        InetAddress[] addresses = <span class=\"keyword\">null</span>;</div><div class=\"line\">        <span class=\"keyword\">boolean</span> success = <span class=\"keyword\">false</span>;</div><div class=\"line\">        UnknownHostException ex = <span class=\"keyword\">null</span>;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\">// Check whether the host is in the lookupTable.</span></div><div class=\"line\">        <span class=\"comment\">// 1) If the host isn't in the lookupTable when</span></div><div class=\"line\">        <span class=\"comment\">//    checkLookupTable() is called, checkLookupTable()</span></div><div class=\"line\">        <span class=\"comment\">//    would add the host in the lookupTable and</span></div><div class=\"line\">        <span class=\"comment\">//    return null. So we will do the lookup.</span></div><div class=\"line\">        <span class=\"comment\">// 2) If the host is in the lookupTable when</span></div><div class=\"line\">        <span class=\"comment\">//    checkLookupTable() is called, the current thread</span></div><div class=\"line\">        <span class=\"comment\">//    would be blocked until the host is removed</span></div><div class=\"line\">        <span class=\"comment\">//    from the lookupTable. Then this thread</span></div><div class=\"line\">        <span class=\"comment\">//    should try to look up the addressCache.</span></div><div class=\"line\">        <span class=\"comment\">//     i) if it found the addresses in the</span></div><div class=\"line\">        <span class=\"comment\">//        addressCache, checkLookupTable()  would</span></div><div class=\"line\">        <span class=\"comment\">//        return the addresses.</span></div><div class=\"line\">        <span class=\"comment\">//     ii) if it didn't find the addresses in the</span></div><div class=\"line\">        <span class=\"comment\">//         addressCache for any reason,</span></div><div class=\"line\">        <span class=\"comment\">//         it should add the host in the</span></div><div class=\"line\">        <span class=\"comment\">//         lookupTable and return null so the</span></div><div class=\"line\">        <span class=\"comment\">//         following code would do  a lookup itself.</span></div><div class=\"line\">        <span class=\"keyword\">if</span> ((addresses = checkLookupTable(host)) == <span class=\"keyword\">null</span>) &#123;</div><div class=\"line\">            <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">                <span class=\"comment\">// This is the first thread which looks up the addresses</span></div><div class=\"line\">                <span class=\"comment\">// this host or the cache entry for this host has been</span></div><div class=\"line\">                <span class=\"comment\">// expired so this thread should do the lookup.</span></div><div class=\"line\">                <span class=\"keyword\">for</span> (NameService nameService : nameServices) &#123;</div><div class=\"line\">                    <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">                        <span class=\"comment\">/*</span></div><div class=\"line\">                         * Do not put the call to lookup() inside the</div><div class=\"line\">                         * constructor.  if you do you will still be</div><div class=\"line\">                         * allocating space when the lookup fails.</div><div class=\"line\">                         */</div><div class=\"line\"></div><div class=\"line\">                        addresses = nameService.lookupAllHostAddr(host);</div><div class=\"line\">                        success = <span class=\"keyword\">true</span>;</div><div class=\"line\">                        <span class=\"keyword\">break</span>;</div><div class=\"line\">                    &#125; <span class=\"keyword\">catch</span> (UnknownHostException uhe) &#123;</div><div class=\"line\">                        <span class=\"keyword\">if</span> (host.equalsIgnoreCase(<span class=\"string\">\"localhost\"</span>)) &#123;</div><div class=\"line\">                            InetAddress[] local = <span class=\"keyword\">new</span> InetAddress[] &#123; impl.loopbackAddress() &#125;;</div><div class=\"line\">                            addresses = local;</div><div class=\"line\">                            success = <span class=\"keyword\">true</span>;</div><div class=\"line\">                            <span class=\"keyword\">break</span>;</div><div class=\"line\">                        &#125;</div><div class=\"line\">                        <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">                            addresses = unknown_array;</div><div class=\"line\">                            success = <span class=\"keyword\">false</span>;</div><div class=\"line\">                            ex = uhe;</div><div class=\"line\">                        &#125;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\"></div><div class=\"line\">                <span class=\"comment\">// More to do?</span></div><div class=\"line\">                <span class=\"keyword\">if</span> (reqAddr != <span class=\"keyword\">null</span> &amp;&amp; addresses.length &gt; <span class=\"number\">1</span> &amp;&amp; !addresses[<span class=\"number\">0</span>].equals(reqAddr)) &#123;</div><div class=\"line\">                    <span class=\"comment\">// Find it?</span></div><div class=\"line\">                    <span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;</div><div class=\"line\">                    <span class=\"keyword\">for</span> (; i &lt; addresses.length; i++) &#123;</div><div class=\"line\">                        <span class=\"keyword\">if</span> (addresses[i].equals(reqAddr)) &#123;</div><div class=\"line\">                            <span class=\"keyword\">break</span>;</div><div class=\"line\">                        &#125;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                    <span class=\"comment\">// Rotate</span></div><div class=\"line\">                    <span class=\"keyword\">if</span> (i &lt; addresses.length) &#123;</div><div class=\"line\">                        InetAddress tmp, tmp2 = reqAddr;</div><div class=\"line\">                        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt; i; j++) &#123;</div><div class=\"line\">                            tmp = addresses[j];</div><div class=\"line\">                            addresses[j] = tmp2;</div><div class=\"line\">                            tmp2 = tmp;</div><div class=\"line\">                        &#125;</div><div class=\"line\">                        addresses[i] = tmp2;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">                <span class=\"comment\">// Cache the address.</span></div><div class=\"line\">                cacheAddresses(host, addresses, success);</div><div class=\"line\"></div><div class=\"line\">                <span class=\"keyword\">if</span> (!success &amp;&amp; ex != <span class=\"keyword\">null</span>)</div><div class=\"line\">                    <span class=\"keyword\">throw</span> ex;</div><div class=\"line\"></div><div class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</div><div class=\"line\">                <span class=\"comment\">// Delete host from the lookupTable and notify</span></div><div class=\"line\">                <span class=\"comment\">// all threads waiting on the lookupTable monitor.</span></div><div class=\"line\">                updateLookupTable(host);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> addresses;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> InetAddress[] checkLookupTable(String host) &#123;</div><div class=\"line\">        <span class=\"keyword\">synchronized</span> (lookupTable) &#123;</div><div class=\"line\">            <span class=\"comment\">// If the host isn't in the lookupTable, add it in the</span></div><div class=\"line\">            <span class=\"comment\">// lookuptable and return null. The caller should do</span></div><div class=\"line\">            <span class=\"comment\">// the lookup.</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (lookupTable.containsKey(host) == <span class=\"keyword\">false</span>) &#123;</div><div class=\"line\">                lookupTable.put(host, <span class=\"keyword\">null</span>);</div><div class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            <span class=\"comment\">// If the host is in the lookupTable, it means that another</span></div><div class=\"line\">            <span class=\"comment\">// thread is trying to look up the addresses of this host.</span></div><div class=\"line\">            <span class=\"comment\">// This thread should wait.</span></div><div class=\"line\">            <span class=\"keyword\">while</span> (lookupTable.containsKey(host)) &#123;</div><div class=\"line\">                <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">                    lookupTable.wait();</div><div class=\"line\">                &#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\">// The other thread has finished looking up the addresses of</span></div><div class=\"line\">        <span class=\"comment\">// the host. This thread should retry to get the addresses</span></div><div class=\"line\">        <span class=\"comment\">// from the addressCache. If it doesn't get the addresses from</span></div><div class=\"line\">        <span class=\"comment\">// the cache, it will try to look up the addresses itself.</span></div><div class=\"line\">        InetAddress[] addresses = getCachedAddresses(host);</div><div class=\"line\">        <span class=\"keyword\">if</span> (addresses == <span class=\"keyword\">null</span>) &#123;</div><div class=\"line\">            <span class=\"keyword\">synchronized</span> (lookupTable) &#123;</div><div class=\"line\">                lookupTable.put(host, <span class=\"keyword\">null</span>);</div><div class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> addresses;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">updateLookupTable</span><span class=\"params\">(String host)</span> </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">synchronized</span> (lookupTable) &#123;</div><div class=\"line\">            lookupTable.remove(host);</div><div class=\"line\">            lookupTable.notifyAll();</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<p>拿到一个host，首先会调用getCachedAddresses方法查缓存（缓存由LinkedHashMap实现），命中缓存则返回地址，未命中则调用getAddressesFromNameService方法查询name server。在查询name server之前，该方法会检查lookupTable（一个HashMap）。如果table中已经存在key为hostname的记录，说明此时另外一个线程正在对该host进行查询，那么当前线程就会等待，直到host记录被删除，也就是说另一个线程完成了对host的查询并更新了缓存，正常情况下此时缓存中已经有该条host的记录了，因此当前线程就没有必要自己查询name server，从缓存中取即可，但是特殊情况下无法命中缓存，那么当前线程需要将键值对<host, null=\"\">放入lookupTable，标志其正在进行查询，遍历所有已知的name server，找到host对应的地址后，更新缓存、删除lookupTable中的记录，最后返回查到的地址。</host,></p>\n<p>上面提到，java查询DNS后会有缓存，具体缓存多久的时间与jvm security policy的配置相关。通过下面两个参数可以控制DNS解析结果的缓存时间：</p>\n<p><strong>networkaddress.cache.ttl</strong>（default: -1）# 设置缓存解析成功的时间</p>\n<blockquote>\n<p>Specified in java.security to indicate the caching policy for successful name lookups from the name service. The value is specified as as integer to indicate the number of seconds to cache the successful lookup.<br>A value of -1 indicates cache forever. The default behavior is to cache forever when a security manager is installed, and to cache for an implementation specific period of time, when a security manager is not installed.</p>\n</blockquote>\n<p><strong>networkaddress.cache.negative.ttl</strong> (default: 10) # 设置缓存解析失败的时间</p>\n<blockquote>\n<p>Indicates the caching policy for un-successful name lookups from the name service. The value is specified as as integer to indicate the number of seconds to cache the failure for un-successful lookups. A value of 0 indicates never cache. A value of -1 indicates cache forever.</p>\n</blockquote>\n<p>以上两个参数可在<code>${java.home}/jre/lib/security/java.security</code>中配置，或者也可以在代码中进行配置：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">java.security.Security.setProperty(networkaddress.cache.ttl, <span class=\"number\">60</span>);</div></pre></td></tr></table></figure>","categories":["Work"],"tags":["DNS","抓包"]},{"title":"ddb架构和坑","url":"/2018/10/ddb%E6%9E%B6%E6%9E%84%E5%92%8C%E5%9D%91/","content":"<h2 id=\"DDB架构\"><a href=\"#DDB架构\" class=\"headerlink\" title=\"DDB架构\"></a>DDB架构</h2><h3 id=\"老架构\"><a href=\"#老架构\" class=\"headerlink\" title=\"老架构\"></a>老架构</h3><p><img src=\"old arch.png\" alt=\"老架构\"></p>\n<p>应用层app通过DBI驱动来访问DDB，与大多数驱动一样，DBI提供了访问DDB的各种接口。与mysql官方提供的Standard jdbc Connector/J不同，DBI首先会接收应用app的sql，通过解析器生成抽象语法树，再根据语法树生成分布式执行计划，然后通过jdbc驱动将执行计划下发给数据节点dbn，各节点执行sql通过mysql通信协议将结果返回，最后在DBI层进行结果的聚合并返回给应用层。</p>\n<p>该架构有以下缺点：</p>\n<ul>\n<li>由于语法解析、执行计划的生成都发生在应用服务器，一定程度上消耗了应用服务器的资源</li>\n<li>DBI通过打包成db.jar为供应用端所使用，DDB的升级需要重新打包，这就导致每次DDB升级都需要应用停服重启才能生效，给运维工作带来困难，造成的问题就是各个产品线使用不同版本的DDB</li>\n<li>由于 DBI 部署在应用端,每次应用重启都会伴随着 DBI 模块的重启,由于 DBI 内<br>部维护了一些文件锁,瞬间重启可能由于操作系统的文件锁没来得及释放而抛异<br>常,</li>\n</ul>\n<h3 id=\"新架构\"><a href=\"#新架构\" class=\"headerlink\" title=\"新架构\"></a>新架构</h3><p><img src=\"new arch.png\" alt=\"新架构\"></p>\n<p>为了解决上述问题，实现DBI与应用层的解耦，DBA团队开发了QS模式。该模式单独抽出了一个QS层，通常一个应用对应对个QS节点。QS实现了mysql标准jdbc驱动到DBI驱动的转换，语法解析、执行计划的生成都在QS服务器上完成，为应用服务器减轻压力的同时，实现了与应用层的解耦，可以做到对应用层的无感知升级。另外，QS与应用服务器的交互完全采用标准mysql通信协议，应用层的语言不再限制为java。</p>\n<h3 id=\"全局自增ID\"><a href=\"#全局自增ID\" class=\"headerlink\" title=\"全局自增ID\"></a>全局自增ID</h3><p>DDB不支持全局ID的单调递增！！</p>\n<p>提供两种自增ID的分配方式：</p>\n<ul>\n<li>USB: User Sequence Based<ul>\n<li>通过数据库批量申请ID，默认一次1K个</li>\n<li>优点：实现简单，满足大多数应用场景</li>\n<li>缺点：依赖数据库，自增性不是很好</li>\n</ul>\n</li>\n<li>TSB: Time Sequence Based<ul>\n<li>依赖QS时间戳生成全局ID</li>\n<li>优点：自增性较好，不依赖数据库</li>\n<li>缺点：字段太长，应用支持不是很好</li>\n</ul>\n</li>\n</ul>\n<p>我们通常使用USB。假设应用层对应两个QS节点QSa和QSb，采用USB模式时，QSa和QSb会各自预申请1000个ID，假设QSa申请到1~1000，QSb申请到1001~2000。我们每次insert一条数据时，会向QS申请分配一个ID，如果请求分配给QSa，那么QSa会从它的ID池中递增地拿出一个ID，类似地请求分配到QSb时，QSb会从1001~2000中拿出尚未分配出去的最小ID。因此，整体上ID有增长的趋势，但并非严格单调递增。</p>\n<h3 id=\"均衡字段实现分库\"><a href=\"#均衡字段实现分库\" class=\"headerlink\" title=\"均衡字段实现分库\"></a>均衡字段实现分库</h3><p>DDB通过均衡字段BF实现分库，每张表设定一个均衡字段，表数据根据一定的分区策略存储到不同的dbn节点上</p>\n<p>DDB分区策略：%n (n=桶个数) + 二级映射</p>\n<p>按照下图决定将数据存储到哪一个节点上：</p>\n<p><img src=\"bf.png\" alt=\"均衡字段\"></p>\n<p>这里的bucket是一个逻辑上的概念，它与物理节点的映射关系可以进行动态调整，这样的话增加或减少物理节点不会影响到均衡字段与桶的映射关系，方便动态扩容和缩容。</p>\n<p>这种方案的一个特点就是数据分布情况取决于均衡字段的选择和hash函数的选取。举个例子，如果选取时间作为均衡字段，且hash函数就是简单地取模操作，那么这种方案适用于数据关于时间均匀分布的场景，数据会均匀地分布到各个节点上；但是如果某段时间内线上数据激增，那么大量的数据可能会汇聚到同一个节点上，增加了该节点的负荷。</p>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><p>由于DDB是分布式数据库，在使用offset时要格外慎重。比如sql语句：select * from vcloud_vod_video limit 10 offset 1000，下发到每个dbn节点时，每个节点都会limit 1010，即limit+offset。过大的offset会直接导致慢sql，甚至导致OOM</p>\n","categories":["Work"],"tags":["分布式数据库"]},{"title":"Spring注解Resource和Autowired区别对比","url":"/2018/08/Spring%E6%B3%A8%E8%A7%A3Resource%E5%92%8CAutowired%E5%8C%BA%E5%88%AB%E5%AF%B9%E6%AF%94/","content":"<p>@Resource和@Autowired都是做bean的注入时使用，其实@Resource并不是Spring的注解，它的包是javax.annotation.Resource，需要导入，但是Spring支持该注解的注入。</p>\n<h3 id=\"共同点\"><a href=\"#共同点\" class=\"headerlink\" title=\"共同点\"></a>共同点</h3><p>两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。</p>\n<h3 id=\"不同点\"><a href=\"#不同点\" class=\"headerlink\" title=\"不同点\"></a>不同点</h3><h4 id=\"Autowired\"><a href=\"#Autowired\" class=\"headerlink\" title=\"@Autowired\"></a>@Autowired</h4><p>@Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。</p>\n<p><img src=\"https://ss0.baidu.com/6ONWsjip0QIZ8tyhnq/it/u=2195010768,3429289948&amp;fm=173&amp;app=25&amp;f=JPEG?w=401&amp;h=263&amp;s=E0D2A164DAEC976C54D5458F0000E082\" alt=\"img\"></p>\n<p>@Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。如下：</p>\n<p><img src=\"https://ss0.baidu.com/6ONWsjip0QIZ8tyhnq/it/u=1835858463,553867819&amp;fm=173&amp;app=25&amp;f=JPEG?w=400&amp;h=124&amp;s=B8C2A544CFA4BD725E79858F0000E0C2\" alt=\"img\"></p>\n<h3 id=\"Resource\"><a href=\"#Resource\" class=\"headerlink\" title=\"@Resource\"></a>@Resource</h3><p>@Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。</p>\n<p>所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。</p>\n<p><img src=\"https://ss1.baidu.com/6ONXsjip0QIZ8tyhnq/it/u=1198233895,1119089040&amp;fm=173&amp;app=25&amp;f=JPEG?w=401&amp;h=257&amp;s=B0D7A1641AE48D6C14C5458B0000E08A\" alt=\"img\"></p>\n<p>注：最好是将@Resource放在setter方法上，因为这样更符合面向对象的思想，通过set、get去操作属性，而不是直接去操作属性。</p>\n<p>@Resource装配顺序：</p>\n<p>①如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常。</p>\n<p>②如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常。</p>\n<p>③如果指定了type，则从上下文中找到类似匹配的唯一bean进行装配，找不到或是找到多个，都会抛出异常。</p>\n<p>④如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。</p>\n<p>@Resource的作用相当于@Autowired，只不过@Autowired按照byType自动注入。</p>\n<hr>\n<blockquote>\n<p>Written with <a href=\"https://typora.io/\" target=\"_blank\" rel=\"external\">Typora</a>.</p>\n</blockquote>\n","categories":["Work"],"tags":["Java","Spring"]},{"title":"git版本控制","url":"/2018/05/git%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/","content":"<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><ul>\n<li>Snapshots, Not Differences</li>\n<li>Nearly Every Operation Is Local</li>\n<li>Git Has Integrity</li>\n<li>Git Generally Only Adds Data</li>\n</ul>\n<h4 id=\"三种状态\"><a href=\"#三种状态\" class=\"headerlink\" title=\"三种状态\"></a>三种状态</h4><p>Git has three main states that your files can reside in:</p>\n<ul>\n<li>commited: Committed means that the data is safely stored in your local database.</li>\n<li>modified: Modified means that you have changed the file but have not committed it to your database yet.</li>\n<li>staged: Staged means that you have marked a modified file in its current version to go into your next commit snapshot.</li>\n</ul>\n<h4 id=\"三种区域\"><a href=\"#三种区域\" class=\"headerlink\" title=\"三种区域\"></a>三种区域</h4><p>This leads us to the three main sections of a Git project: </p>\n<ul>\n<li>git directory(提交区): The Git directory is where Git stores the metadata and object database for your project. This is the most important part of Git, and it is what is copied when you clone a repository from another computer.</li>\n<li>working tree(工作区): The working tree is a single checkout of one version of the project. These files are pulled out of the compressed database in the Git directory and placed on disk for you to use or modify.</li>\n<li>staging area(暂存区): The staging area is a file, generally contained in your Git directory, that stores information about what will go into your next commit. Its technical name in Git parlance is the “index”, but the phrase “staging area” works just as well.</li>\n</ul>\n<h4 id=\"工作流程\"><a href=\"#工作流程\" class=\"headerlink\" title=\"工作流程\"></a>工作流程</h4><p>The basic Git workflow goes something like this:</p>\n<ol>\n<li>You modify files in your working tree.</li>\n<li>You selectively stage just those changes you want to be part of your next commit, which adds only those changes to the staging area.</li>\n<li>You do a commit, which takes the files as they are in the staging area and stores that snapshot permanently to your Git directory.</li>\n</ol>\n<h3 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h3><h4 id=\"git-diff\"><a href=\"#git-diff\" class=\"headerlink\" title=\"git diff\"></a><code>git diff</code></h4><p>比较工作区和暂存区，找出那些尚未被记录到暂存区的对工作区的改变<br>This command compares what is in your working directory with what is in your staging area. The result tells you the changes you’ve made that you haven’t yet staged.</p>\n<h4 id=\"git-diff-staged-或-git-diff-cached\"><a href=\"#git-diff-staged-或-git-diff-cached\" class=\"headerlink\" title=\"git diff --staged 或 git diff --cached\"></a><code>git diff --staged</code> 或 <code>git diff --cached</code></h4><p>比较暂存区和提交区，找出哪些对暂存区的改变会进入到下一次提交<br>If you want to see what you’ve staged that will go into your next commit, you can use <code>git diff --staged</code>. This command compares your staged changes to your last commit<br>(<code>--staged</code>与<code>--cached</code>相同)</p>\n<p><img src=\"gitdiff.jpg\" alt=\"git diff示意图\"></p>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><p><code>git rm</code>与<code>git add</code>相反，如果你不想track文件foo了，那么可以用<code>git rm foo</code>把它删除。但如果foo有改变在暂存区，会报下面错误：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">error: the following file has changes staged in the index:</div><div class=\"line\">    foo</div><div class=\"line\">(use --cached to keep the file, or -f to force removal)</div></pre></td></tr></table></figure></p>\n<p>如提示所述，这时<code>--cached</code>会保留磁盘，仅把foo变为untracked；<code>-f</code>会强制删除文件</p>\n<h3 id=\"git-rm-cached\"><a href=\"#git-rm-cached\" class=\"headerlink\" title=\"git rm --cached\"></a><code>git rm --cached</code></h3><p>如果你忘记在.gitignore中添加某种文件类型，如日志文件，而又恰巧不小心把这种文件add到了暂存区，这时可用<code>git rm --cached foo.log</code>将它从暂存区删除，这样commit的时候就不会把这种文件commit到提交区，而且也不会将文件从工作目录中删掉</p>\n<h3 id=\"撤销\"><a href=\"#撤销\" class=\"headerlink\" title=\"撤销\"></a>撤销</h3><h4 id=\"git-commit-amend\"><a href=\"#git-commit-amend\" class=\"headerlink\" title=\"git commit --amend\"></a><code>git commit --amend</code></h4><p>如果你已经完成了某项功能的开发准备好commit了，用<code>git commit -m &quot;complete feature #7&quot;</code>做了提交。然而却发现你忘了把一个与该功能有关的文件foo.java添加到暂存区了，导致这个文件没有被存入提交快照，如果用<code>git add foo.java</code>然后再commit一次，commit message怎么写才好呢？写”forgot foo.java”？这样不太好，会被老板骂，怎么办呢？用<code>--amend</code>再commit一次就好了，这次提交会覆盖上次有问题的提交，而且<code>git log</code>中只会显示这次提交的记录，这样就避免了同一功能对应多次提交记录。<br>完整过程如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ git commit -m &quot;complete feature #7&quot;</div><div class=\"line\">$ git add foo.java</div><div class=\"line\">$ git commit --amend</div></pre></td></tr></table></figure></p>\n<h4 id=\"git-reset-HEAD-lt-file-gt\"><a href=\"#git-reset-HEAD-lt-file-gt\" class=\"headerlink\" title=\"git reset HEAD &lt;file&gt;\"></a><code>git reset HEAD &lt;file&gt;</code></h4><p>Unstaging a Staged File：比如你想做一次commit，但是暂存区中有你不想提交的文件，那么可以用该命令将文件从暂存区删除</p>\n<h4 id=\"git-checkout-lt-file-gt\"><a href=\"#git-checkout-lt-file-gt\" class=\"headerlink\" title=\"git checkout -- &lt;file&gt;\"></a><code>git checkout -- &lt;file&gt;</code></h4><p>Unmodifying a Modified File：比如你已经修改了某文件，但还未将修改添加到暂存区，此时你想丢掉做出的修改，那么可用该命令将文件恢复成上次提交的样子</p>\n<h4 id=\"可恢复与不可恢复\"><a href=\"#可恢复与不可恢复\" class=\"headerlink\" title=\"可恢复与不可恢复\"></a>可恢复与不可恢复</h4><p>Remember, anything that is committed in Git can almost always be recovered. Even commits that were on branches that were deleted or commits that were overwritten with an <code>--amend</code> commit can be recovered (see Data Recovery for data recovery). However, anything you lose that was never committed is likely never to be seen again.</p>\n<h3 id=\"分支\"><a href=\"#分支\" class=\"headerlink\" title=\"分支\"></a>分支</h3><h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ul>\n<li><p>用户配置<br><code>git config --global user.name &lt;your_name&gt;</code><br><code>git config --global user.email &lt;your_email&gt;</code></p>\n</li>\n<li><p>配置级别<br><code>--local</code>：【默认，高优先级】，只影响本仓库，配置信息存储于本仓库中(.git/config)<br><code>--global</code>：【中优先级】，影响所有当前用户的git仓库，配置信息存储于用户目录中(~/.gitconfig)<br><code>--system</code>：【低优先级】，影响全系统的git仓库，配置信息存储于系统目录(/etc/gitconfig)</p>\n</li>\n</ul>\n<h3 id=\"提交记录\"><a href=\"#提交记录\" class=\"headerlink\" title=\"提交记录\"></a>提交记录</h3><p><code>git log</code> 查看提交记录<br><code>git log --oneline</code> 美化输出信息只显示一行</p>\n<h3 id=\"git学习资料及参考\"><a href=\"#git学习资料及参考\" class=\"headerlink\" title=\"git学习资料及参考\"></a>git学习资料及参考</h3><ul>\n<li><a href=\"progit.pdf\">Pro Git : [everything you need to know about Git] 2nd Edition (2014)</a></li>\n<li><a href=\"https://try.github.io\" target=\"_blank\" rel=\"external\">try git in 15 minutes</a></li>\n<li><a href=\"http://rogerdudler.github.io/git-guide/index.zh.html\" target=\"_blank\" rel=\"external\">git - 简明指南</a></li>\n</ul>\n","categories":["Learning"],"tags":["git"]},{"title":"Maven核心概念","url":"/2018/02/Maven%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/","content":"<h3 id=\"Maven是什么\"><a href=\"#Maven是什么\" class=\"headerlink\" title=\"Maven是什么\"></a>Maven是什么</h3><ul>\n<li>Apache基金会出品</li>\n<li>开源</li>\n<li>java写的</li>\n<li>Maven是一个项目构建和依赖管理的工具</li>\n</ul>\n<h3 id=\"为什么选择Maven\"><a href=\"#为什么选择Maven\" class=\"headerlink\" title=\"为什么选择Maven\"></a>为什么选择Maven</h3><ul>\n<li>基于约定优先于配置的原则：默认限定了项目的目录结构，项目之间迁移的学习成本低</li>\n<li>提供三方依赖包的管理：提供远程仓库，解决了依赖维护</li>\n<li>提供一致的项目构建管理方式：将项目构建过程的操作抽象成生命周期，减少构建工作量</li>\n<li>插件式的架构，大量的可重用的插件</li>\n<li>方便地集成IDE</li>\n</ul>\n<h3 id=\"pom-xml\"><a href=\"#pom-xml\" class=\"headerlink\" title=\"pom.xml\"></a>pom.xml</h3><ul>\n<li>POM: Project Object Model</li>\n<li>groupId:组织</li>\n<li>artifactId:项目标识符</li>\n<li>version:版本　　X.Y.Z-SNAPSHOT, X.Y.Z-RELEASE, X.Y.Z</li>\n<li>groupId,artifactId,version三个字段构成了一个项目的唯一坐标</li>\n<li>packaging:打包类型　有war,jar,pom三种</li>\n<li>dependencies:依赖的项目</li>\n</ul>\n<h3 id=\"Maven基本命令\"><a href=\"#Maven基本命令\" class=\"headerlink\" title=\"Maven基本命令\"></a>Maven基本命令</h3><ul>\n<li><code>mvn archetype:generate</code>  使用模板生成项目<br>例子：<br><code>mvn archetype:generate -DgroupId=com.netease.restaurant -DartifactId=Kitchen -Dpackage=com.netease -Dversion=1.0.0-SNAPSHOT -DarchetypeArtifactId=maven-archetype-webapp</code><br>archetypeArtifactId指定了项目类型<br>web项目模板：maven-archetype-webapp<br>java项目模板：maven-archetype-quickstart</li>\n<li><code>mvn compile</code>  编译源代码</li>\n<li><code>mvn test</code>  一般用来跑单元测试</li>\n<li><code>mvn package</code>  打包</li>\n<li><code>mvn deploy</code>  部署</li>\n<li><code>mvn site</code>  生成项目相关的站点和在线文档等</li>\n<li><code>mvn clean</code>  清理</li>\n<li><code>mvn install</code>  把包安装到本地仓库，从而让其他项目引用</li>\n</ul>\n<h3 id=\"Tomcat插件\"><a href=\"#Tomcat插件\" class=\"headerlink\" title=\"Tomcat插件\"></a>Tomcat插件</h3><ul>\n<li>Tomcat官方提供的，实现了在Maven中内嵌一个Tomcat，方便开发调试</li>\n<li><code>mvn help:describe -Dplugin=tomcat7</code>  获得插件的详细帮助</li>\n<li><code>mvn tomcat7:run</code>  启动一个Tomcat实例</li>\n<li>还有<code>mvn tomcat7:deploy</code>  <code>mvn tomcat7:undeploy</code>等命令</li>\n</ul>\n<h3 id=\"父pom与子pom\"><a href=\"#父pom与子pom\" class=\"headerlink\" title=\"父pom与子pom\"></a>父pom与子pom</h3><ul>\n<li>子pom从父pom中继承，也可以覆盖父pom中的配置</li>\n<li>可继承项目：<br>坐标，如groupId<br>依赖配置<br>插件配置<br>一般性信息，如开发者信息、开源协议等</li>\n</ul>\n<h3 id=\"Super-POM\"><a href=\"#Super-POM\" class=\"headerlink\" title=\"Super POM\"></a>Super POM</h3><ul>\n<li>所有Maven项目的POM都继承自Super POM</li>\n<li>是Maven的组成部分</li>\n<li>定义了一组被所有项目共享的默认设置<br>如：默认的文件结构<br>统一的插件配置<br>默认的中央仓库配置</li>\n</ul>\n<h3 id=\"多模块构建\"><a href=\"#多模块构建\" class=\"headerlink\" title=\"多模块构建\"></a>多模块构建</h3><ul>\n<li>parent项目，packaging类型是pom，定义多个modules</li>\n<li>子模块module配置通过<code>&lt;parent&gt;&lt;/parent&gt;</code>属性指定parent项目，继承自parent</li>\n</ul>\n<h3 id=\"依赖配置\"><a href=\"#依赖配置\" class=\"headerlink\" title=\"依赖配置\"></a>依赖配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">&lt;dependencies&gt;</div><div class=\"line\">  &lt;dependency&gt;</div><div class=\"line\">    &lt;groupId&gt;javax.servlet&lt;/groupId&gt;</div><div class=\"line\">    &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;</div><div class=\"line\">    &lt;version&gt;3.0.1&lt;/version&gt;</div><div class=\"line\">    &lt;scope&gt;provided&lt;/scope&gt;</div><div class=\"line\">  &lt;/dependency&gt;</div><div class=\"line\">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>\n<p>scope指的是依赖范围，有两种：compile和provided<br>不配置scope时默认是compile，指所依赖的包在编译的时候用，在打包的时候也会把这个依赖包打包进去；provided就是在依赖包在只在编译的时候用，在打包的时候不把依赖包打包进去，因为在部署的时候一般容器都会提供这个依赖包，所以不需要再打包进去了</p>\n<h3 id=\"仓库\"><a href=\"#仓库\" class=\"headerlink\" title=\"仓库\"></a>仓库</h3><ul>\n<li>用于统一存储所有Maven项目共享的构件的空间</li>\n<li>仓库分为本地仓库和远程仓库。本地仓库相当于缓存，在查找依赖包时，首先在本地仓库找，找不到再从远程仓库下载，下载到本地仓库以便下次使用。</li>\n<li>本地仓库目录为<code>${usr.home}/.m2/repository</code></li>\n<li>远程仓库有中央仓库、其他公共仓库、私服三种。中央仓库由maven官方提供和维护，其他公共仓库提供国内镜像等，私服由公司内部搭建</li>\n<li>maven项目在远程仓库的存放路径为：<code>/&lt;groupId&gt;/&lt;artifactId&gt;/&lt;version&gt;/&lt;artifactId&gt;-&lt;version&gt;.&lt;packaging&gt;</code></li>\n</ul>\n<h3 id=\"构建的生命周期\"><a href=\"#构建的生命周期\" class=\"headerlink\" title=\"构建的生命周期\"></a>构建的生命周期</h3><ul>\n<li>一个构建生命周期是一组精心组织的有序的阶段</li>\n<li>每个阶段执行预先定义的“动作”：编译、打包、部署等等</li>\n<li>这些“动作”会根据项目的类型进行选择<h4 id=\"clean生命周期：pre-clean-gt-clean-gt-post-clean\"><a href=\"#clean生命周期：pre-clean-gt-clean-gt-post-clean\" class=\"headerlink\" title=\"clean生命周期：pre-clean -&gt; clean -&gt; post-clean\"></a>clean生命周期：pre-clean -&gt; clean -&gt; post-clean</h4><h4 id=\"default生命周期：…-gt-process-resources-gt-compile-gt-…-gt-test-gt-package-gt-install-gt-deploy\"><a href=\"#default生命周期：…-gt-process-resources-gt-compile-gt-…-gt-test-gt-package-gt-install-gt-deploy\" class=\"headerlink\" title=\"default生命周期：… -&gt; process-resources -&gt; compile -&gt; … -&gt; test -&gt; package -&gt; install -&gt; deploy\"></a>default生命周期：… -&gt; process-resources -&gt; compile -&gt; … -&gt; test -&gt; package -&gt; install -&gt; deploy</h4>举几个阶段的例子：</li>\n<li>validate：验证项目是否正确，以及检查为了完成完整构建过程所必要的信息是否有缺少</li>\n<li>process-resources：将资源文件复制目标目录下</li>\n<li>compile：编译源代码</li>\n<li>test：跑单元测试</li>\n<li>package：打包</li>\n<li>install：将包安装到本地仓库，供其他项目进行依赖</li>\n<li>deploy：将包上传到远程仓库<h4 id=\"site生命周期：pre-site-gt-site-gt-post-site-gt-site-deploy\"><a href=\"#site生命周期：pre-site-gt-site-gt-post-site-gt-site-deploy\" class=\"headerlink\" title=\"site生命周期：pre-site -&gt; site -&gt; post-site -&gt; site-deploy\"></a>site生命周期：pre-site -&gt; site -&gt; post-site -&gt; site-deploy</h4></li>\n</ul>\n<h3 id=\"插件-Plugin-和目标-Goal\"><a href=\"#插件-Plugin-和目标-Goal\" class=\"headerlink\" title=\"插件(Plugin)和目标(Goal)\"></a>插件(Plugin)和目标(Goal)</h3><ul>\n<li>Maven是插件式架构，可以看成是由一个引擎和多个插件构成的，所有的插件本身也是一个Maven构件，由Maven仓库管理</li>\n<li>每个Plugin提供多个Goal</li>\n<li>调用目标的格式：<code>mvn &lt;Plugin&gt;:&lt;Goal&gt;</code></li>\n</ul>\n<h3 id=\"插件和目标绑定构建生命周期\"><a href=\"#插件和目标绑定构建生命周期\" class=\"headerlink\" title=\"插件和目标绑定构建生命周期\"></a>插件和目标绑定构建生命周期</h3><ul>\n<li>生命周期的阶段与目标是绑定的，用户指定生命周期阶段实际上是隐式地调用了某个插件执行任务</li>\n<li>生命周期的各个阶段绑定的目标如表所示：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>生命周期阶段</th>\n<th>目标</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>process-resources</td>\n<td>resources:resources</td>\n</tr>\n<tr>\n<td>compile</td>\n<td>compiler:compile</td>\n</tr>\n<tr>\n<td>test</td>\n<td>surefire:test</td>\n</tr>\n<tr>\n<td>install</td>\n<td>install:install</td>\n</tr>\n<tr>\n<td>deploy</td>\n<td>deploy:deploy</td>\n</tr>\n</tbody>\n</table>\n<p>比如<code>mvn compile</code>实际上就是执行了compiler插件的compile目标，相当于执行了<code>mvn compiler:compile</code><br>对于package阶段，会根据项目类型不同，绑定到不同的目标</p>\n<h3 id=\"插件配置\"><a href=\"#插件配置\" class=\"headerlink\" title=\"插件配置\"></a>插件配置</h3><p>在pom.xml中经常会配置某个插件的参数，如果不知道怎么配，可以用下面命令查看帮助文档：<br><code>mvn help:describe -Dplugin=&lt;plugin_name&gt; -Dgoal=&lt;goal_name&gt; -Ddetail</code><br>比如查看compiler插件中compile目标的配置参数帮助文档：<br><code>mvn help:describe -Dplugin=compiler -Dgoal=compile -Ddetail</code></p>\n","categories":["Learning"],"tags":["Maven"]},{"title":"tomcat相关问题解决","url":"/2017/12/tomcat%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","content":"<h3 id=\"解决tomcat启动过慢\"><a href=\"#解决tomcat启动过慢\" class=\"headerlink\" title=\"解决tomcat启动过慢\"></a>解决tomcat启动过慢</h3><p><a href=\"http://blog.csdn.net/benyuxy/article/details/7570244\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/benyuxy/article/details/7570244</a><br><a href=\"http://blog.csdn.net/u011627980/article/details/54024974\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/u011627980/article/details/54024974</a><br><a href=\"http://blog.csdn.net/changyinling520/article/details/71036515\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/changyinling520/article/details/71036515</a></p>\n<h3 id=\"远程部署war包过程中，tomcat报错java-util-zip-ZipException-error-in-opening-zip-file。\"><a href=\"#远程部署war包过程中，tomcat报错java-util-zip-ZipException-error-in-opening-zip-file。\" class=\"headerlink\" title=\"远程部署war包过程中，tomcat报错java.util.zip.ZipException: error in opening zip file。\"></a>远程部署war包过程中，tomcat报错java.util.zip.ZipException: error in opening zip file。</h3><p><img src=\"tomcat配置.png\" alt=\"server.xml配置\" title=\"server.xml配置\"><br>tomcat会自动解压webapps目录下的war包，当用scp把war包部署到远程tomcat上的时候，如果这个war包比较大，那么tomcat在war包还没有传输完成的时候就尝试解压，这样就会导致zipException</p>\n<p>另：</p>\n<h3 id=\"tomcat下部署war包的两种方法\"><a href=\"#tomcat下部署war包的两种方法\" class=\"headerlink\" title=\"tomcat下部署war包的两种方法\"></a>tomcat下部署war包的两种方法</h3><p><a href=\"http://blog.csdn.net/wy818/article/details/7240294\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/wy818/article/details/7240294</a></p>\n","categories":["Work"],"tags":["tomcat"]},{"title":"nginx+lua动态改变upstream","url":"/2017/11/nginx-lua%E5%8A%A8%E6%80%81%E6%94%B9%E5%8F%98upstream/","content":"<p>在做毕设的时候需要动态改变通过nginx代理的服务器数量。背景大概是我有一个generator不断产生负载打在nginx上，还有一个monitor根据generator生成负载的qps来动态决定需要多少台服务器刚好能够承担这个qps的请求，因此需要动态修改nginx中的upstream。以前在配置nginx的时候，upstream都是写死在nginx.conf文件中的，现在要动态改变upstream，这需要在nginx运行过程中用脚本修改，那么就用Lua来实现吧。</p>\n<h3 id=\"nginx-lua安装\"><a href=\"#nginx-lua安装\" class=\"headerlink\" title=\"nginx+lua安装\"></a>nginx+lua安装</h3><p>之前安装过了nginx，但是没有安装lua模块，下面按照官网的步骤开始集成Lua。<br>需要下载：</p>\n<ul>\n<li><a href=\"http://luajit.org/download.html\" target=\"_blank\" rel=\"external\">LuaJIT</a>：Lua编译器(a Just-In-Time Compiler for Lua),2.0或2.1版本均可</li>\n<li><a href=\"https://github.com/simpl/ngx_devel_kit/tags\" target=\"_blank\" rel=\"external\">ngx_devel_kit (NDK) module</a></li>\n<li><a href=\"https://github.com/openresty/lua-nginx-module/tags\" target=\"_blank\" rel=\"external\">lua-nginx-module</a></li>\n</ul>\n<p>安装好LuaJIT，解压NDK module和lua-nginx-module，继续。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 打开nginx源代码目录:</span></div><div class=\"line\"> <span class=\"built_in\">cd</span> ~/work/nginx-1.12.1</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 告诉nginx编译程序在哪里能找到LuaJIT:</span></div><div class=\"line\"> <span class=\"built_in\">export</span> LUAJIT_LIB=/path/to/luajit/lib</div><div class=\"line\"> <span class=\"built_in\">export</span> LUAJIT_INC=/path/to/luajit/include/luajit-2.0</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 配置nginx模块:</span></div><div class=\"line\"> ./configure \\</div><div class=\"line\">         --with-ld-opt=<span class=\"string\">\"-Wl,-rpath,/path/to/luajit-or-lua/lib\"</span> \\</div><div class=\"line\">         --add-module=/path/to/ngx_devel_kit \\</div><div class=\"line\">         --add-module=/path/to/lua-nginx-module</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 编译&amp;安装:</span></div><div class=\"line\"> make &amp; sudo make install</div></pre></td></tr></table></figure>\n<p>测试一下是否成功：<br>在nginx.conf中加入<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">location /hello &#123; </div><div class=\"line\">      default_type <span class=\"string\">'text/plain'</span>; </div><div class=\"line\">      content_by_lua <span class=\"string\">'ngx.say(\"hello, lua\")'</span>; </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>访问127.0.0.1/hello,出现”hello, lua”即为成功。</p>\n<h3 id=\"动态改变upstream\"><a href=\"#动态改变upstream\" class=\"headerlink\" title=\"动态改变upstream\"></a>动态改变upstream</h3><p>这里使用了lua中的”lua_shared_dict”创建一个共享内存空间，通过该命令定义的共享内存对象对于nginx中所有worker进程都是可见的，通过./nginx -s reload是不会改变共享内存对象的内容的，只有nginx重启才重新清空内容。</p>\n<p>下面就是nginx.conf中的配置了。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># nginx结合lua动态修改uptream</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#user  nobody;</span></div><div class=\"line\">worker_processes  1; <span class=\"comment\">#工作进程个数</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#error_log  logs/error.log;</span></div><div class=\"line\"><span class=\"comment\">#error_log  logs/error.log  notice;</span></div><div class=\"line\"><span class=\"comment\">#error_log  logs/error.log  info;</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#pid        logs/nginx.pid;</span></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">events &#123;</div><div class=\"line\">    worker_connections  1024; <span class=\"comment\">#单个进程最大连接数</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">http &#123;</div><div class=\"line\">    lua_shared_dict _upstream_G 1m; <span class=\"comment\">#定义upstream共享内存空间</span></div><div class=\"line\"></div><div class=\"line\">    include       mime.types;</div><div class=\"line\">    default_type  application/octet-stream;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">#log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '</span></div><div class=\"line\">    <span class=\"comment\">#                  '$status $body_bytes_sent \"$http_referer\" '</span></div><div class=\"line\">    <span class=\"comment\">#                  '\"$http_user_agent\" \"$http_x_forwarded_for\"';</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">#access_log  logs/access.log  main;</span></div><div class=\"line\"></div><div class=\"line\">    sendfile        on;</div><div class=\"line\">    <span class=\"comment\">#tcp_nopush     on;</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">#keepalive_timeout  0;</span></div><div class=\"line\">    keepalive_timeout  65;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">#gzip  on;</span></div><div class=\"line\"></div><div class=\"line\">    upstream energyaware_servers_default &#123;</div><div class=\"line\">        server 127.0.0.1:8080;</div><div class=\"line\">        server 127.0.0.1:8090;</div><div class=\"line\">        server 127.0.0.1:8091;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">    upstream energyaware_servers_3 &#123;</div><div class=\"line\">        server 127.0.0.1:8080;</div><div class=\"line\">        server 127.0.0.1:8090;</div><div class=\"line\">        server 127.0.0.1:8091;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    upstream energyaware_servers_2 &#123;</div><div class=\"line\">        server 127.0.0.1:8080;</div><div class=\"line\">        server 127.0.0.1:8090;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    upstream energyaware_servers_1 &#123;</div><div class=\"line\">        server 127.0.0.1:8080;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">    server &#123;</div><div class=\"line\">        listen       80;</div><div class=\"line\">        server_name  energyaware.com localhost; <span class=\"comment\">#可以有多个，用空格分隔</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\">#charset koi8-r;</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\">#access_log  logs/host.access.log  main;</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 切换 upstream 接口  </span></div><div class=\"line\">        location = /upstream_switch &#123;</div><div class=\"line\">            content_by_lua <span class=\"string\">'</span></div><div class=\"line\">                local ups = ngx.req.get_uri_args()[\"ups\"]</div><div class=\"line\">                if ups == nil then</div><div class=\"line\">                    ngx.say(\"usage: /upstream_switch?ups=x.x.x.x\")</div><div class=\"line\">                    return</div><div class=\"line\">                end</div><div class=\"line\">                local host = ngx.var.http_host</div><div class=\"line\">                local ups_from = ngx.shared._upstream_G:get(host)</div><div class=\"line\">                if ups_from == nil then</div><div class=\"line\">                    ups_from = \"energyaware_servers_default\"</div><div class=\"line\">                end</div><div class=\"line\">                ngx.log(ngx.ERR, host, \" switch upstream from \", ups_from, \" to \", ups)</div><div class=\"line\">                ngx.shared._upstream_G:set(host, ups)</div><div class=\"line\">            ';</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        location / &#123;</div><div class=\"line\">            <span class=\"comment\"># 动态设置当前 upstream, 未设置则使用默认 upstream  </span></div><div class=\"line\">            set_by_lua <span class=\"variable\">$cur_ups</span> <span class=\"string\">'</span></div><div class=\"line\">                local host = ngx.var.http_host</div><div class=\"line\">                local ups = ngx.shared._upstream_G:get(host)</div><div class=\"line\">                if ups ~= nil then</div><div class=\"line\">                    ngx.log(ngx.ERR, \"get [\", ups, \"] from ngx.shared._upstream_G\")</div><div class=\"line\">                    return ups</div><div class=\"line\">                end</div><div class=\"line\">                ngx.shared._upstream_G:set(host, \"energyaware_servers_default\")</div><div class=\"line\">                ngx.log(ngx.ERR, \"use default upstream: energyaware_servers_default\")</div><div class=\"line\">                return \"energyaware_servers_default\"</div><div class=\"line\">            ';</div><div class=\"line\">            <span class=\"comment\">#proxy_next_upstream off;</span></div><div class=\"line\">            proxy_set_header Host <span class=\"variable\">$host</span>:<span class=\"variable\">$server_port</span>;</div><div class=\"line\">            <span class=\"comment\">#proxy_set_header    Connection  \"\";</span></div><div class=\"line\">            <span class=\"comment\">#proxy_redirect  http://$cur_ups http://$cur_ups:80;</span></div><div class=\"line\">            <span class=\"comment\">#proxy_redirect http://energyaware_servers_default http://energyaware_servers_default:80;</span></div><div class=\"line\">            proxy_pass http://<span class=\"variable\">$cur_ups</span>;</div><div class=\"line\">            <span class=\"comment\">#proxy_pass http://energyaware_servers_default;</span></div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">\tlocation /hello &#123; </div><div class=\"line\">      \t    default_type <span class=\"string\">'text/plain'</span>; </div><div class=\"line\">            content_by_lua <span class=\"string\">'ngx.say(\"hello, lua\")'</span>; </div><div class=\"line\">\t&#125;</div><div class=\"line\">   </div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>日志打在了nginx/log/error.log中<br>定义了切换upstream的接口，下面命令可以将upstream切换为energyaware_servers_2(一组服务器)，而无需./nginx -s reload<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">curl http://energyaware.com/upstream_switch\\?ups\\=energyaware_servers_2</div></pre></td></tr></table></figure></p>\n<p>切换完成之后，可以用下面脚本生成请求，然后看看这些请求都打到了哪台服务器上<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> $(seq 10); <span class=\"keyword\">do</span> curl http://energyaware.com  ;<span class=\"keyword\">done</span></div></pre></td></tr></table></figure></p>\n<p>我这里energyaware_servers_2中有两台服务器，负载均衡策略就是最简单的轮询，所以请求应该是平均地被这两台服务器消费了。</p>\n<p>当然也可以把upstream设置成单台服务器，直接写成ip:port的形式即可。比如：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">curl http://energyaware.com/upstream_switch\\?ups\\=127.0.0.1:8090</div></pre></td></tr></table></figure></p>\n<blockquote>\n<p>参考：<br><a href=\"https://github.com/openresty/lua-nginx-module#installation\" target=\"_blank\" rel=\"external\">https://github.com/openresty/lua-nginx-module#installation</a><br><a href=\"http://blog.csdn.net/force_eagle/article/details/51966333\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/force_eagle/article/details/51966333</a><br><a href=\"http://blog.csdn.net/toontong/article/details/49633829\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/toontong/article/details/49633829</a></p>\n</blockquote>\n<h3 id=\"利用redis持久化upstream\"><a href=\"#利用redis持久化upstream\" class=\"headerlink\" title=\"利用redis持久化upstream\"></a>利用redis持久化upstream</h3><p>有的时候我们希望把upstream持久化，否则nginx因为各种各样的原因需要重启的时候<strong>lua_shared_dict</strong>被清空，从而失去了我们原来的upstream；而且，当不止有一台nginx的时候，由于<strong>lua_shared_dict</strong>为单个nginx所有不被共享，造成不同nginx对应着不同的upstream，失去了nginx集群的意义。总之，我们需要持久化upstream。</p>\n<p>实现与上面方法类似，将upstream以<key, value=\"\">的形式存在redis中，key是host名，value是upstream，对外提供restful接口将value修改成我们想要的upstream即可。当然如果我们每次请求都要从redis里面查找显然是不合理的，可以利用前面提到的<strong>lua_shared_dict</strong>做缓存，先从缓存里取，缓存中没有再从redis中取，然后更新缓存。</key,></p>\n<blockquote>\n<p>参考：<br>  <a href=\"https://sosedoff.com/2012/06/11/dynamic-nginx-upstreams-with-lua-and-redis.html\" target=\"_blank\" rel=\"external\">https://sosedoff.com/2012/06/11/dynamic-nginx-upstreams-with-lua-and-redis.html</a><br>  <a href=\"http://blog.csdn.net/imlsz/article/details/47720235\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/imlsz/article/details/47720235</a></p>\n</blockquote>\n<h3 id=\"其他方法\"><a href=\"#其他方法\" class=\"headerlink\" title=\"其他方法\"></a>其他方法</h3><ul>\n<li><p>其实我最初的想法是想能不能动态地增加/删除upstream里面的server，这样做需要懂nginx内核了。。。好在发现了一个开源的模块<a href=\"https://github.com/yzprofile/ngx_http_dyups_module\" target=\"_blank\" rel=\"external\">ngx_http_dyups_module</a>，淘宝大神写的。不过我还没有尝试，先记录下万一以后用到。</p>\n</li>\n<li><p>nginx官方实现了这个功能，但是在<a href=\"https://www.nginx.com/products/nginx/load-balancing/#load-balancing-api\" target=\"_blank\" rel=\"external\">nginx plus</a>版本中(收费)</p>\n<blockquote>\n<p>“NGINX Plus offers an API that falls closely to the REST architecture and is unified under a single API endpoint. Use the NGINX Plus API to update upstream configurations and key‑value stores on the fly with zero downtime. “<br>–摘自官网</p>\n</blockquote>\n</li>\n<li><p>另外还找到一篇<a href=\"http://www.jianshu.com/p/35b03c82f9fd\" target=\"_blank\" rel=\"external\">基于 consul + upsync 的动态upstream管理</a></p>\n</li>\n</ul>\n","categories":["Work"],"tags":["nginx","Lua"]},{"title":"解决校园网登录release and renew ip address问题","url":"/2017/11/%E8%A7%A3%E5%86%B3%E6%A0%A1%E5%9B%AD%E7%BD%91%E7%99%BB%E5%BD%95release-and-renew-ip-address%E9%97%AE%E9%A2%98/","content":"<p>今天在登录校园网时出现了”Invalid ip address, please release and renew it”的错误，无法正常上网，记录一下解决办法。</p>\n<h3 id=\"Windows系统\"><a href=\"#Windows系统\" class=\"headerlink\" title=\"Windows系统\"></a>Windows系统</h3><p>Windows系统下，在cmd中输入<br><code>ipconfig release</code><br><code>ipconfig renew</code></p>\n<h3 id=\"Linux系统\"><a href=\"#Linux系统\" class=\"headerlink\" title=\"Linux系统\"></a>Linux系统</h3><p>Linux系统下，<code>ip a</code>查看所有网卡：<br><img src=\"网卡.png\" alt=\"所有网卡\" title=\"所有网卡\"><br>在我机器上wlan0是连接校园网的无线网卡</p>\n<p>接着执行以下2条命令：<br><code>sudo dhclient -v -r wlan0</code><br><code>sudo dhclient -v wlan0</code><br>第一条命令相当于释放当前已分配的ip地址，第二条命令从DHCP server重新获得一个ip</p>\n<p>重新登录校园网即可。</p>\n<blockquote>\n<p>参考<a href=\"https://www.cnblogs.com/Leo_wl/p/5484108.html\" target=\"_blank\" rel=\"external\">https://www.cnblogs.com/Leo_wl/p/5484108.html</a></p>\n</blockquote>\n","categories":["Work"],"tags":["network"]},{"title":"(转载)消息队列的使用场景","url":"/2017/11/%E8%BD%AC%E8%BD%BD-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/","content":"<blockquote>\n<p>原文：<a href=\"http://www.cnblogs.com/linjiqin/p/5720865.html\" target=\"_blank\" rel=\"external\">http://www.cnblogs.com/linjiqin/p/5720865.html</a></p>\n</blockquote>\n<h2 id=\"消息队列概述\"><a href=\"#消息队列概述\" class=\"headerlink\" title=\"消息队列概述\"></a>消息队列概述</h2><p>消息队列中间件是分布式系统中重要的组件，主要解决应用解耦，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ</p>\n<h2 id=\"消息队列应用场景\"><a href=\"#消息队列应用场景\" class=\"headerlink\" title=\"消息队列应用场景\"></a>消息队列应用场景</h2><p>以下介绍消息队列在实际应用中常用的使用场景。异步处理，应用解耦，流量削锋，日志处理和消息通讯五个场景。</p>\n<h3 id=\"异步处理\"><a href=\"#异步处理\" class=\"headerlink\" title=\"异步处理\"></a>异步处理</h3><p>场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种 1.串行的方式；2.并行方式</p>\n<ul>\n<li><p>串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。<br><img src=\"串行方式.png\" alt=\"串行方式\" title=\"串行方式\"></p>\n</li>\n<li><p>并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间<br><img src=\"并行方式.png\" alt=\"并行方式\" title=\"并行方式\"></p>\n</li>\n</ul>\n<p>假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。<br>因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）<br>小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？</p>\n<p>引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：<br><img src=\"异步消息.png\" alt=\"异步消息\" title=\"异步消息\"><br>按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。</p>\n<h3 id=\"应用解耦\"><a href=\"#应用解耦\" class=\"headerlink\" title=\"应用解耦\"></a>应用解耦</h3><p>场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图：<br><img src=\"应用高耦合.png\" alt=\"应用高耦合\" title=\"应用高耦合\"><br>传统模式的缺点：假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，订单系统与库存系统耦合</p>\n<p>如何解决以上问题呢？引入应用消息队列后的方案，如下图：<br><img src=\"应用解耦.png\" alt=\"应用解耦\" title=\"应用解耦\"><br>订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功<br>库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作<br>假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦</p>\n<h3 id=\"流量削锋\"><a href=\"#流量削锋\" class=\"headerlink\" title=\"流量削锋\"></a>流量削锋</h3><p>流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。<br>应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。</p>\n<ul>\n<li>可以控制活动的人数</li>\n<li>可以缓解短时间内高流量压垮应用<br><img src=\"流量削峰.png\" alt=\"流量削峰\" title=\"流量削峰\"><br>用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。<br>秒杀业务根据消息队列中的请求信息，再做后续处理</li>\n</ul>\n<h3 id=\"日志处理\"><a href=\"#日志处理\" class=\"headerlink\" title=\"日志处理\"></a>日志处理</h3><p>日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下<br><img src=\"日志处理.png\" alt=\"日志处理\" title=\"日志处理\"><br>日志采集客户端，负责日志数据采集，定时写受写入Kafka队列<br>Kafka消息队列，负责日志数据的接收，存储和转发<br>日志处理应用：订阅并消费kafka队列中的日志数据 </p>\n<h3 id=\"消息通讯\"><a href=\"#消息通讯\" class=\"headerlink\" title=\"消息通讯\"></a>消息通讯</h3><p>消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等</p>\n<ul>\n<li><p>点对点通讯：<br><img src=\"点对点通讯.png\" alt=\"点对点通讯\" title=\"点对点通讯\"><br>客户端A和客户端B使用同一队列，进行消息通讯。</p>\n</li>\n<li><p>聊天室通讯：<br><img src=\"聊天室通讯.png\" alt=\"聊天室通讯\" title=\"聊天室通讯\"><br>客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</p>\n</li>\n</ul>\n<p>以上实际是消息队列的两种消息模式，点对点或发布订阅模式。模型为示意图，供参考。</p>\n<h2 id=\"消息中间件示例\"><a href=\"#消息中间件示例\" class=\"headerlink\" title=\"消息中间件示例\"></a>消息中间件示例</h2><h3 id=\"电商系统\"><a href=\"#电商系统\" class=\"headerlink\" title=\"电商系统\"></a>电商系统</h3><p><img src=\"电商.jpg\" alt=\"电商\" title=\"电商\"><br>消息队列采用高可用，可持久化的消息中间件。比如Active MQ，Rabbit MQ，Rocket Mq。<br>（1）应用将主干逻辑处理完成后，写入消息队列。消息发送是否成功可以开启消息的确认模式。（消息队列返回消息接收成功状态后，应用再返回，这样保障消息的完整性）<br>（2）扩展流程（发短信，配送处理）订阅队列消息。采用推或拉的方式获取消息并处理。<br>（3）消息将应用解耦的同时，带来了数据一致性问题，可以采用最终一致性方式解决。比如主数据写入数据库，扩展应用根据消息队列，并结合数据库方式实现基于消息队列的后续处理。</p>\n<h3 id=\"日志收集系统\"><a href=\"#日志收集系统\" class=\"headerlink\" title=\"日志收集系统\"></a>日志收集系统</h3><p><img src=\"日志收集.jpg\" alt=\"日志收集\" title=\"日志收集\"><br>分为Zookeeper注册中心，日志收集客户端，Kafka集群和Storm集群（OtherApp）四部分组成。<br>Zookeeper注册中心，提出负载均衡和地址查找服务<br>日志收集客户端，用于采集应用系统的日志，并将数据推送到kafka队列<br>Kafka集群：接收，路由，存储，转发等消息处理<br>Storm集群：与OtherApp处于同一级别，采用拉的方式消费队列中的数据</p>\n<h2 id=\"JMS消息服务\"><a href=\"#JMS消息服务\" class=\"headerlink\" title=\"JMS消息服务\"></a>JMS消息服务</h2><p>讲消息队列就不得不提JMS 。JMS（JAVA Message Service，java消息服务）API是一个消息服务的标准/规范，允许应用程序组件基于JavaEE平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。<br>在EJB架构中，有消息bean可以无缝的与JM消息服务集成。在J2EE架构模式中，有消息服务者模式，用于实现消息与应用直接的解耦。</p>\n<h3 id=\"消息模型\"><a href=\"#消息模型\" class=\"headerlink\" title=\"消息模型\"></a>消息模型</h3><p>在JMS标准中，有两种消息模型P2P（Point to Point）,Publish/Subscribe(Pub/Sub)。</p>\n<h4 id=\"P2P模式\"><a href=\"#P2P模式\" class=\"headerlink\" title=\"P2P模式\"></a>P2P模式</h4><p><img src=\"P2P模式.png\" alt=\"P2P模式\" title=\"P2P模式\"><br>P2P模式包含三个角色：消息队列（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。</p>\n<p>P2P的特点：<br>每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)<br>发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列<br>接收者在成功接收消息之后需向队列应答成功<br>如果希望发送的每个消息都会被成功处理的话，那么需要P2P模式。</p>\n<h4 id=\"Pub-Sub模式\"><a href=\"#Pub-Sub模式\" class=\"headerlink\" title=\"Pub/Sub模式\"></a>Pub/Sub模式</h4><p><img src=\"Pub-Sub模式.png\" alt=\"Pub/Sub模式\" title=\"Pub/Sub模式\"><br>包含三个角色主题（Topic），发布者（Publisher），订阅者（Subscriber） 多个发布者将消息发送到Topic，系统将这些消息传递给多个订阅者。</p>\n<p>Pub/Sub的特点：<br>每个消息可以有多个消费者<br>发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息<br>为了消费消息，订阅者必须保持运行的状态<br>为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。<br>如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型。</p>\n<h3 id=\"消息消费\"><a href=\"#消息消费\" class=\"headerlink\" title=\"消息消费\"></a>消息消费</h3><p>在JMS中，消息的产生和消费都是异步的。对于消费来说，JMS的消息者可以通过两种方式来消费消息。</p>\n<ul>\n<li>同步：订阅者或接收者通过receive方法来接收消息，receive方法在接收到消息之前（或超时之前）将一直阻塞；</li>\n<li>异步：订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的onMessage方法。</li>\n</ul>\n<p>JNDI：Java命名和目录接口,是一种标准的Java命名系统接口。可以在网络上查找和访问服务。通过指定一个资源名称，该名称对应于数据库或命名服务中的一个记录，同时返回资源连接建立所必须的信息。<br>JNDI在JMS中起到查找和访问发送目标或消息来源的作用。</p>\n<h2 id=\"常用消息队列\"><a href=\"#常用消息队列\" class=\"headerlink\" title=\"常用消息队列\"></a>常用消息队列</h2><p>一般商用的容器，比如WebLogic，JBoss，都支持JMS标准，开发上很方便。但免费的比如Tomcat，Jetty等则需要使用第三方的消息中间件。本部分内容介绍常用的消息中间件（Active MQ,Rabbit MQ，Zero MQ,Kafka）以及他们的特点。</p>\n<h3 id=\"ActiveMQ\"><a href=\"#ActiveMQ\" class=\"headerlink\" title=\"ActiveMQ\"></a>ActiveMQ</h3><p>ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。</p>\n<p>ActiveMQ特性如下：<br>⒈ 多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP<br>⒉ 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)<br>⒊ 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性<br>⒋ 通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上<br>⒌ 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA<br>⒍ 支持通过JDBC和journal提供高速的消息持久化<br>⒎ 从设计上保证了高性能的集群，客户端-服务器，点对点<br>⒏ 支持Ajax<br>⒐ 支持与Axis的整合<br>⒑ 可以很容易得调用内嵌JMS provider，进行测试</p>\n<h3 id=\"Kafka\"><a href=\"#Kafka\" class=\"headerlink\" title=\"Kafka\"></a>Kafka</h3><p>Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群机来提供实时的消费。</p>\n<p>Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：</p>\n<ul>\n<li>通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。（文件追加的方式写入数据，过期的数据定期删除）</li>\n<li>高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息</li>\n<li>支持通过Kafka服务器和消费机集群来分区消息</li>\n<li>支持Hadoop并行数据加载</li>\n</ul>\n<p>Kafka相关概念：</p>\n<ul>\n<li>Broker:Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>\n<li>Topic:每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</li>\n<li>Partition:Parition是物理上的概念，每个Topic包含一个或多个Partition.</li>\n<li>Producer:负责发布消息到Kafka broker</li>\n<li>Consumer:消息消费者，向Kafka broker读取消息的客户端。</li>\n<li>Consumer Group:每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li>\n</ul>\n<p>一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用。</p>\n","categories":["Work"],"tags":["转载","消息队列"]},{"title":"NIO编程学习笔记(三)","url":"/2017/10/NIO%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%89/","content":"<h2 id=\"Java-NIO-Buffer\"><a href=\"#Java-NIO-Buffer\" class=\"headerlink\" title=\"Java NIO Buffer\"></a>Java NIO Buffer</h2><h3 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h3><p>Java NIO Buffer通常被用来与Channel交互，我们知道，数据从channel被读到buffer，从buffer被写入channel。<br>一个buffer是一个内存块，让我们写入数据，写完之后从中读取数据。这块内存被封装成NIO Buffer对象，并提供了一些方法让我们方便地操作这块内存。</p>\n<h3 id=\"Buffer基本用法\"><a href=\"#Buffer基本用法\" class=\"headerlink\" title=\"Buffer基本用法\"></a>Buffer基本用法</h3><p>Buffer读取和写入数据通常分以下4个过程：</p>\n<ul>\n<li>向buffer写入数据</li>\n<li>调用buffer.flip()</li>\n<li>从buffer读数据</li>\n<li>调用buffer.clear()或者buffer.compact()</li>\n</ul>\n<p>当我们向buffer写数据时，buffer会自动跟踪写了多少数据。当我们需要从buffer读数据时，需要将buffer从”writing mode”切换到”reading mode”，也就是要调用flip()方法。在reading mode下我们可以读取所有被写入buffer的数据。</p>\n<p>当我们已经读取完所有数据时，我们需要清空buffer，好让buffer可以重新被写入。有两种方法做到这点：clear()和compact()。clear()方法清空整个buffer；compact()方法只清空我们已经读过的数据，所有尚未读到的数据都会被移动到buffer的起始位置，接下来数据将会被写入到未读数据之后。</p>\n<p>下面是一个例子：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">RandomAccessFile aFile = <span class=\"keyword\">new</span> RandomAccessFile(<span class=\"string\">\"data/nio-data.txt\"</span>, <span class=\"string\">\"rw\"</span>);</div><div class=\"line\">FileChannel inChannel = aFile.getChannel();</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//create buffer with capacity of 48 bytes</span></div><div class=\"line\">ByteBuffer buf = ByteBuffer.allocate(<span class=\"number\">48</span>);</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">int</span> bytesRead = inChannel.read(buf); <span class=\"comment\">//read into buffer.</span></div><div class=\"line\"><span class=\"keyword\">while</span> (bytesRead != -<span class=\"number\">1</span>) &#123;</div><div class=\"line\"></div><div class=\"line\">  buf.flip();  <span class=\"comment\">//make buffer ready for read</span></div><div class=\"line\"></div><div class=\"line\">  <span class=\"keyword\">while</span>(buf.hasRemaining())&#123;</div><div class=\"line\">      System.out.print((<span class=\"keyword\">char</span>) buf.get()); <span class=\"comment\">// read 1 byte at a time</span></div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  buf.clear(); <span class=\"comment\">//make buffer ready for writing</span></div><div class=\"line\">  bytesRead = inChannel.read(buf);</div><div class=\"line\">&#125;</div><div class=\"line\">aFile.close();</div></pre></td></tr></table></figure></p>\n<h3 id=\"Buffer中的Capacity-Position和Limit\"><a href=\"#Buffer中的Capacity-Position和Limit\" class=\"headerlink\" title=\"Buffer中的Capacity,Position和Limit\"></a>Buffer中的Capacity,Position和Limit</h3><p>Buffer类有三个重要的属性，分别是：</p>\n<ul>\n<li>capacity</li>\n<li>position</li>\n<li>limit</li>\n</ul>\n<p>position和limit的含义在reading mode和writing mode下有所不同，但是capacity的含义无论哪种mode都是相同的。</p>\n<p><img src=\"buffers-modes.png\" alt=\"Buffer capacity, position and limit in write and read mode\" title=\"Buffer capacity, position and limit in write and read mode\"></p>\n<h4 id=\"capacity\"><a href=\"#capacity\" class=\"headerlink\" title=\"capacity\"></a>capacity</h4><p>作为一个内存块，Buffer有固定的大小，即capacity。一旦Buffer满了，我们必须先清理它(read the data, or clear it)，才能再次写入数据。</p>\n<h4 id=\"position\"><a href=\"#position\" class=\"headerlink\" title=\"position\"></a>position</h4><p>向Buffer写入数据是从一个特定的position开始的，最初position等于0。当不断地向Buffer写数据时，position就不断地向前移动。position最大等于capacity-1</p>\n<p>从Buffer读数据也是从一个给定的position开始的。调用flip()方法从writing mode切换到reading mode时，position的值被重置为0，随着我们不断地读数据，position的值也会不断地向前移动。</p>\n<h4 id=\"limit\"><a href=\"#limit\" class=\"headerlink\" title=\"limit\"></a>limit</h4><p>writing mode下，limit是我们能够写入Buffer的最大数据数，和capacity相等。</p>\n<p>reading mode下，limit是我们能够从Buffer读取的最大数据数。用flip()方法切换到reading mode时，limit被设置成writing mode下的position(见上图)。换言之，我们之前写入多少数据就可以读多少数据。</p>\n<h3 id=\"Buffer的实现类\"><a href=\"#Buffer的实现类\" class=\"headerlink\" title=\"Buffer的实现类\"></a>Buffer的实现类</h3><p>Buffer主要有以下8种实现类：</p>\n<ul>\n<li>ByteBuffer</li>\n<li>MappedByteBuffer</li>\n<li>CharBuffer</li>\n<li>DoubleBuffer</li>\n<li>FloatBuffer</li>\n<li>IntBuffer</li>\n<li>LongBuffer</li>\n<li>ShortBuffer</li>\n</ul>\n<h3 id=\"向Buffer写数据\"><a href=\"#向Buffer写数据\" class=\"headerlink\" title=\"向Buffer写数据\"></a>向Buffer写数据</h3><p>有两类向Buffer写入数据的方法：</p>\n<ul>\n<li>从Channel写入</li>\n<li>用put()方法写入</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> bytesRead = inChannel.read(buf); <span class=\"comment\">//read into buffer.</span></div><div class=\"line\"></div><div class=\"line\">buf.put(<span class=\"number\">127</span>);</div></pre></td></tr></table></figure>\n<p>更多put()方法的api可参考JavaDoc</p>\n<h3 id=\"flip-方法\"><a href=\"#flip-方法\" class=\"headerlink\" title=\"flip()方法\"></a>flip()方法</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> Buffer <span class=\"title\">flip</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    limit = position;</div><div class=\"line\">    position = <span class=\"number\">0</span>;</div><div class=\"line\">    mark = -<span class=\"number\">1</span>;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>flip()方法将Buffer从writing mode切换到reading mode。切换完成后，position标记着读的起始位置，limit标记着最多有多少数据可读。</p>\n<h3 id=\"从Buffer读数据\"><a href=\"#从Buffer读数据\" class=\"headerlink\" title=\"从Buffer读数据\"></a>从Buffer读数据</h3><p>有两类从Buffer读取数据的方法：</p>\n<ul>\n<li>从Channel读取</li>\n<li>用get()方法读取</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> bytesWritten = inChannel.write(buf); <span class=\"comment\">//read from buffer into channel.</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">byte</span> aByte = buf.get();</div></pre></td></tr></table></figure>\n<p>更多get()方法的api可参考JavaDoc</p>\n<h3 id=\"rewind-方法\"><a href=\"#rewind-方法\" class=\"headerlink\" title=\"rewind()方法\"></a>rewind()方法</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> Buffer <span class=\"title\">rewind</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    position = <span class=\"number\">0</span>;</div><div class=\"line\">    mark = -<span class=\"number\">1</span>;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>注意rewind()与flip()的唯一区别就是不改变limit</p>\n<h3 id=\"clear-和compact\"><a href=\"#clear-和compact\" class=\"headerlink\" title=\"clear()和compact()\"></a>clear()和compact()</h3><p>一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()和compact()方法来完成。</p>\n<p>如果调用clear()方法，position将被设为0，limit被设置成capacity的值。换句话说，Buffer被清空了，但是Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。如果Buffer中有一些未读的数据，调用clear()方法，这些数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。</p>\n<p>如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先写些数据，那么使用compact()方法。compact()方法将所有未读的数据拷贝到Buffer起始处，然后将position设为最后一个未读元素后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。</p>\n<h3 id=\"mark-和reset\"><a href=\"#mark-和reset\" class=\"headerlink\" title=\"mark()和reset()\"></a>mark()和reset()</h3><p>我们可以用mark()方法记住某个position，然后用reset()方法将position重置为刚刚mark的标记。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">buffer.mark();</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//call buffer.get() a couple of times, e.g. during parsing.</span></div><div class=\"line\"></div><div class=\"line\">buffer.reset();  <span class=\"comment\">//set position back to mark.</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"Java-NIO-Selector\"><a href=\"#Java-NIO-Selector\" class=\"headerlink\" title=\"Java NIO Selector\"></a>Java NIO Selector</h2><p>Selector可以监控一个或多个channel，查看哪些channel有感兴趣的事件就绪，这样的话单线程就可以管理多个channel，即多个网络连接。<br><img src=\"overview-selectors.png\" alt=\"Java NIO: A Thread uses a Selector to handle 3 Channels\" title=\"Java NIO: A Thread uses a Selector to handle 3 Channels\"></p>\n<h3 id=\"创建Selector\"><a href=\"#创建Selector\" class=\"headerlink\" title=\"创建Selector\"></a>创建Selector</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">Selector selector = Selector.open();</div></pre></td></tr></table></figure>\n<h3 id=\"把Channel注册到Selector上\"><a href=\"#把Channel注册到Selector上\" class=\"headerlink\" title=\"把Channel注册到Selector上\"></a>把Channel注册到Selector上</h3><p>为了让Selector能够监听Channel，我们必须把Channel注册到Selector上去。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">channel.configureBlocking(<span class=\"keyword\">false</span>);</div><div class=\"line\"></div><div class=\"line\">SelectionKey key = channel.register(selector, SelectionKey.OP_READ);</div></pre></td></tr></table></figure></p>\n<p>为了与Selector配合使用，Channel必须配置成non-blocking mode。这就意味着我们不能将FileChannel和Selector配合使用，因为FileChannel不能被配置成non-blocking mode。不过其它Channel可以。</p>\n<p>注意register()方法的第二个参数，这是”interest set”，也就是我们把Channel注册到Selector上面，让Selector时刻注意我们感兴趣的event。我们可以监听4种event：</p>\n<ul>\n<li>Connect</li>\n<li>Accept</li>\n<li>Read</li>\n<li>Write</li>\n</ul>\n<p>Channel触发了一个event说明该event已经就绪。一个Channel成功连接上另一台服务器称为”connect ready”；一个ServerSocketChannel准备好接受一个连接称为”accept ready”；一个有数据可读的Channel称为”read ready”；一个准备接受写入数据的Channel称为”write ready”。</p>\n<p>上面4中event可以用4个常量表示：</p>\n<ul>\n<li>SelectionKey.OP_CONNECT</li>\n<li>SelectionKey.OP_ACCEPT</li>\n<li>SelectionKey.OP_READ</li>\n<li>SelectionKey.OP_WRITE</li>\n</ul>\n<p>如果我们对不止一种event感兴趣，可以用<strong>OR运算符</strong>连接起来：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;</div></pre></td></tr></table></figure></p>\n<h3 id=\"SelectionKey\"><a href=\"#SelectionKey\" class=\"headerlink\" title=\"SelectionKey\"></a>SelectionKey</h3><p>register()方法返回一个SelectionKey对象，SelectionKey对象有下面几个property：</p>\n<ul>\n<li>The interest set</li>\n<li>The ready set</li>\n<li>The Channel</li>\n<li>The Selector</li>\n<li>An attached object (optional)</li>\n</ul>\n<p>下面分别详细说明这些property</p>\n<h4 id=\"Interest-Set\"><a href=\"#Interest-Set\" class=\"headerlink\" title=\"Interest Set\"></a>Interest Set</h4><p>Interest Set是我们感兴趣的事件的集合，我们可以通过SelectionKey读写Interest Set，看下例：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> interestSet = selectionKey.interestOps();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">boolean</span> isInterestedInAccept  = interestSet &amp; SelectionKey.OP_ACCEPT;</div><div class=\"line\"><span class=\"keyword\">boolean</span> isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;</div><div class=\"line\"><span class=\"keyword\">boolean</span> isInterestedInRead    = interestSet &amp; SelectionKey.OP_READ;</div><div class=\"line\"><span class=\"keyword\">boolean</span> isInterestedInWrite   = interestSet &amp; SelectionKey.OP_WRITE;</div></pre></td></tr></table></figure></p>\n<p>可以看到，用<strong>AND</strong>操作Interest Set和给定的SelectionKey常量，可以确定某个确定的事件是否在Interest Set中。</p>\n<h4 id=\"Ready-Set\"><a href=\"#Ready-Set\" class=\"headerlink\" title=\"Ready Set\"></a>Ready Set</h4><p>Ready Set是Channel已经准备就绪的操作的集合。在一次选择(Selection)之后，我们会得到这个Ready Set<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> readySet = selectionKey.readyOps();</div></pre></td></tr></table></figure></p>\n<p>我们可以通过与Interest Set类似的方法判断某个event是否在Ready Set中，也可以用下面的方法：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">boolean</span> isAcceptReady = selectionKey.isAcceptable();</div><div class=\"line\"><span class=\"keyword\">boolean</span> isConnectReady = selectionKey.isConnectable();</div><div class=\"line\"><span class=\"keyword\">boolean</span> isReadReady = selectionKey.isReadable();</div><div class=\"line\"><span class=\"keyword\">boolean</span> isWriteReady = selectionKey.isWritable();</div></pre></td></tr></table></figure></p>\n<h4 id=\"Channel和Selector\"><a href=\"#Channel和Selector\" class=\"headerlink\" title=\"Channel和Selector\"></a>Channel和Selector</h4><p>通过SelectionKey得到Channel和Selector是很简单的：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">Channel  channel  = selectionKey.channel();</div><div class=\"line\"></div><div class=\"line\">Selector selector = selectionKey.selector();</div></pre></td></tr></table></figure></p>\n<h4 id=\"Attaching-Objects\"><a href=\"#Attaching-Objects\" class=\"headerlink\" title=\"Attaching Objects\"></a>Attaching Objects</h4><p>可以将一个对象或者更多信息附加到SelectionKey上，这样就能方便地识别某个Channel。比如，可以附加与Channel一起使用的Buffer，或是包含聚集数据的某个对象。如下例：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">selectionKey.attach(theObject);</div><div class=\"line\"></div><div class=\"line\">Object attachedObj = selectionKey.attachment();</div></pre></td></tr></table></figure></p>\n<p>也可以在注册的时候直接附加一个对象到SelectionKey上：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject);</div></pre></td></tr></table></figure></p>\n<h3 id=\"通过Selector选择Channel\"><a href=\"#通过Selector选择Channel\" class=\"headerlink\" title=\"通过Selector选择Channel\"></a>通过Selector选择Channel</h3><p>向一个Selector注册一个或多个Channel后，我们就可以使用select()方法了。该方法返回我们感兴趣的事件(connect, accept, read or write)且这些事件已经准备就绪的那些Channel。比如，我们对“读就绪”的Channel感兴趣，select()方法会返回读事件已经就绪的那些Channel。</p>\n<p>有以下3种select()方法：</p>\n<ul>\n<li>int select()</li>\n<li>int select(long timeout)</li>\n<li>int selectNow()</li>\n</ul>\n<p>select()在有就绪事件的Channel出现之前会一直阻塞<br>select(long timeout)与select()相似，只不过最多阻塞timeout微秒<br>selectNow()不会阻塞，它会立即返回，不论是否有Channel就绪</p>\n<p>select()方法返回的int值表示有多少通道已经就绪，也就是自上次调用select()方法后有多少通道变成就绪状态。如果调用select()方法，这时有一个通道变成就绪状态，就会返回1，若再次调用select()方法，这时另一个通道就绪了，它会再次返回1。如果对第一个就绪的channel没有做任何操作，现在就有两个就绪的通道，但在每次select()方法调用之间，只有一个通道就绪了。</p>\n<h3 id=\"selectedKeys-方法\"><a href=\"#selectedKeys-方法\" class=\"headerlink\" title=\"selectedKeys()方法\"></a>selectedKeys()方法</h3><p>调用了select()方法后，可以通过selectKeys()方法得到“selected key set”，进而得到就绪的Channel.<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();</div></pre></td></tr></table></figure></p>\n<p>下面是一个比较完整的例子：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();</div><div class=\"line\"></div><div class=\"line\">Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span>(keyIterator.hasNext()) &#123;</div><div class=\"line\">    </div><div class=\"line\">    SelectionKey key = keyIterator.next();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span>(key.isAcceptable()) &#123;</div><div class=\"line\">        <span class=\"comment\">// a connection was accepted by a ServerSocketChannel.</span></div><div class=\"line\"></div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (key.isConnectable()) &#123;</div><div class=\"line\">        <span class=\"comment\">// a connection was established with a remote server.</span></div><div class=\"line\"></div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (key.isReadable()) &#123;</div><div class=\"line\">        <span class=\"comment\">// a channel is ready for reading</span></div><div class=\"line\"></div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (key.isWritable()) &#123;</div><div class=\"line\">        <span class=\"comment\">// a channel is ready for writing</span></div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    keyIterator.remove();</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>遍历所有在selected key set中的key，对每一个key都判断是否有就绪的事件发生。<br>注意最后的keyIterator.remove()，Selector不会自己从selected key set中移除SelectionKey实例，必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入selected key set中。</p>\n<p>SelectionKey.channel()方法返回的通道需要转型成我们要处理的类型，比如ServerSocketChannel,SocketChannel等。</p>\n<h3 id=\"wakeUp-方法\"><a href=\"#wakeUp-方法\" class=\"headerlink\" title=\"wakeUp()方法\"></a>wakeUp()方法</h3><p>如果select()方法一直阻塞，也就是一直没有就绪的Channel，这时可以用wakeUp()方法让线程从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可，阻塞在select()方法上的线程会立即返回。</p>\n<p>如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即wake up。</p>\n<h3 id=\"close-方法\"><a href=\"#close-方法\" class=\"headerlink\" title=\"close()方法\"></a>close()方法</h3><p>close()方法关闭一个Selector，并且使得所有注册到这个Selector上的SelectionKey实例全部失效，但是注册的Channel不会被关闭。</p>\n<p>###　一个完整的例子<br>打开一个Selector，把Channel注册到这个Selector上，然后监控事件是否就绪。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">Selector selector = Selector.open();</div><div class=\"line\"></div><div class=\"line\">channel.configureBlocking(<span class=\"keyword\">false</span>);</div><div class=\"line\"></div><div class=\"line\">SelectionKey key = channel.register(selector, SelectionKey.OP_READ);</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span>(<span class=\"keyword\">true</span>) &#123;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"keyword\">int</span> readyChannels = selector.select();</div><div class=\"line\"></div><div class=\"line\">  <span class=\"keyword\">if</span>(readyChannels == <span class=\"number\">0</span>) <span class=\"keyword\">continue</span>;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">  Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();</div><div class=\"line\"></div><div class=\"line\">  Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator();</div><div class=\"line\"></div><div class=\"line\">  <span class=\"keyword\">while</span>(keyIterator.hasNext()) &#123;</div><div class=\"line\"></div><div class=\"line\">    SelectionKey key = keyIterator.next();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span>(key.isAcceptable()) &#123;</div><div class=\"line\">        <span class=\"comment\">// a connection was accepted by a ServerSocketChannel.</span></div><div class=\"line\"></div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (key.isConnectable()) &#123;</div><div class=\"line\">        <span class=\"comment\">// a connection was established with a remote server.</span></div><div class=\"line\"></div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (key.isReadable()) &#123;</div><div class=\"line\">        <span class=\"comment\">// a channel is ready for reading</span></div><div class=\"line\"></div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (key.isWritable()) &#123;</div><div class=\"line\">        <span class=\"comment\">// a channel is ready for writing</span></div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    keyIterator.remove();</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n","categories":["Learning"],"tags":["NIO","网络编程"]},{"title":"NIO编程学习笔记(二)","url":"/2017/10/NIO%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C/","content":"<h2 id=\"Java-NIO-Channel\"><a href=\"#Java-NIO-Channel\" class=\"headerlink\" title=\"Java NIO Channel\"></a>Java NIO Channel</h2><h3 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h3><p>Java NIO Channel与流(stream)的概念相似，但有以下几点不同：</p>\n<ul>\n<li>我们可以同时对channel进行读写操作，而stream是单向的，读和写不能同时进行</li>\n<li>Channel可以异步地进行读写</li>\n<li>Channel总是向buffer读数据，或者从buffer写数据</li>\n</ul>\n<p><img src=\"overview-channels-buffers.png\" alt=\"Java NIO: Channels read data into Buffers, and Buffers write data into Channels\" title=\"Java NIO: Channels read data into Buffers, and Buffers write data into Channels\"></p>\n<p>前面提到过Channel主要有以下四种实现类：</p>\n<ul>\n<li>FileChannel</li>\n<li>DatagramChannel</li>\n<li>SocketChannel</li>\n<li>ServerSocketChannel</li>\n</ul>\n<p>FileChannel向文件读写数据<br>DatagramChannel通过UDP读写数据<br>SocketChannel通过TCP读写数据<br>ServerSocketChannel监听即将到来的TCP连接，就像Web服务器所做的那样。对每一个到来的TCP连接，都会创建一个SocketChannel</p>\n<h3 id=\"简单的关于Channel的例子\"><a href=\"#简单的关于Channel的例子\" class=\"headerlink\" title=\"简单的关于Channel的例子\"></a>简单的关于Channel的例子</h3><p>这个例子用了FileChannel将数据读到buffer中</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">RandomAccessFile aFile = <span class=\"keyword\">new</span> RandomAccessFile(System.getProperty(<span class=\"string\">\"user.dir\"</span>)+<span class=\"string\">\"/data/nio-data.txt\"</span>, <span class=\"string\">\"rw\"</span>);</div><div class=\"line\">FileChannel inChannel = aFile.getChannel();</div><div class=\"line\"></div><div class=\"line\">ByteBuffer buf = ByteBuffer.allocate(<span class=\"number\">48</span>);</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">int</span> bytesRead = inChannel.read(buf);</div><div class=\"line\"><span class=\"keyword\">while</span> (bytesRead != -<span class=\"number\">1</span>) &#123;</div><div class=\"line\"></div><div class=\"line\">    System.out.println(<span class=\"string\">\"Read \"</span> + bytesRead);</div><div class=\"line\">    buf.flip();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">while</span>(buf.hasRemaining())&#123;</div><div class=\"line\">        System.out.println(i + <span class=\"string\">\" \"</span>+(<span class=\"keyword\">char</span>) buf.get());</div><div class=\"line\">        i++;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    buf.clear();</div><div class=\"line\">    bytesRead = inChannel.read(buf);</div><div class=\"line\">&#125;</div><div class=\"line\">aFile.close();</div></pre></td></tr></table></figure>\n<h3 id=\"Channel的Scattering-read和Gathering-write\"><a href=\"#Channel的Scattering-read和Gathering-write\" class=\"headerlink\" title=\"Channel的Scattering read和Gathering write\"></a>Channel的Scattering read和Gathering write</h3><h4 id=\"Scatter-扩散\"><a href=\"#Scatter-扩散\" class=\"headerlink\" title=\"Scatter(扩散)\"></a>Scatter(扩散)</h4><p>Scattering read是指将1个channel的数据读到多个buffer中去，如图：<br><img src=\"scatter.png\" alt=\"Java NIO: Scattering Read\" title=\"Java NIO: Scattering Read\"></p>\n<p>下面是一个简单的Scattering read的例子<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">ByteBuffer header = ByteBuffer.allocate(<span class=\"number\">128</span>);</div><div class=\"line\">ByteBuffer body   = ByteBuffer.allocate(<span class=\"number\">1024</span>);</div><div class=\"line\"></div><div class=\"line\">ByteBuffer[] bufferArray = &#123; header, body &#125;;</div><div class=\"line\"></div><div class=\"line\">channel.read(bufferArray);</div></pre></td></tr></table></figure></p>\n<p>read()方法首先填充header，header满了之后再填充body<br>Scattering read只有在填满1个buffer之后才会去填充下一个，这意味着它不适合用在大小动态变化的场景。比如，我们有1个header和1个body，header的大小是固定的(e.g. 128 bytes)，那么使用Scattering read是可行的；如果header大小是可变的(e.g. 这次128 bytes，下次64 bytes了)，那么用Scattering read读到第一个buffer中的数据可能不是我们想要的。</p>\n<h4 id=\"Gather-聚集\"><a href=\"#Gather-聚集\" class=\"headerlink\" title=\"Gather(聚集)\"></a>Gather(聚集)</h4><p>Gathering write是指将多个buffer中的数据写入到1个channel中，如图：<br><img src=\"gather.png\" alt=\"Java NIO: Gathering Write\" title=\"Java NIO: Gathering Write\"></p>\n<p>下面是一个简单的Gathering write的例子<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">ByteBuffer header = ByteBuffer.allocate(<span class=\"number\">128</span>);</div><div class=\"line\">ByteBuffer body   = ByteBuffer.allocate(<span class=\"number\">1024</span>);</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//write data into buffers</span></div><div class=\"line\"></div><div class=\"line\">ByteBuffer[] bufferArray = &#123; header, body &#125;;</div><div class=\"line\"></div><div class=\"line\">channel.write(bufferArray);</div></pre></td></tr></table></figure></p>\n<p>与前面的read()方法类似，write()方法按顺序将buffer依次写入到channel中，当然，只写入buffer在position和limit之间的数据，比如buffer的capacity是128字节，但是position和limit之间只有58字节，那么只写入58字节。因此，Gathering write不存在像Scattering read那样不适合用在大小动态变化场景的问题。</p>\n<h3 id=\"Channel和Channel之间传输数据\"><a href=\"#Channel和Channel之间传输数据\" class=\"headerlink\" title=\"Channel和Channel之间传输数据\"></a>Channel和Channel之间传输数据</h3><p>Java NIO允许我们直接在两个channel之间传输数据，当然这样做的前提是其中一个channel是FileChannel类，因为FileChannel类提供了transferFrom()和transferTo()</p>\n<h4 id=\"transferFrom\"><a href=\"#transferFrom\" class=\"headerlink\" title=\"transferFrom()\"></a>transferFrom()</h4><p>FileChannel.transferFrom()将数据从源channel传输到FileChannel中。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">RandomAccessFile fromFile = <span class=\"keyword\">new</span> RandomAccessFile(<span class=\"string\">\"fromFile.txt\"</span>, <span class=\"string\">\"rw\"</span>);</div><div class=\"line\">FileChannel      fromChannel = fromFile.getChannel();</div><div class=\"line\"></div><div class=\"line\">RandomAccessFile toFile = <span class=\"keyword\">new</span> RandomAccessFile(<span class=\"string\">\"toFile.txt\"</span>, <span class=\"string\">\"rw\"</span>);</div><div class=\"line\">FileChannel      toChannel = toFile.getChannel();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">long</span> position = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">long</span> count    = fromChannel.size();</div><div class=\"line\"></div><div class=\"line\">toChannel.transferFrom(fromChannel, position, count);</div></pre></td></tr></table></figure>\n<p>参数position和count，告诉我们从目的文件的何处(position)开始写入数据，以及最多写入多少(count)字节的数据。如果源channel的字节数小于count，则有多少写入多少。<br>除此之外，如果源channel是SocketChannel的话，transferFrom()方法只会传输SocketChannel当前的数据，即使未来SocketChannel中还会有新的数据到来。因此，如果调用该方法时SocketChannel中的字节数少于count，传输的字节也少于count，即使未来SocketChannel中字节数多于count。</p>\n<h4 id=\"transferTo\"><a href=\"#transferTo\" class=\"headerlink\" title=\"transferTo()\"></a>transferTo()</h4><p>transferTo()方法将数据从FileChannel传输到目的channel。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">RandomAccessFile fromFile = <span class=\"keyword\">new</span> RandomAccessFile(<span class=\"string\">\"fromFile.txt\"</span>, <span class=\"string\">\"rw\"</span>);</div><div class=\"line\">FileChannel      fromChannel = fromFile.getChannel();</div><div class=\"line\"></div><div class=\"line\">RandomAccessFile toFile = <span class=\"keyword\">new</span> RandomAccessFile(<span class=\"string\">\"toFile.txt\"</span>, <span class=\"string\">\"rw\"</span>);</div><div class=\"line\">FileChannel      toChannel = toFile.getChannel();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">long</span> position = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">long</span> count    = fromChannel.size();</div><div class=\"line\"></div><div class=\"line\">fromChannel.transferTo(position, count, toChannel);</div></pre></td></tr></table></figure>\n<p>此例与上面的例子相似。与此同时，上面提到的SocketChannel的问题在这里依然存在。</p>\n<h3 id=\"SocketChannel\"><a href=\"#SocketChannel\" class=\"headerlink\" title=\"SocketChannel\"></a>SocketChannel</h3><p>Java NIO SocketChannel是连接到TCP网络套接字的通道，有两种方法可以创建它。</p>\n<ul>\n<li>我们打开SocketChannel并连接到互联网某服务器</li>\n<li>当有新的连接到达ServerSocketChannel时，一个SocketChannel会被创建</li>\n</ul>\n<h4 id=\"打开一个SocketChannel\"><a href=\"#打开一个SocketChannel\" class=\"headerlink\" title=\"打开一个SocketChannel\"></a>打开一个SocketChannel</h4><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">SocketChannel socketChannel = SocketChannel.open();</div><div class=\"line\">socketChannel.connect(<span class=\"keyword\">new</span> InetSocketAddress(<span class=\"string\">\"http://jenkov.com\"</span>, <span class=\"number\">80</span>));</div></pre></td></tr></table></figure>\n<h4 id=\"关闭一个SocketChannel\"><a href=\"#关闭一个SocketChannel\" class=\"headerlink\" title=\"关闭一个SocketChannel\"></a>关闭一个SocketChannel</h4><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">socketChannel.close();</div></pre></td></tr></table></figure>\n<h4 id=\"从SocketChannel读数据\"><a href=\"#从SocketChannel读数据\" class=\"headerlink\" title=\"从SocketChannel读数据\"></a>从SocketChannel读数据</h4><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">ByteBuffer buf = ByteBuffer.allocate(<span class=\"number\">48</span>);</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">int</span> bytesRead = socketChannel.read(buf);</div></pre></td></tr></table></figure>\n<p>read()方法将数据从SocketChannel读到buffer中，方法返回的int值为读到数据的字节数，如果返回为-1，说明读到了流的末尾(连接关闭了)。</p>\n<h4 id=\"向SocketChannel写数据\"><a href=\"#向SocketChannel写数据\" class=\"headerlink\" title=\"向SocketChannel写数据\"></a>向SocketChannel写数据</h4><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">String newData = <span class=\"string\">\"New String to write to file...\"</span> + System.currentTimeMillis();</div><div class=\"line\"></div><div class=\"line\">ByteBuffer buf = ByteBuffer.allocate(<span class=\"number\">48</span>);</div><div class=\"line\">buf.clear();</div><div class=\"line\">buf.put(newData.getBytes());</div><div class=\"line\"></div><div class=\"line\">buf.flip();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span>(buf.hasRemaining()) &#123;</div><div class=\"line\">    channel.write(buf);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>注意SocketChannel.write()方法的调用是在一个while循环中的。write()方法无法保证能写多少字节到SocketChannel，所以重复调用write()直到Buffer没有要写的字节为止。</p>\n<h4 id=\"非阻塞模式-Non-blocking-Mode\"><a href=\"#非阻塞模式-Non-blocking-Mode\" class=\"headerlink\" title=\"非阻塞模式(Non-blocking Mode)\"></a>非阻塞模式(Non-blocking Mode)</h4><p>我们可以把SocketChannel设置为非阻塞模式，这样我们就可以在异步模式下调用connect(),read(),write()</p>\n<p>connect()：<br>如果SocketChannel处于非阻塞模式，然后调用connect()方法，方法可能在连接建立完成之前就返回了。为了确定连接是否建立完成了，我们可以用finishConnect方法进行判断，如下例：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">socketChannel.configureBlocking(<span class=\"keyword\">false</span>);</div><div class=\"line\">socketChannel.connect(<span class=\"keyword\">new</span> InetSocketAddress(<span class=\"string\">\"http://jenkov.com\"</span>, <span class=\"number\">80</span>));</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span>(! socketChannel.finishConnect() )&#123;</div><div class=\"line\">    <span class=\"comment\">//wait, or do something else...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>write()：<br>非阻塞模式下write()方法可能在尚未写入任何数据时就返回了，因此需要在循环中调用write()方法。</p>\n<p>read()：<br>非阻塞模式下read()方法可能在尚未读取任何数据时就返回了，因此需要时刻关注read()方法的返回值，看读了多少字节。</p>\n<h4 id=\"非阻塞模式与Selector配合使用\"><a href=\"#非阻塞模式与Selector配合使用\" class=\"headerlink\" title=\"非阻塞模式与Selector配合使用\"></a>非阻塞模式与Selector配合使用</h4><p>非阻塞模式与Selector搭配会工作的更好，通过将一或多个SocketChannel注册到Selector，可以询问选择器哪个通道已经准备好了读取，写入等。后面会详细说明。</p>\n<h3 id=\"ServerSocketChannel\"><a href=\"#ServerSocketChannel\" class=\"headerlink\" title=\"ServerSocketChannel\"></a>ServerSocketChannel</h3><p>ServerSocketChannel可以监听即将到达的TCP连接，就像Java标准IO中的ServerSocket。<br>下面是一个例子：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</div><div class=\"line\"></div><div class=\"line\">serverSocketChannel.socket().bind(<span class=\"keyword\">new</span> InetSocketAddress(<span class=\"number\">9999</span>));</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span>(<span class=\"keyword\">true</span>)&#123;</div><div class=\"line\">    SocketChannel socketChannel = serverSocketChannel.accept();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">//do something with socketChannel...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"打开和关闭ServerSocketChannel\"><a href=\"#打开和关闭ServerSocketChannel\" class=\"headerlink\" title=\"打开和关闭ServerSocketChannel\"></a>打开和关闭ServerSocketChannel</h4><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</div><div class=\"line\"></div><div class=\"line\">serverSocketChannel.close();</div></pre></td></tr></table></figure>\n<h4 id=\"监听新到来的TCP连接\"><a href=\"#监听新到来的TCP连接\" class=\"headerlink\" title=\"监听新到来的TCP连接\"></a>监听新到来的TCP连接</h4><p>通过ServerSocketChannel.accept()方法监听新进来的连接。当accept()方法返回的时候,它返回一个包含新进来的连接的SocketChannel。因此,accept()方法会一直阻塞到有新连接到达。<br>我们通常不会仅仅监听一个连接，因此通常像下例这么做：Se<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">while</span>(<span class=\"keyword\">true</span>)&#123;</div><div class=\"line\">    SocketChannel socketChannel = serverSocketChannel.accept();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">//do something with socketChannel...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"非阻塞模式\"><a href=\"#非阻塞模式\" class=\"headerlink\" title=\"非阻塞模式\"></a>非阻塞模式</h4><p>ServerSocketChannel也可以被设置成非阻塞模式。在非阻塞模式下，ServerSocketChannel的accep()不论有没有连接到达都会立即返回，因此可能返回为null。看下例：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><div class=\"line\">ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</div><div class=\"line\"></div><div class=\"line\">serverSocketChannel.socket().bind(<span class=\"keyword\">new</span> InetSocketAddress(<span class=\"number\">9999</span>));</div><div class=\"line\">serverSocketChannel.configureBlocking(<span class=\"keyword\">false</span>);</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span>(<span class=\"keyword\">true</span>)&#123;</div><div class=\"line\">    SocketChannel socketChannel = serverSocketChannel.accept();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span>(socketChannel != <span class=\"keyword\">null</span>)&#123;</div><div class=\"line\">        <span class=\"comment\">//do something with socketChannel...</span></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n","categories":["Learning"],"tags":["NIO","网络编程"]},{"title":"NIO编程学习笔记(一)","url":"/2017/10/NIO%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80/","content":"<h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><h3 id=\"“伪异步”\"><a href=\"#“伪异步”\" class=\"headerlink\" title=\"“伪异步”\"></a>“伪异步”</h3><p>JAVA socket I/O是阻塞型的，为每个请求开一个线程，并发请求过多时必然消耗大量资源，JDK1.5之前没有NIO，怎样解决高并发问题呢？可以采用线程池和阻塞队列实现一种“伪异步”的IO通信框架。</p>\n<p>其实就是将客户端的socket封装成一个task任务(实现Runnable接口)然后投递到线程池中，线程池限制了系统为应用开辟的最大线程数，如果同时有大量的请求到来，超过了最大线程数，那么就会添加到阻塞队列中等待进入线程池。</p>\n<p>这种方法实际上仅仅能够解决高并发引起的服务器宕机问题，但是并不能提高效率。</p>\n<h3 id=\"阻塞和非阻塞\"><a href=\"#阻塞和非阻塞\" class=\"headerlink\" title=\"阻塞和非阻塞\"></a>阻塞和非阻塞</h3><p>BIO(Blocking I/O)和NIO(Non-Blocking I/O)的区别，其本质就是阻塞和非阻塞的区别。</p>\n<p>阻塞：应用程序在获取网络数据的时候，如果网络传输数据很慢，那么程序就一直等着，直到传输完毕为止。</p>\n<p>非阻塞：应用程序直接可以获取已经准备就绪好的数据，无需等待。</p>\n<p><strong>BIO为同步阻塞形式，NIO为同步非阻塞形式，NIO并没有实现异步，在JDK1.7之后，升级了NIO库包，支持异步非阻塞通信模型，即NIO2.0(AIO)</strong></p>\n<h3 id=\"同步和异步\"><a href=\"#同步和异步\" class=\"headerlink\" title=\"同步和异步\"></a>同步和异步</h3><p>同步和异步：同步和异步一般是面向操作系统与应用程序对IO操作的层面上来区别的。</p>\n<p>同步时，应用会直接参与IO读写操作，并且我们的应用程序会直接阻塞到某一个方法上，直到数据准备就绪；或者采用轮询的策略实时检查数据的就绪状态，如果就绪则获取数据。</p>\n<p>异步时，所有的IO读写操作交给操作系统处理，与我们的应用程序没有直接关系，程序不需要关系IO读写，当操作系统完成了IO读写操作时，会给我们应用程序发送通知，应用程序直接拿走数据即可。</p>\n<h2 id=\"NIO概述\"><a href=\"#NIO概述\" class=\"headerlink\" title=\"NIO概述\"></a>NIO概述</h2><blockquote>\n<p>从这里开始，后面所有关于NIO编程的内容均翻译自<a href=\"http://tutorials.jenkov.com/java-nio/index.html\" target=\"_blank\" rel=\"external\">java nio tutorial</a></p>\n</blockquote>\n<p>在标准IO中我们使用字节流和字符流，在NIO中我们使用Channel和Buffer。数据总是从channel被读到buffer，或者从buffer被写入channel中。Java NIO可以让我们以非阻塞的形式进行IO操作。比如一个线程可以将数据从channel读到buffer，与此同时，线程可以做其他事情而不必阻塞于IO操作。一旦数据被读到了buffer，线程可以回过头来处理这些数据。向channel中写入数据也是类似。除了Channel和Buffer之外，Selector也是NIO中最重要的概念。一个selector可以通过轮询的方式监听多个channel中的事件(比如：打开连接，数据到来等)，因此，只需单个线程就可以监控多个channel了。</p>\n<h3 id=\"Channels-and-Buffers\"><a href=\"#Channels-and-Buffers\" class=\"headerlink\" title=\"Channels and Buffers\"></a>Channels and Buffers</h3><p>在NIO中，所有的IO操作都是从一个channel开始的。Channel有点像流(stream)，数据可以从channel读到buffer，也可以从buffer写入到channel，如下图：<br><img src=\"overview-channels-buffers.png\" alt=\"Java NIO: Channels read data into Buffers, and Buffers write data into Channels\" title=\"Java NIO: Channels read data into Buffers, and Buffers write data into Channels\"></p>\n<p>Java NIO中主要有以下几种Channel的实现类：</p>\n<ul>\n<li>FileChannel</li>\n<li>DatagramChannel</li>\n<li>SocketChannel</li>\n<li>ServerSocketChannel</li>\n</ul>\n<p>可以看到，这些实现类涵盖了UDP/TCP newwork IO和file IO</p>\n<p>Java NIO中的Buffer实现类有以下几种：</p>\n<ul>\n<li>ByteBuffer</li>\n<li>CharBuffer</li>\n<li>DoubleBuffer</li>\n<li>FloatBuffer</li>\n<li>IntBuffer</li>\n<li>LongBuffer</li>\n<li>ShortBuffer</li>\n</ul>\n<p>可以看到，Buffer针对Java中除了Boolean的所有基本数据类型都实现了相应的Buffer类。<br>除了以上7种之外，还有一个MappedByteBuffer类。</p>\n<h3 id=\"Selector\"><a href=\"#Selector\" class=\"headerlink\" title=\"Selector\"></a>Selector</h3><p>Selector使得单线程就可以处理多个channel。当我们有许多连接(channel)同时打开，每个连接却只有少量的通信流量的时候(比如：聊天服务器)，这种特性是十分好用的。</p>\n<p>下图描述了一个线程利用Selector处理3个channel<br><img src=\"overview-selectors.png\" alt=\"Java NIO: A Thread uses a Selector to handle 3 Channel&#39;s\" title=\"Java NIO: A Thread uses a Selector to handle 3 Channel&#39;s\"></p>\n<p>使用Selector的时候必须把需要监听的channel注册到该Selector上，然后调用Selector的select()方法，该方法会一直阻塞，直到注册过的channels中有就绪的event发生，然后线程就会处理这些event。</p>\n","categories":["Learning"],"tags":["NIO","网络编程"]},{"title":"nginx学习笔记","url":"/2017/10/nginx%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"<h2 id=\"Nginx-Keepalived实现高可用\"><a href=\"#Nginx-Keepalived实现高可用\" class=\"headerlink\" title=\"Nginx + Keepalived实现高可用\"></a>Nginx + Keepalived实现高可用</h2><h3 id=\"Keepalived简介\"><a href=\"#Keepalived简介\" class=\"headerlink\" title=\"Keepalived简介\"></a>Keepalived简介</h3><p>Keepalived是一个高性能的服务器高可用或热备解决方案，Keepalived主要来防止服务器单点故障的发生，可以通过与Nginx的配合实现web服务端的高可用。<br>Keepalived以VRRP协议为实现基础，用VRRP协议来实现高可用性(HA)。VRRP(Virtual Router Redundancy Protocol)协议是用于实现路由器冗余的协议，VRRP协议将两台或多台路由器设备虚拟成一个设备，对外提供虚拟路由器IP(一个或多个)，如下图所示：</p>\n<p><img src=\"使用Keepalived实现Nginx高可用.png\" alt=\"使用Keepalived实现Nginx高可用\" title=\"使用Keepalived实现Nginx高可用\"></p>\n<p>Keepalived不仅能实现Nginx的高可用，还能实现Redis, Mysql等服务集群的高可用</p>\n<h3 id=\"VRRP工作机制\"><a href=\"#VRRP工作机制\" class=\"headerlink\" title=\"VRRP工作机制\"></a>VRRP工作机制</h3><p>在一个VRRP虚拟路由器中，有多台物理的VRRP路由器，但是这多台的物理的机器并不能同时工作，而是由一台称为MASTER的负责路由工作，其它的都是BACKUP，MASTER并非一成不变，VRRP让每个VRRP路由器参与竞选，最终获胜的就是MASTER。MASTER拥有一些特权，比如，拥有虚拟路由器的IP地址，我们的主机就是用这个IP地址作为静态路由的。拥有特权的MASTER要负责转发发送给网关地址的包和响应ARP请求。</p>\n<p>VRRP通过竞选协议来实现虚拟路由器的功能，所有的协议报文都是通过IP多播(multicast)包(多播地址224.0.0.18)形式发送的。虚拟路由器由VRID(范围0-255)和一组IP地址组成，对外表现为一个周知的MAC地址。所以，在一个虚拟路由 器中，不管谁是MASTER，对外都是相同的MAC和IP(称之为VIP)。客户端主机并不需要因为MASTER的改变而修改自己的路由配置，对客户端来说，这种主从的切换是透明的。</p>\n<p>在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP通告信息(VRRPAdvertisement message)，BACKUP不会抢占MASTER，除非它的优先级(priority)更高。当MASTER不可用时(BACKUP收不到通告信息)， 多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(&lt;1s)，以保证服务的连续性。由于安全性考虑，VRRP包使用了加密协议进行加密。</p>\n<h3 id=\"Keepalived工作原理\"><a href=\"#Keepalived工作原理\" class=\"headerlink\" title=\"Keepalived工作原理\"></a>Keepalived工作原理</h3><p><img src=\"Keepalived原理图.png\" alt=\"Keepalived原理图\" title=\"Keepalived原理图\"></p>\n<p>上图显示了一个应用场景，Keepalived虚拟出一个虚拟设备，该设备对外暴露IP；有两个nginx提供反向代理和负载均衡服务；在每台nginx服务器的物理机上都运行Keepalived服务。<br>我们假设nginx1是主节点，叫做MASTER；nginx2是备份节点，叫做BACKUP。</p>\n<p>下面分别是Keepalived在MASTER和BACKUP的配置文件，读懂了配置文件也就大致清楚了Keepalived的工作原理。</p>\n<p>首先是MASTER节点：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">! Configuration File for keepalived</div><div class=\"line\"></div><div class=\"line\">global_defs &#123;</div><div class=\"line\">   router_id nginx1 ##标识节点的字符串，通常为hostname</div><div class=\"line\">&#125;</div><div class=\"line\"> ## keepalived 会定时执行脚本并且对脚本的执行结果进行分析，动态调整vrrp_instance的优先级。</div><div class=\"line\"> ##这里的权重weight 是与下面的优先级priority有关，如果执行了一次检查脚本成功，则权重会-20，也就是由100 - 20 变成了80，</div><div class=\"line\"> ##Master 的优先级为80 就低于了Backup的优先级90，那么会进行自动的主备切换。</div><div class=\"line\"> ##如果脚本执行结果为0并且weight配置的值大于0，则优先级会相应增加。</div><div class=\"line\"> ##如果脚本执行结果不为0 并且weight配置的值小于0，则优先级会相应减少。</div><div class=\"line\">vrrp_script chk_nginx &#123;</div><div class=\"line\">    script &quot;/etc/keepalived/nginx_check.sh&quot; ##执行脚本位置</div><div class=\"line\">    interval 2 ##检测时间间隔2s</div><div class=\"line\">    weight -20 ## 如果条件成立则权重减20（-20）</div><div class=\"line\">&#125;</div><div class=\"line\"> ## 定义虚拟路由 VI_1为自定义标识。</div><div class=\"line\">vrrp_instance VI_1 &#123;</div><div class=\"line\">    state MASTER   ## 主节点为MASTER，备份节点为BACKUP</div><div class=\"line\">    ## 绑定虚拟IP的网络接口（网卡），与本机IP地址所在的网络接口相同（我这里是eth0）</div><div class=\"line\">    interface eth0  </div><div class=\"line\">    virtual_router_id 100  ## 虚拟路由ID号，同一个 vrrp_instance,MASTER 和 BACKUP 的 virtual_router_id 是一致的,同时在整个 vrrp 内是唯一的。</div><div class=\"line\">    mcast_src_ip 192.168.1.172  ## 本机ip地址</div><div class=\"line\">    priority 100  ##优先级配置（0-254的值）</div><div class=\"line\">    Nopreempt  ##不主动抢占资源，只在MASTER这台优先级高的设置，BACKUP不设置</div><div class=\"line\">    advert_int 1 ## 组播信息发送间隔，两个节点必须配置一致，默认1s</div><div class=\"line\">    authentication &#123;  </div><div class=\"line\">        auth_type PASS</div><div class=\"line\">        auth_pass mypassword ## 同一个vrrp_instance中MASTER 与 BACKUP 使用相同的密码才能正常通信。</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    track_script &#123;</div><div class=\"line\">        chk_nginx</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    virtual_ipaddress &#123;</div><div class=\"line\">        192.168.1.170 ## 虚拟ip(vip)，可以指定多个</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>然后是BACKUP节点：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">! Configuration File for keepalived</div><div class=\"line\"></div><div class=\"line\">global_defs &#123;</div><div class=\"line\">   router_id nginx2</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">vrrp_script chk_nginx &#123;</div><div class=\"line\">    script &quot;/etc/keepalived/nginx_check.sh&quot;</div><div class=\"line\">    interval 2</div><div class=\"line\">    weight -20</div><div class=\"line\">&#125;</div><div class=\"line\">vrrp_instance VI_1 &#123;</div><div class=\"line\">    state BACKUP</div><div class=\"line\">    interface eth0</div><div class=\"line\">    virtual_router_id 100 ##必须与MASTER一致</div><div class=\"line\">    mcast_src_ip 192.168.1.173</div><div class=\"line\">    priority 90 ##优先级配置</div><div class=\"line\">    advert_int 1</div><div class=\"line\">    authentication &#123;</div><div class=\"line\">        auth_type PASS</div><div class=\"line\">        auth_pass mypassword</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    track_script &#123;</div><div class=\"line\">        chk_nginx</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    virtual_ipaddress &#123;</div><div class=\"line\">        192.168.1.170</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>最后是nginx_check.sh脚本：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\">A=`ps -C nginx –no-header |wc <span class=\"_\">-l</span>`</div><div class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$A</span> <span class=\"_\">-eq</span> 0 ];<span class=\"keyword\">then</span></div><div class=\"line\">    /usr/<span class=\"built_in\">local</span>/nginx/sbin/nginx</div><div class=\"line\">    sleep 2</div><div class=\"line\">    <span class=\"keyword\">if</span> [ `ps -C nginx --no-header |wc <span class=\"_\">-l</span>` <span class=\"_\">-eq</span> 0 ];<span class=\"keyword\">then</span></div><div class=\"line\">        killall keepalived</div><div class=\"line\">    <span class=\"keyword\">fi</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure></p>\n<p>再来看一遍这张图：<br><img src=\"Keepalived原理图.png\" alt=\"Keepalived原理图\" title=\"初始时刻MASTER的优先级是100，BACKUP是90\"></p>\n<p>初始时刻MASTER的优先级是100，BACKUP是90，因此Keepalived会把到来的请求打到优先级大的机器上，也就是打到MASTER上。与此同时，Keepalived会每隔2秒执行一次指定的脚本，即nginx_check.sh脚本，这个脚本首先计算机器中nginx进程的数量，如果数量等于0，说明这台物理机上nginx挂掉了，那么尝试启动nginx，休眠2秒钟之后，再次统计nginx进程数量，如果数量依然是0，说明启动nginx不成功，那么就把该物理机上的Keepalived服务杀掉。如果MASTER上的nginx挂掉且启动失败，那么根据配置文件中的weight值是-20，把MASTER的priority值减去20结果等于80。根据VRRP协议，MASTER要定时向所有BACKUP发送VRRP通告信息，由于MASTER上的Keepalived服务被杀掉了，无法发送VRRP通告，收不到通告的BACKUP会接管虚拟IP，也就是实现了主从切换，在这里就是由nginx2取代了nginx1。</p>\n<h3 id=\"最后说明一点\"><a href=\"#最后说明一点\" class=\"headerlink\" title=\"最后说明一点\"></a>最后说明一点</h3><p>Keepalived还可以实现mysql，redis等集群的高可用，配置与nginx类似，不同的是执行的脚本不同。比如mysql，每隔2秒执行一次mysql_check.sh脚本，脚本的大致流程就是检查mysql服务是否挂掉了，挂掉了就尝试启动，启动不了就杀掉Keepalived服务，根据VRRP协议实现主从切换，都是类似的。</p>\n","categories":["Learning"],"tags":["nginx","Keepalived","高可用"]},{"title":"Shell脚本学习笔记","url":"/2017/10/Shell%E8%84%9A%E6%9C%AC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"<p>此篇为Shell脚本的学习笔记，方便用到的时候查阅。</p>\n<h3 id=\"shell中的命令不一定要用绝对路径，比如-bin-pwd-和-pwd-均可\"><a href=\"#shell中的命令不一定要用绝对路径，比如-bin-pwd-和-pwd-均可\" class=\"headerlink\" title=\"shell中的命令不一定要用绝对路径，比如 /bin/pwd 和 pwd 均可\"></a>shell中的命令不一定要用绝对路径，比如 /bin/pwd 和 pwd 均可</h3><h3 id=\"Linux在以下几个目录下存放命令：-bin、-sbin、-usr-bin、-usr-sbin\"><a href=\"#Linux在以下几个目录下存放命令：-bin、-sbin、-usr-bin、-usr-sbin\" class=\"headerlink\" title=\"Linux在以下几个目录下存放命令： /bin、/sbin、/usr/bin、/usr/sbin\"></a>Linux在以下几个目录下存放命令： /bin、/sbin、/usr/bin、/usr/sbin</h3><p>这几个目录的区别如下：</p>\n<ul>\n<li>/bin 是系统的一些指令。bin为binary的简写主要放置一些系统的必备执行档例如:cat、cp、chmod df、dmesg、gzip、kill、ls、mkdir、more、mount、rm、su、tar等。</li>\n<li>/sbin 一般是指超级用户指令。主要放置一些系统管理的必备程式例如:cfdisk、dhcpcd、dump、e2fsck、fdisk、halt、ifconfig、ifup、 ifdown、init、insmod、lilo、lsmod、mke2fs、modprobe、quotacheck、reboot、rmmod、 runlevel、shutdown等。</li>\n<li>/usr/bin 是你在后期安装的一些软件的运行脚本。主要放置一些应用软体工具的必备执行档例如c++、g++、gcc、chdrv、diff、dig、du、eject、elm、free、gnome<em>、 gzip、htpasswd、kfm、ktop、last、less、locale、m4、make、man、mcopy、ncftp、 newaliases、nslookup passwd、quota、smb</em>、wget等。</li>\n<li>/usr/sbin 放置一些用户安装的系统管理的必备程式例如:dhcpd、httpd、imap、in.*d、inetd、lpd、named、netconfig、nmbd、samba、sendmail、squid、swap、tcpd、tcpdump等。</li>\n</ul>\n<p>如果新装的系统，运行一些很正常的诸如：shutdown，fdisk的命令时，悍然提示：bash:command not found。那么首先就要考虑root 的$PATH里是否已经包含了这些环境变量。<br>可以查看PATH，如果是：PATH=$PATH:$HOME/bin则需要添加成如下：<br><code>PATH=$PATH:$HOME/bin:/sbin:/usr/bin:/usr/sbin</code></p>\n<blockquote>\n<p>摘自<a href=\"http://blog.csdn.net/kkdelta/article/details/7708250\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/kkdelta/article/details/7708250</a></p>\n</blockquote>\n<h3 id=\"vim下的字符串替换：\"><a href=\"#vim下的字符串替换：\" class=\"headerlink\" title=\"vim下的字符串替换：\"></a>vim下的字符串替换：</h3><p>%s/old/new  把每一行中的第一个old替换成new<br>%s/old/new/g  把每一行中的所有old替换成new<br>如果在要被替换的字符串中出现分隔符/，那么可以用加号+代替/     比如：%s+/test/file1.info+/test/file1.java/g  就是把每一行中的所有/test/file1.info替换成/test/file1.java</p>\n<h3 id=\"Shell中有两类变量：临时变量和永久变量\"><a href=\"#Shell中有两类变量：临时变量和永久变量\" class=\"headerlink\" title=\"Shell中有两类变量：临时变量和永久变量\"></a>Shell中有两类变量：临时变量和永久变量</h3><p>临时变量是Shell程序内部定义的，适用范围仅限于定义它的程序，包括用户自定义变量、位置变量。<br>永久变量是环境变量，使用范围为Linux系统。<br>set命令输出系统中的所有环境变量，unset命令删除指定的变量</p>\n<h3 id=\"Shell中的特殊变量：\"><a href=\"#Shell中的特殊变量：\" class=\"headerlink\" title=\"Shell中的特殊变量：\"></a>Shell中的特殊变量：</h3><ul>\n<li>$*  这个程序中的所有参数</li>\n<li>$#  这个程序的参数个数</li>\n<li>$$  这个程序的PID</li>\n<li>$!  执行上一个后台命令的PID</li>\n<li>$?  执行上一个命令的返回值</li>\n<li>$(0-9)  显示位置变量</li>\n</ul>\n<h3 id=\"Shell中双引号和单引号的区别：\"><a href=\"#Shell中双引号和单引号的区别：\" class=\"headerlink\" title=\"Shell中双引号和单引号的区别：\"></a>Shell中双引号和单引号的区别：</h3><p>shell会把双引号里的变量值打印出来，而单引号不会去翻译变量，直接所见即所得。<br><img src=\"双引号和单引号的区别.png\" alt=\"双引号和单引号的区别\" title=\"双引号和单引号的区别\"></p>\n<h3 id=\"命令替换符号\"><a href=\"#命令替换符号\" class=\"headerlink\" title=\"命令替换符号``\"></a>命令替换符号``</h3><p>``不是单引号，在键盘中的数字1之前<br><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#!/bin/sh</span></div><div class=\"line\">DATE=`/bin/date +%Y%m%d`</div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"TODAY IS <span class=\"variable\">$DATE</span>\"</span></div></pre></td></tr></table></figure></p>\n<p>输出<code>TODAY IS 20171020</code><br>``里面是命令执行的结果</p>\n<h3 id=\"test条件控制语句\"><a href=\"#test条件控制语句\" class=\"headerlink\" title=\"test条件控制语句\"></a>test条件控制语句</h3><ul>\n<li>test -d file    指定文件是否是目录<br>   test -f file    指定文件是否是常规文件<br>   test -x file    文件是否可执行<br>   test -r file    文件是否可读<br>   test -w file    文件是否可写<br>   test -a file    文件是否存在<br>   test -s file    文件大小是否非0</li>\n</ul>\n<p>test条件控制语句可以简写为[]的形式<br>比如：<code>if test -d file.txt</code>等价于<code>if [ -d file.txt ]</code><br>注意空格：if’空格’[‘空格’-d file.txt’空格’]</p>\n<h3 id=\"Shell中用-a表示逻辑与，用-o表示逻辑或\"><a href=\"#Shell中用-a表示逻辑与，用-o表示逻辑或\" class=\"headerlink\" title=\"Shell中用-a表示逻辑与，用-o表示逻辑或\"></a>Shell中用-a表示逻辑与，用-o表示逻辑或</h3><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#!/bin/sh</span></div><div class=\"line\"><span class=\"comment\"># read variables from keyboard</span></div><div class=\"line\"><span class=\"built_in\">read</span> a b c</div><div class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$a</span> <span class=\"_\">-eq</span> <span class=\"variable\">$b</span> <span class=\"_\">-a</span> <span class=\"variable\">$b</span> <span class=\"_\">-ne</span> <span class=\"variable\">$c</span> -o <span class=\"variable\">$c</span> -le <span class=\"variable\">$a</span> ]</div><div class=\"line\"><span class=\"keyword\">then</span>\t<span class=\"built_in\">echo</span> <span class=\"string\">\"success\"</span></div><div class=\"line\"><span class=\"keyword\">else</span>\t<span class=\"built_in\">echo</span> <span class=\"string\">\"fail\"</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure>\n<h3 id=\"sh-x表示以debug的方式执行脚本，方便debug\"><a href=\"#sh-x表示以debug的方式执行脚本，方便debug\" class=\"headerlink\" title=\"sh -x表示以debug的方式执行脚本，方便debug\"></a>sh -x表示以debug的方式执行脚本，方便debug</h3><p><code>-x xtrace        Write each command to standard error (preceded by a ‘+ ’) before it is executed.  Useful for debugging.</code></p>\n<h3 id=\"Shell脚本的流程控制\"><a href=\"#Shell脚本的流程控制\" class=\"headerlink\" title=\"Shell脚本的流程控制\"></a>Shell脚本的流程控制</h3><p>参见另一篇博文：<a href=\"https://xiangxianzui.github.io/2017/10/Shell%E8%84%9A%E6%9C%AC%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/\">Shell脚本流程控制</a></p>\n","categories":["Learning"],"tags":["Linux","Shell"]},{"title":"关于Bloom Filter","url":"/2017/10/%E5%85%B3%E4%BA%8EBloom-Filter/","content":"<p>Bloom Filter是一种空间效率很高的随机数据结构，用来表示一个集合，主要的应用是判断一个元素是否属于这个集合，适用于能容忍一定错误率的场合下，比如网络爬虫里的url去重。</p>\n<p>最近看到了一个写的非常好的关于Bloom Filter的文章系列，读完之后受益匪浅，写篇博文记录之。</p>\n<h3 id=\"Bloom-Filter概念和原理\"><a href=\"#Bloom-Filter概念和原理\" class=\"headerlink\" title=\"Bloom Filter概念和原理\"></a>Bloom Filter概念和原理</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1495500\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1495500</a></p>\n<h3 id=\"从哈希存储到Bloom-Filter\"><a href=\"#从哈希存储到Bloom-Filter\" class=\"headerlink\" title=\"从哈希存储到Bloom Filter\"></a>从哈希存储到Bloom Filter</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1496329\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1496329</a></p>\n<h3 id=\"应用Bloom-Filter的几个技巧\"><a href=\"#应用Bloom-Filter的几个技巧\" class=\"headerlink\" title=\"应用Bloom Filter的几个技巧\"></a>应用Bloom Filter的几个技巧</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1497361\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1497361</a></p>\n<h3 id=\"Counting-Bloom-Filter\"><a href=\"#Counting-Bloom-Filter\" class=\"headerlink\" title=\"Counting Bloom Filter\"></a>Counting Bloom Filter</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1498283\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1498283</a></p>\n<h3 id=\"Partial-Bloom-Filter\"><a href=\"#Partial-Bloom-Filter\" class=\"headerlink\" title=\"Partial Bloom Filter\"></a>Partial Bloom Filter</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1502910\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1502910</a></p>\n<h3 id=\"Compressed-Bloom-Filter\"><a href=\"#Compressed-Bloom-Filter\" class=\"headerlink\" title=\"Compressed Bloom Filter\"></a>Compressed Bloom Filter</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1505299\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1505299</a></p>\n<h3 id=\"Perfect-Hashing-VS-Bloom-Filter\"><a href=\"#Perfect-Hashing-VS-Bloom-Filter\" class=\"headerlink\" title=\"Perfect Hashing VS. Bloom Filter\"></a>Perfect Hashing VS. Bloom Filter</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1519383\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1519383</a></p>\n<h3 id=\"Bloom-Filter应用之Web-Cache-Sharing\"><a href=\"#Bloom-Filter应用之Web-Cache-Sharing\" class=\"headerlink\" title=\"Bloom Filter应用之Web Cache Sharing\"></a>Bloom Filter应用之Web Cache Sharing</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1531423\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1531423</a></p>\n<h3 id=\"Bloom-Filter-Counting-Bloom-Filter和Dynamic-Count-Filter源码下载\"><a href=\"#Bloom-Filter-Counting-Bloom-Filter和Dynamic-Count-Filter源码下载\" class=\"headerlink\" title=\"Bloom Filter, Counting Bloom Filter和Dynamic Count Filter源码下载\"></a>Bloom Filter, Counting Bloom Filter和Dynamic Count Filter源码下载</h3><p><a href=\"http://blog.csdn.net/jiaomeng/article/details/1619321\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/jiaomeng/article/details/1619321</a></p>\n<blockquote>\n<p>注：该文章系列的作者为<a href=\"http://blog.csdn.net/jiaomeng\" target=\"_blank\" rel=\"external\">焦萌</a></p>\n</blockquote>\n","categories":["Work"],"tags":["Bloom Filter","转载"]},{"title":"(转载)一致性哈希","url":"/2017/10/%E8%BD%AC%E8%BD%BD-%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/","content":"<blockquote>\n<p>原文: <a href=\"http://blog.csdn.net/cywosp/article/details/23397179\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/cywosp/article/details/23397179</a></p>\n</blockquote>\n<p>一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 </p>\n<p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：<br>1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。<br>2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。<br>3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。<br>4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</p>\n<p>在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的.</p>\n<h3 id=\"环形Hash空间\"><a href=\"#环形Hash空间\" class=\"headerlink\" title=\"环形Hash空间\"></a>环形Hash空间</h3><p>按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图:</p>\n<p><img src=\"img_1.png\" alt=\"环形Hash空间\" title=\"环形Hash空间\"></p>\n<h3 id=\"把数据通过一定的hash算法处理后映射到环上\"><a href=\"#把数据通过一定的hash算法处理后映射到环上\" class=\"headerlink\" title=\"把数据通过一定的hash算法处理后映射到环上\"></a>把数据通过一定的hash算法处理后映射到环上</h3><p>现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图：<br>    Hash(object1) = key1；<br>    Hash(object2) = key2；<br>    Hash(object3) = key3；<br>    Hash(object4) = key4；<br><img src=\"img_2.png\" alt=\"将数据映射到Hash环上\" title=\"将数据映射到Hash环上\"></p>\n<h3 id=\"将机器通过hash算法映射到环上\"><a href=\"#将机器通过hash算法映射到环上\" class=\"headerlink\" title=\"将机器通过hash算法映射到环上\"></a>将机器通过hash算法映射到环上</h3><p>在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。<br>假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下：<br>Hash(NODE1) = KEY1;<br>Hash(NODE2) = KEY2;<br>Hash(NODE3) = KEY3;<br><img src=\"img_3.png\" alt=\"将机器映射到Hash环上\" title=\"将机器映射到Hash环上\"><br>通过上图可以看出对象(数据)与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。</p>\n<h3 id=\"机器的删除与添加\"><a href=\"#机器的删除与添加\" class=\"headerlink\" title=\"机器的删除与添加\"></a>机器的删除与添加</h3><p>普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。</p>\n<ol>\n<li><p>节点（机器）的删除<br>以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图：<br><img src=\"img_4.png\" alt=\"节点（机器）的删除\" title=\"节点（机器）的删除\"></p>\n</li>\n<li><p>节点（机器）的添加<br>如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图：<br><img src=\"img_5.png\" alt=\"节点（机器）的添加\" title=\"节点（机器）的添加\"><br>通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。</p>\n</li>\n</ol>\n<h3 id=\"平衡性\"><a href=\"#平衡性\" class=\"headerlink\" title=\"平衡性\"></a>平衡性</h3><p>根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。<br>——“虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。<br>以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下：<br><img src=\"img_6.png\" alt=\"加入虚拟节点\" title=\"加入虚拟节点\"></p>\n<p>根据上图可知对象的映射关系：object1-&gt;NODE1-1，object2-&gt;NODE1-2，object3-&gt;NODE3-2，object4-&gt;NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图：<br><img src=\"img_6.png\" alt=\"虚拟节点到实际节点的转换\" title=\"虚拟节点到实际节点的转换\"></p>\n<p>“虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值：<br>Hash(“192.168.1.100”);<br>引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值：<br>Hash(“192.168.1.100#1”); // NODE1-1<br>Hash(“192.168.1.100#2”); // NODE1-2</p>\n<hr>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Work"],"tags":["转载","负载均衡"]},{"title":"Shell脚本流程控制","url":"/2017/10/Shell%E8%84%9A%E6%9C%AC%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","content":"<h3 id=\"if-else\"><a href=\"#if-else\" class=\"headerlink\" title=\"if-else\"></a>if-else</h3><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/sh</span></div><div class=\"line\">a=1</div><div class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$1</span>=<span class=\"variable\">$a</span> ]</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\"> <span class=\"built_in\">echo</span> <span class=\"string\">\"you input 1\"</span></div><div class=\"line\"><span class=\"keyword\">elif</span> [ <span class=\"variable\">$1</span>=2 ]</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\"> <span class=\"built_in\">echo</span> <span class=\"string\">\"you input 2\"</span></div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\"> <span class=\"comment\">#do nothing</span></div><div class=\"line\"> <span class=\"built_in\">echo</span> <span class=\"string\">\" you input <span class=\"variable\">$1</span>\"</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure>\n<p>如果某个条件下的执行体为空, 就不能写这个条件，否则会报错；<br> [ ] 两边一定要加空格, 否则会报错；<br>注意: 实际上这里的[]是test命令的一种形式, [是系统的一个内置命令,存在路径是/bin/[,它是调用test命令的标识, 右中括号是关闭条件判断的标识。</p>\n<h3 id=\"case\"><a href=\"#case\" class=\"headerlink\" title=\"case\"></a>case</h3><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/sh</span></div><div class=\"line\">input=<span class=\"variable\">$1</span></div><div class=\"line\"><span class=\"keyword\">case</span> <span class=\"variable\">$input</span> <span class=\"keyword\">in</span></div><div class=\"line\">        1 | 0)</div><div class=\"line\">        str=<span class=\"string\">\"一or零\"</span>;;</div><div class=\"line\">        2)</div><div class=\"line\">        str=<span class=\"string\">\"二\"</span>;;</div><div class=\"line\">        3)</div><div class=\"line\">        str=<span class=\"string\">\"三\"</span>;;</div><div class=\"line\">        *)</div><div class=\"line\">        str=<span class=\"variable\">$input</span>;;</div><div class=\"line\"><span class=\"keyword\">esac</span></div></pre></td></tr></table></figure>\n<p>case 1 | 0代表逻辑或;<br>;;相当于其它语言中的break;<br>每个pattern之后记得加)</p>\n<h3 id=\"for\"><a href=\"#for\" class=\"headerlink\" title=\"for\"></a>for</h3><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> *.txt</div><div class=\"line\"><span class=\"keyword\">do</span></div><div class=\"line\"> open <span class=\"variable\">$file</span></div><div class=\"line\"><span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n<p>[]括起来的 in list, 为可选部分, 如果省略in list则默认为in “$@”, 即你执行此命令时传入的参数列表；</p>\n<h3 id=\"while\"><a href=\"#while\" class=\"headerlink\" title=\"while\"></a>while</h3><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/sh</span></div><div class=\"line\">i=0</div><div class=\"line\"><span class=\"keyword\">while</span> ((i&lt;5));</div><div class=\"line\"><span class=\"keyword\">do</span></div><div class=\"line\"> ((i++))</div><div class=\"line\"> <span class=\"built_in\">echo</span> <span class=\"string\">\"i=<span class=\"variable\">$i</span>\"</span></div><div class=\"line\"><span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n<h3 id=\"until\"><a href=\"#until\" class=\"headerlink\" title=\"until\"></a>until</h3><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/sh</span></div><div class=\"line\">i=5</div><div class=\"line\">until ((i==0))</div><div class=\"line\"><span class=\"keyword\">do</span></div><div class=\"line\"> ((i--))</div><div class=\"line\"> <span class=\"built_in\">echo</span> <span class=\"string\">\"i=<span class=\"variable\">$i</span>\"</span></div><div class=\"line\"><span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n<h3 id=\"函数\"><a href=\"#函数\" class=\"headerlink\" title=\"函数\"></a>函数</h3><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">function</span> <span class=\"function\"><span class=\"title\">funcname</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\"> <span class=\"keyword\">do</span> something</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>或者<br><figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"title\">funcname</span></span> ()</div><div class=\"line\">&#123;</div><div class=\"line\"> <span class=\"keyword\">do</span> something</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/sh</span></div><div class=\"line\"><span class=\"comment\"># ad.sh 计算sum</span></div><div class=\"line\"><span class=\"function\"><span class=\"title\">add</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\"> <span class=\"built_in\">let</span> <span class=\"string\">\"sum=<span class=\"variable\">$1</span>+<span class=\"variable\">$2</span>\"</span></div><div class=\"line\"> <span class=\"built_in\">return</span> <span class=\"variable\">$sum</span></div><div class=\"line\">&#125;</div><div class=\"line\"> </div><div class=\"line\">add <span class=\"variable\">$1</span> <span class=\"variable\">$2</span></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"sum=$?\"</span></div></pre></td></tr></table></figure>\n<p>\\$?保存的是上一条命令的返回值，\\$@代表所有参数的内容, \\$#代表所有参数的个数, \\$0代表脚本的名称, \\$1代表第一个参数的值.<br>函数必须先定义后使用；<br>如果在函数中使用exit会退出脚本, 如果想退回到原本函数调用的地方, 则可使用return；</p>\n<hr>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Learning"],"tags":["Linux","Shell"]},{"title":"nginx配置样例","url":"/2017/10/nginx%E9%85%8D%E7%BD%AE%E6%A0%B7%E4%BE%8B/","content":"<p>nginx配置样例，详情请阅读全文。</p>\n<a id=\"more\"></a>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">upstream twell &#123;</div><div class=\"line\">        server 127.0.0.1:8888;</div><div class=\"line\">        server l-tw1.f.dev.cn6.qunar.com:8888;</div><div class=\"line\">        server l-tw2.f.dev.cn6.qunar.com:8888;</div><div class=\"line\">        server l-tw4.f.dev.cn6.qunar.com:8888;</div><div class=\"line\">        healthcheck_enabled;</div><div class=\"line\">        healthcheck_delay 3000;</div><div class=\"line\">        healthcheck_timeout 1000;</div><div class=\"line\">        healthcheck_failcount 2;</div><div class=\"line\">        healthcheck_send &apos;GET /healthcheck.html HTTP/1.0&apos; &apos;Host: qunar.com&apos; &apos;Connection: close&apos;;</div><div class=\"line\">    &#125;</div><div class=\"line\">     server &#123;</div><div class=\"line\">        listen       80;</div><div class=\"line\">        server_name  flightlcf.qunar.com;</div><div class=\"line\">        gzip                    on;</div><div class=\"line\">        gzip_disable            &quot;MSIE [1-6]&quot;;</div><div class=\"line\">        gzip_http_version       1.1;</div><div class=\"line\">        gzip_buffers            256 64k;</div><div class=\"line\">        gzip_comp_level         5;</div><div class=\"line\">        gzip_min_length         1000;</div><div class=\"line\">        gzip_types              text/csv text/xml text/css text/plain text/javascript application/javascript application/x-javascript application/json application/xml;</div><div class=\"line\">        error_page   500 502 503 504  /50x.html;</div><div class=\"line\">        location / &#123;</div><div class=\"line\">            proxy_pass http://twell;</div><div class=\"line\">            proxy_set_header Host $host;</div><div class=\"line\">            proxy_next_upstream http_502 http_500 http_503 http_404;</div><div class=\"line\">            proxy_set_header X-Real-IP $remote_addr;</div><div class=\"line\">            root   html;</div><div class=\"line\">            index  index.html index.htm;</div><div class=\"line\">            client_max_body_size    70m;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<p>配置完成后reload：<br>sudo /home/q/nginx/sbin/nginx -s reload</p>\n","categories":["Work"],"tags":["nginx","需要密码才能看"]},{"title":"实习整理(六)","url":"/2017/10/%E5%AE%9E%E4%B9%A0%E6%95%B4%E7%90%86-%E5%85%AD/","content":"<h3 id=\"查看当前运行了多少个tomcat实例：\"><a href=\"#查看当前运行了多少个tomcat实例：\" class=\"headerlink\" title=\"查看当前运行了多少个tomcat实例：\"></a>查看当前运行了多少个tomcat实例：</h3><p>ps -ef | grep -v grep | grep -c tomcat</p>\n<p>ps -ef | grep -v grep | grep tomcat | wc</p>\n<p><img src=\"wc.png\" alt=\"wc命令\" title=\"wc命令\"></p>\n<h3 id=\"定时任务crond：\"><a href=\"#定时任务crond：\" class=\"headerlink\" title=\"定时任务crond：\"></a>定时任务crond：</h3><p>crond是linux系统用来定期执行命令或指定程序任务的一种服务或软件。一般情况下，我们安装完ubuntu操作系统之后，默认便会启动Crond任务调度服务。Crond服务会定期（默认每分钟检查一次）检查系统中是否有要执行的任务工作。如果有，便会根据其预先设定的定时任务规则自动执行该定时任务工作。这个Crond定时任务服务就相当于我们早上使用的闹钟一样。</p>\n<p>在/etc目录下，有系统自带的定时任务脚本，可以参考学习</p>\n<p><img src=\"crond.png\" alt=\"定时任务脚本\" title=\"定时任务脚本\"><br>﻿<br>crontab -e 编辑定时任务，每一个用户会有不同的定时任务</p>\n<p>在线生成cron表达式：<a href=\"http://cron.qqe2.com/\" target=\"_blank\" rel=\"external\">http://cron.qqe2.com/</a></p>\n<p>﻿crontab命令的功能是在一定的时间间隔调度一些命令的执行。在/etc目录下有一个crontab文件，这里存放有系统运行的一些调度程序。每个用户可以建立自己的调度crontab。<br>crontab命令有三种形式的命令行结构：<br>crontab [-u user] [file]<br>crontab [-u user] [-e|-l|-r]<br>crontab -l -u [-e|-l|-r] 第一个命令行中，file是命令文件的名字。如果在命令行中指定了这个文件，那么执行crontab命令，则将这个文件拷贝到crontabs目录下；如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将他们也存放在crontab目录下。<br>命令行中-r选项的作用是从/usr/spool/cron/crontabs目录下删除用户定义的文件crontab；<br>命令行中-l选项的作用是显示用户crontab文件的内容。<br>使用命令crontab -u user -e命令编辑用户user的cron(c)作业。用户通过编辑文件来增加或修改任何作业请求。<br>执行命令crontab -u user -r即可删除当前用户的所有的cron作业。<br>作业与它们预定的时间储存在文件/usr/spool/cron/crontabs/username里。username是用户名，在相应的文件中存放着该用户所要运行的命令。命令执行的结果，无论是标准输出还是错误输出，都将以邮件形式发给用户。文件里的每一个请求必须包含以spaces和tabs分割的六个域。前五个字段可以取整数值，指定何时开始工作，第六个域是字符串，称为命令字段，其中包括了crontab调度执行的命令。<br>第一道第五个字段的整数取值范围及意义是：<br>0～59 表示分<br>1～23 表示小时<br>1～31 表示日<br>1～12 表示月份<br>0～6 表示星期（其中0表示星期日）<br>/usr/lib/cron/cron.allow表示谁能使用crontab命令。如果它是一个空文件表明没有一个用户能安排作业。如果这个文件不存在，而有另外一个文件/usr/lib/cron/cron.deny,则只有不包括在这个文件中的用户才可以使用crontab命令。如果它是一个空文件表明任何用户都可安排作业。两个文件同时存在时cron.allow优先，如果都不存在，只有超级用户可以安排作业。</p>\n<h3 id=\"关于-etc-init-d：\"><a href=\"#关于-etc-init-d：\" class=\"headerlink\" title=\"关于/etc/init.d：\"></a>关于/etc/init.d：</h3><p>如果你使用过Linux系统，那么你一定听说过init.d目录。这个目录到底是干嘛的呢？它归根结底只做了一件事情，但这件事情非同小可，是为整个系统做的，因此它非常重要。init.d目录包含许多系统各种服务的启动和停止脚本。它控制着所有从acpid到x11-common的各种事务。当然，init.d远远没有这么简单。（译者注：acpid 是linux操作系统新型电源管理标准 ；X11也叫做X Window系统，X Window系统 (X11或X)是一种位图显示的 视窗系统 。它是在 Unix 和 类Unix 操作系统 ，以及 OpenVMS 上建立图形用户界面的标准工具包和协议，并可用于几乎已有的现代操作系统）。<br>当你查看/etc目录时，你会发现许多rc#.d 形式存在的目录（这里#代表一个指定的初始化级别，范围是0~6）。在这些目录之下，包含了许多对进程进行控制的脚本。这些脚本要么以”K”开头，要么以”S”开头。以K开头的脚本运行在以S开头的脚本之前。这些脚本放置的地方，将决定这些脚本什么时候开始运行。在这些目录之间，系统服务一起合作，就像运行状况良好的机器一样。然而，有时候你希望能在不使用kill 或killall 命令的情况下，能干净的启动或杀死一个进程。这就是/etc/init.d能够派上用场的地方了！<br>/etc/init.d/command 选项comand是实际运行的命令，选项可以有如下几种：</p>\n<ul>\n<li>start</li>\n<li>stop</li>\n<li>reload</li>\n<li>restart</li>\n<li>force-reload</li>\n</ul>\n<p>大多数的情况下，你会使用start,stop,restart选项。例如，如果你想关闭网络，你可以使用如下形式的命令：</p>\n<p><code>/etc/init.d/networking stop</code></p>\n<p>又比如，你改变了网络设置，并且需要重启网络。你可以使用如下命令：</p>\n<p><code>/etc/init.d/networking restart</code></p>\n<h3 id=\"关于-etc-rc-local\"><a href=\"#关于-etc-rc-local\" class=\"headerlink\" title=\"关于/etc/rc.local\"></a>关于/etc/rc.local</h3><p>rc.local也是我经常使用的一个脚本。该脚本是在系统初始化级别脚本运行之后再执行的，因此可以安全地在里面添加你想在系统启动之后执行的脚本。常见的情况是你可以再里面添加nfs挂载/mount脚本。此外，你也可以在里面添加一些调试用的脚本命令。例如，我就碰到过这种情况：samba服务总是无法正常运行，而检查发现，samba是在系统启动过程中就该启动执行的，也就是说，samba守护程序配置保证了这种功能本应该正确执行。碰到这种类似情况，一般我也懒得花大量时间去查为什么，我只需要简单的在/etc/rc.local脚本里加上这么一行：</p>\n<p><code>/etc/init.d/samba start</code></p>\n<p>这样就成功的解决了samba服务异常的问题。</p>\n<hr>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Internship"],"tags":["Linux","定时任务"]},{"title":"Linux查找文件","url":"/2017/10/Linux%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6/","content":"<p>Linux下查找文件通常可以用which，whereis，locate和find命令，下面总结它们各自的用法和区别。</p>\n<h3 id=\"which\"><a href=\"#which\" class=\"headerlink\" title=\"which\"></a>which</h3><p>which 用来查找可执行文件的绝对路径。which只能用来查找PATH环境变量中出现的路径下的可执行文件。当查找的文件在PATH变量中并没有时，就会报错。</p>\n<h3 id=\"whereis-和-locate\"><a href=\"#whereis-和-locate\" class=\"headerlink\" title=\"whereis 和 locate\"></a>whereis 和 locate</h3><p>whereis 通过预先生成的一个文件列表库去查找跟给出的文件名相关的文件。<br>locate 类似于whereis，也是通过查找预先生成的文件列表库来告诉用户要查找的文件在哪里。后边直接跟文件名。</p>\n<h3 id=\"find\"><a href=\"#find\" class=\"headerlink\" title=\"find\"></a>find</h3><p>find 语法： find [路径] [参数]<br>常用的参数<br>-atime +n ：访问或执行时间大于n天的文件<br>-ctime +n ：写入、更改inode属性（例如更改所有者、权限或者连接）时间大于n天的文件<br>-mtime +n ：写入时间大于n天的文件<br>-name expression ：根据正则表达式查找文件     e.g.  find . -name “*p.java” 在当前目录查找以p结尾的java文件<br>-type type ：通过文件类型查找<br>文件的 Access time，atime 是在读取文件或者执行文件时更改的。<br>文件的 Modified time，mtime 是在写入文件时随文件内容的更改而更改的。<br>文件的 Create time，ctime 是在写入文件、更改所有者、权限或链接设置时随 Inode 的内容更改而更改的。<br>因此，更改文件的内容即会更改 mtime 和 ctime，但是文件的ctime 可能会在 mtime 未发生任何变化时更改，例如，更改了文件的权限，但是文件内容没有变化。<br>如何获得一个文件的atime mtime 以及ctime ？<br>ls -l 命令可用来列出文件的 atime、ctime 和 mtime。<br>ls -lc filename         列出文件的 ctime<br>ls -lu filename         列出文件的 atime<br>ls -l filename          列出文件的 mtime<br>atime不一定在访问文件之后被修改，因为：使用ext3文件系统的时候，如果在mount的时候使用了noatime参数那么就不会更新atime的信息。而这是加了 noatime 取消了, 不代表真实情況。反正, 這三個 time stamp 都放在 inode 中。若 mtime, atime 修改inode 就一定會改, 既然 inode 改了, 那 ctime 也就跟着要改了。</p>\n<hr>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Learning"],"tags":["Linux"]},{"title":"Linux窗口管理终极解决方案:tmux","url":"/2017/07/Linux%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86%E7%BB%88%E6%9E%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-tmux/","content":"<h2 id=\"Linux窗口管理终极解决方案-tmux\"><a href=\"#Linux窗口管理终极解决方案-tmux\" class=\"headerlink\" title=\"Linux窗口管理终极解决方案:tmux\"></a>Linux窗口管理终极解决方案:tmux</h2><p>tmux是terminal multiplexer的简称，也就是终端复用，一旦熟悉了tmux后，它就像一个加速器一样加速我们的工作效率。</p>\n<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>tmux的基本概念很简单，包含三种组成要素：</p>\n<ul>\n<li><p>会话(session)</p>\n</li>\n<li><p>窗口(window)</p>\n</li>\n<li><p>面板(pane)</p>\n</li>\n</ul>\n<p>只需要记住三者之间的关系：用户可以创建多个会话，一个会话内可以创建多个窗口，一个窗口内可以创建多个面板。</p>\n<h3 id=\"常用命令和快捷键\"><a href=\"#常用命令和快捷键\" class=\"headerlink\" title=\"常用命令和快捷键\"></a>常用命令和快捷键</h3><h4 id=\"常用命令\"><a href=\"#常用命令\" class=\"headerlink\" title=\"常用命令\"></a>常用命令</h4><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>tmux ls</td>\n<td>列出所有会话</td>\n</tr>\n<tr>\n<td>tmux new -s basic</td>\n<td>创建一个名为basic的会话</td>\n</tr>\n<tr>\n<td>tmux new -s basic -n editor</td>\n<td>创建一个名为basic的会话，并把该会话的第一个窗口命名为editor</td>\n</tr>\n<tr>\n<td>tmux attach -t basic</td>\n<td>attach，连接到一个名为basic的会话</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"快捷键\"><a href=\"#快捷键\" class=\"headerlink\" title=\"快捷键\"></a>快捷键</h4><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>PREFIX d</td>\n<td>detach，将当前会话分离，让该会话在后台运行</td>\n</tr>\n<tr>\n<td>PREFIX c</td>\n<td>在当前会话新建一个窗口</td>\n</tr>\n<tr>\n<td>PREFIX ,</td>\n<td>对当前窗口重命名</td>\n</tr>\n<tr>\n<td>PREFIX 0…9</td>\n<td>根据窗口的编号选择窗口</td>\n</tr>\n<tr>\n<td>PREFIX n</td>\n<td>跳转到下一个窗口</td>\n</tr>\n<tr>\n<td>PREFIX %</td>\n<td>把当前窗口垂直地一分为二，分割后的两个面板各占 50% 大小</td>\n</tr>\n<tr>\n<td>PREFIX “</td>\n<td>把当前窗口水平地一分为二，分割后的两个面板各占 50% 大小</td>\n</tr>\n<tr>\n<td>PREFIX 方向键</td>\n<td>光标跳转到指定面板</td>\n</tr>\n<tr>\n<td>按住PREFIX的同时按方向键</td>\n<td>调整当前面板的大小</td>\n</tr>\n<tr>\n<td>PREFIX 空格键</td>\n<td>切换面板布局</td>\n</tr>\n<tr>\n<td>PREFIX z</td>\n<td>最大化当前面板，再按一次还原</td>\n</tr>\n<tr>\n<td>PREFIX !</td>\n<td>将当前面板从所属窗口分离出去，成为一个新的窗口</td>\n</tr>\n<tr>\n<td>PREFIX ?</td>\n<td>打印快捷键help</td>\n</tr>\n</tbody>\n</table>\n<p>为什么要有PREFIX</p>\n<p>由于我们的程序是在tmux环境里运行的，因此需要一种方式来告诉tmux当前所输入的命令是为了让tmux去执行而不是tmux里的应用程序去执行。</p>\n<p>默认PREFIX是<code>Ctrl b</code>，觉得别扭的话可以在配置文件里自定义。</p>\n<h4 id=\"复制到剪贴板\"><a href=\"#复制到剪贴板\" class=\"headerlink\" title=\"复制到剪贴板\"></a>复制到剪贴板</h4><p>在开启鼠标支持的前提下，按住shift，鼠标左键选择文本，然后右键选择“复制”。</p>\n<h3 id=\"配置文件\"><a href=\"#配置文件\" class=\"headerlink\" title=\"配置文件\"></a>配置文件</h3><p>在默认情况下，tmux 会在两个位置查找配置文件。首先查找 <code>/etc/tmux.conf</code> 作为系统配置，然后在当前用户的主目录下查找 <code>.tmux.conf</code> 文件（~/.tmux.conf 优先级更高）。如果这两个文件都不存在，tmux 就会使用默认配置。</p>\n<h4 id=\"配置示例\"><a href=\"#配置示例\" class=\"headerlink\" title=\"配置示例\"></a>配置示例</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\"># 按PREFIX R重新加载配置文件</div><div class=\"line\">bind R source-file ~/.tmux.conf \\; display-message &quot;Config reloaded..&quot;</div><div class=\"line\"></div><div class=\"line\"># 按PREFIX S在不同面板同步操作，再按一次取消同步</div><div class=\"line\">bind S setw synchronize-panes</div><div class=\"line\"></div><div class=\"line\"># 状态栏</div><div class=\"line\"># 颜色</div><div class=\"line\">set -g status-bg black</div><div class=\"line\">set -g status-fg white</div><div class=\"line\"></div><div class=\"line\"># 设置面板和活动面板的颜色</div><div class=\"line\">set -g pane-active-border-fg white</div><div class=\"line\">set -g pane-active-border-bg yellow</div><div class=\"line\"> </div><div class=\"line\"># 对齐方式</div><div class=\"line\">set-option -g status-justify centre</div><div class=\"line\"> </div><div class=\"line\"># 左下角</div><div class=\"line\">set-option -g status-left &apos;#[bg=black,fg=green][#[fg=cyan]#S#[fg=green]]&apos;</div><div class=\"line\">set-option -g status-left-length 20</div><div class=\"line\"> </div><div class=\"line\"># 窗口列表</div><div class=\"line\">setw -g automatic-rename on</div><div class=\"line\">set-window-option -g window-status-format &apos;#[dim]#I:#[default]#W#[fg=grey,dim]&apos;</div><div class=\"line\">set-window-option -g window-status-current-format &apos;#[fg=cyan,bold]#I#[fg=blue]:#[fg=cyan]#W#[fg=dim]&apos;</div><div class=\"line\"> </div><div class=\"line\"># 右下角</div><div class=\"line\">set -g status-right &apos;#[fg=green][#[fg=cyan]%Y-%m-%d#[fg=green]]&apos;</div><div class=\"line\"></div><div class=\"line\"># 设置鼠标滚轮可用</div><div class=\"line\">set-window-option -g mode-mouse on</div><div class=\"line\"></div><div class=\"line\"># 设置窗口活动通知</div><div class=\"line\">set-window-option -g monitor-activity on</div><div class=\"line\">set -g visual-activity on</div></pre></td></tr></table></figure>\n<h3 id=\"自动化脚本\"><a href=\"#自动化脚本\" class=\"headerlink\" title=\"自动化脚本\"></a>自动化脚本</h3><p>在日常开发中，我们经常需要打开各种各样的窗口，比如一个运行测试自动化脚本的窗口，一个查看应用运行日志的窗口，一个数据库窗口，难道每次都需要一个一个地打开各个窗口吗？自动化脚本就是让你一键拥有需要的所有窗口，并直接运行你想要的程序。</p>\n<h4 id=\"脚本示例\"><a href=\"#脚本示例\" class=\"headerlink\" title=\"脚本示例\"></a>脚本示例</h4><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 创建新的会话basic，并detach</span></div><div class=\"line\">tmux new <span class=\"_\">-s</span> basic <span class=\"_\">-d</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 列出常用工作路径</span></div><div class=\"line\">tmux send-keys -t basic <span class=\"string\">'sd -l'</span> C-m</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 创建新的面板</span></div><div class=\"line\">tmux split-window -h -t basic</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 连接hyvpn</span></div><div class=\"line\">tmux send-keys -t basic:0.1 <span class=\"string\">'cd ~/Downloads'</span> C-m</div><div class=\"line\">tmux send-keys -t basic:0.1 <span class=\"string\">'sudo openvpn hy-vpn.ovpn'</span> C-m</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 创建新的窗口，命名为bl</span></div><div class=\"line\">tmux new-window -n bl -t basic</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># ssh登录堡垒机</span></div><div class=\"line\">tmux send-keys -t basic:1 <span class=\"string\">'ssh-add ~/.ssh/netease/id_rsa'</span> C-m</div><div class=\"line\">tmux send-keys -t basic:1 <span class=\"string\">'ssh -A bl'</span> C-m</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># attach会话</span></div><div class=\"line\">tmux attach -t basic</div></pre></td></tr></table></figure>\n<p>tmux采用c/s架构，有个后台server线程，send-keys就是向这个后台线程发送想让tmux执行的终端命令；<code>tmux send-keys -t basic:0.1 &#39;cd ~/Downloads&#39; C-m</code>表示向basic会话的第1个窗口的第2个面板发送打开<code>~/Downloads</code>文件夹的命令，<code>C-m</code>表示回车。</p>\n<p>窗口、面板默认都是从0开始计数，也可以通过配置使其从1开始计数。</p>\n<p>执行与上面类似的脚本，就可以一键拥有想要的开发环境。</p>\n<h3 id=\"进阶\"><a href=\"#进阶\" class=\"headerlink\" title=\"进阶\"></a>进阶</h3><p>以上内容已基本能够cover住日常工作需求，如需使用tmux更高级的功能，请参考：</p>\n<p>《tmux: Productive Mouse-Free Development》中文版：<a href=\"https://aquaregia.gitbooks.io/tmux-productive-mouse-free-development_zh/content/index.html\" target=\"_blank\" rel=\"external\">https://aquaregia.gitbooks.io/tmux-productive-mouse-free-development_zh/content/index.html</a> </p>\n","categories":["Tool"],"tags":["Linux","tmux","窗口管理"]},{"title":"ELK搭建实时日志分析系统","url":"/2017/07/ELK%E6%90%AD%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/","content":"<p>日志主要包括系统日志、应用程序日志和安全日志。系统运维和开发人员可以通过日志了解服务器软硬件信息、检查配置过程中的错误及错误发生的原因。经常分析日志可以了解服务器的负荷，性能安全性，从而及时采取措施纠正错误。</p>\n<p>通常，日志被分散的储存不同的设备上。如果你管理数十上百台服务器，你还在使用依次登录每台机器的传统方法查阅日志。这样是不是感觉很繁琐和效率低下。当务之急我们使用集中化的日志管理，例如：开源的syslog，将所有服务器上的日志收集汇总。</p>\n<p>集中化管理日志后，日志的统计和检索又成为一件比较麻烦的事情，一般我们使用grep、awk和wc等Linux命令能实现检索和统计，但是对于要求更高的查询、排序和统计等要求和庞大的机器数量依然使用这样的方法难免有点力不从心。</p>\n<p>开源实时日志分析ELK平台能够完美的解决我们上述的问题，ELK由ElasticSearch、Logstash和Kiabana三个开源工具组成。官方网站：<a href=\"https://www.elastic.co/products\" target=\"_blank\" rel=\"external\">https://www.elastic.co/products</a></p>\n<ul>\n<li><p>Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。</p>\n</li>\n<li><p>Logstash是一个完全开源的工具，他可以对你的日志进行收集、过滤，并将其存储供以后使用（如，搜索）。</p>\n</li>\n<li><p>Kibana 也是一个开源和免费的工具，它Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的<br>Web 界面，可以帮助您汇总、分析和搜索重要数据日志。</p>\n</li>\n</ul>\n<blockquote>\n<p>以上摘自：<a href=\"http://baidu.blog.51cto.com/71938/1676798\" target=\"_blank\" rel=\"external\">http://baidu.blog.51cto.com/71938/1676798</a></p>\n</blockquote>\n<p>ELK是目前比较流行的日志分析框架，很多公司都在使用，今天想着自己搭建一个自己的实时日志分析平台。</p>\n<p><img src=\"ELK原理.png\" alt=\"ELK原理\"></p>\n<p>如图所示，AppServer产生原始Log，Logstash收集Log，并根据定义的filter对Log进行自定义解析，并存放到ElasticSearch集群中，而Kibana则从ES集群中查询数据生成图表，最终呈现给Browser。</p>\n<h4 id=\"安装环境：\"><a href=\"#安装环境：\" class=\"headerlink\" title=\"安装环境：\"></a><strong>安装环境：</strong></h4><p>ElasticSearch: 5.5.0<br>Logstash: 5.5.0<br>Kibana: 5.5.0<br>Java: &gt;=1.8<br>ELK下载：<a href=\"https://www.elastic.co/downloads/\" target=\"_blank\" rel=\"external\">https://www.elastic.co/downloads/</a></p>\n<h4 id=\"ElasticSearch\"><a href=\"#ElasticSearch\" class=\"headerlink\" title=\"ElasticSearch:\"></a><strong>ElasticSearch:</strong></h4><p>安装好ElasticSearch后，编辑配置文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> elasticsearch-5.5.0</div><div class=\"line\">vim config/elasticsearch.yml</div></pre></td></tr></table></figure>\n<p>修改为：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Use a descriptive name for your cluster:</span></div><div class=\"line\">cluster.name: es_cluster</div><div class=\"line\"><span class=\"comment\"># Use a descriptive name for the node:</span></div><div class=\"line\">node.name: node-0</div><div class=\"line\"><span class=\"comment\"># Path to directory where to store the data (separate multiple locations by comma):</span></div><div class=\"line\">path.data: /home/wanghao/work/elasticsearch-5.5.0/data</div><div class=\"line\"><span class=\"comment\"># Path to log files:</span></div><div class=\"line\">path.logs: /home/wanghao/work/elasticsearch-5.5.0/logs</div><div class=\"line\"><span class=\"comment\"># Set the bind address to a specific IP (IPv4 or IPv6):</span></div><div class=\"line\">network.host: localhost <span class=\"comment\">#我这里设置成localhost,实际的话可以是ES的IP地址</span></div><div class=\"line\"><span class=\"comment\"># Set a custom port for HTTP:</span></div><div class=\"line\">network.port: 9200</div></pre></td></tr></table></figure></p>\n<p>其他选项保持默认，然后启动elasticsearch:<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">./bin/elasticsearch</div></pre></td></tr></table></figure></p>\n<p>或者使用后台进程的方式启动elasticsearch:<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">./bin/elasticsearch &amp;</div></pre></td></tr></table></figure></p>\n<p><img src=\"elasticsearch_01.png\" alt=\"启动ElasticSearch\"></p>\n<p>ES集群中的节点是通过<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-transport.html\" target=\"_blank\" rel=\"external\">Transport</a>模块来实现相互通信的，从图中可以看到，node-0节点与ES集群中其它节点的通信端口为9300。另外，节点通过<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-http.html\" target=\"_blank\" rel=\"external\">HTTP</a>模块来暴露它的REST API，端口为9200。</p>\n<p>打开localhost:9200，会看到配置的cluster_name和node name，以及安装的ES的版本等信息：</p>\n<p><img src=\"elasticsearch_02.png\" alt=\"访问localhost:9200\"></p>\n<p><strong>安装ElasticSearch-Head</strong></p>\n<p>ElasticSearch-Head是一个用浏览器跟ES集群交互的插件，可以查看集群状态、集群的doc内容、执行搜索和普通的Rest请求等，安装可参考官网：<a href=\"https://github.com/mobz/elasticsearch-head\" target=\"_blank\" rel=\"external\">https://github.com/mobz/elasticsearch-head</a></p>\n<p>需要注意的是，对于Elasticsearch 5.x， 通过插件安装ElasticSearch-Head不再被支持，需要单独安装。方法如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">git <span class=\"built_in\">clone</span> git://github.com/mobz/elasticsearch-head.git</div><div class=\"line\"><span class=\"built_in\">cd</span> elasticsearch-head</div><div class=\"line\">npm install</div><div class=\"line\">npm run start</div></pre></td></tr></table></figure>\n<p>最后浏览器打开<a href=\"http://localhost:9100\" target=\"_blank\" rel=\"external\">http://localhost:9100</a></p>\n<h4 id=\"Logstash\"><a href=\"#Logstash\" class=\"headerlink\" title=\"Logstash:\"></a><strong>Logstash:</strong></h4><p><img src=\"Logstash原理.png\" alt=\"Logstash原理\"></p>\n<p>Logstash实质上是一个日志<strong>收集器</strong>，需要为它指定Input和Output，可以有多个Input和Output。举个例子，比如我们需要把Java代码里Log4j的日志放到ElasticSearch中，那么Input就是Log4j，Output就是ES集群。Filter就是定义放到ElasticSearch中的日志是什么格式的/有哪些字段，具体使用见另一篇博文：实习第六周整理。</p>\n<p>安装Logstash之后,编辑配置:<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">cd</span> logstash-5.5.0</div><div class=\"line\">vim config/<span class=\"built_in\">log</span>4j_to_es.conf</div></pre></td></tr></table></figure></p>\n<p>这里新建了一个配置文件,内容如下:<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># For detail structure of this file</span></div><div class=\"line\"><span class=\"comment\"># Set: https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html</span></div><div class=\"line\">input &#123;</div><div class=\"line\">  <span class=\"comment\"># For detail config for log4j as input, </span></div><div class=\"line\">  <span class=\"comment\"># See: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-log4j.html</span></div><div class=\"line\">  <span class=\"built_in\">log</span>4j &#123;</div><div class=\"line\">    mode =&gt; <span class=\"string\">\"server\"</span></div><div class=\"line\">    host =&gt; <span class=\"string\">\"localhost\"</span></div><div class=\"line\">    port =&gt; 4567</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\">filter &#123;</div><div class=\"line\">  <span class=\"comment\">#Only matched data are send to output.</span></div><div class=\"line\">&#125;</div><div class=\"line\">output &#123;</div><div class=\"line\">  <span class=\"comment\"># For detail config for elasticsearch as output, </span></div><div class=\"line\">  <span class=\"comment\"># See: https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html</span></div><div class=\"line\">  elasticsearch &#123;</div><div class=\"line\">    action =&gt; <span class=\"string\">\"index\"</span>          <span class=\"comment\">#The operation on ES</span></div><div class=\"line\">    hosts  =&gt; <span class=\"string\">\"localhost:9200\"</span>   <span class=\"comment\">#ElasticSearch host, can be array.</span></div><div class=\"line\">    index  =&gt; <span class=\"string\">\"applog\"</span>         <span class=\"comment\">#The index to write data to.</span></div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>启动Logstash,用-f指定配置文件<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">./bin/logstash <span class=\"_\">-f</span> config/<span class=\"built_in\">log</span>4j_to_es.conf</div></pre></td></tr></table></figure></p>\n<p>Logstash配置和启动完毕</p>\n<h4 id=\"Log4j生成日志\"><a href=\"#Log4j生成日志\" class=\"headerlink\" title=\"Log4j生成日志:\"></a><strong>Log4j生成日志:</strong></h4><p>收集器有了(Logstash),收集后放在哪里也清楚了(ES),但是还没有日志…所以现在需要有一个程序产生日志,这里就用Log4j</p>\n<p>建立Maven工程,并在pom.xml中添加log4j依赖:<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">&lt;dependency&gt;</div><div class=\"line\">    &lt;groupId&gt;<span class=\"built_in\">log</span>4j&lt;/groupId&gt;</div><div class=\"line\">    &lt;artifactId&gt;<span class=\"built_in\">log</span>4j&lt;/artifactId&gt;</div><div class=\"line\">    &lt;version&gt;1.2.17&lt;/version&gt;</div><div class=\"line\">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>\n<p>使用log4j需要配置log4j.properties<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">log</span>4j.rootLogger=INFO,console</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># for package com.demo.elk, log would be sent to socket appender.</span></div><div class=\"line\"><span class=\"built_in\">log</span>4j.logger.com.demo.elk=DEBUG, socket</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># appender socket</span></div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.socket=org.apache.log4j.net.SocketAppender</div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.socket.Port=4567</div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.socket.RemoteHost=localhost</div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.socket.layout=org.apache.log4j.PatternLayout</div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.socket.layout.ConversionPattern=%d [%-5p] [%l] %m%n</div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.socket.ReconnectionDelay=10000</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># appender console</span></div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.console=org.apache.log4j.ConsoleAppender</div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.console.target=System.out</div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.console.layout=org.apache.log4j.PatternLayout</div><div class=\"line\"><span class=\"built_in\">log</span>4j.appender.console.layout.ConversionPattern=%d [%-5p] [%l] %m%n</div></pre></td></tr></table></figure></p>\n<p>这里配置了log4j的两个appender:SocketAppender和ConsoleAppender。 Log4j通过socket与运行在localhost:4567的Logstash实例通信,将日志传输过去。</p>\n<p>下面是产生日志的代码,使用PropertyConfigurator显式地加载log4j.properties<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">public class Application &#123;</div><div class=\"line\">    private static final Logger LOGGER = Logger.getLogger(Application.class);</div><div class=\"line\">    public static void main(String[] args) throws Exception &#123;</div><div class=\"line\">        PropertyConfigurator.configure(<span class=\"string\">\"log4j.properties\"</span>);</div><div class=\"line\">        <span class=\"keyword\">for</span> (int i = 0; i &lt; 10; i++) &#123;</div><div class=\"line\">            LOGGER.error(<span class=\"string\">\"Info log [\"</span> + i + <span class=\"string\">\"].\"</span>);</div><div class=\"line\">            Thread.sleep(500);</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>除了将log4j作为Logstash的Input,Logstash还支持很多Input Plugins,详见<a href=\"https://www.elastic.co/guide/en/logstash/current/input-plugins.html\" target=\"_blank\" rel=\"external\">https://www.elastic.co/guide/en/logstash/current/input-plugins.html</a></p>\n<p><a href=\"https://my.oschina.net/itblog/blog/547250\" target=\"_blank\" rel=\"external\">https://my.oschina.net/itblog/blog/547250</a></p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Work"],"tags":["ElasticSearch","Logstash","Kibana"]},{"title":"(转载)JVM监控命令详解","url":"/2017/07/%E8%BD%AC%E8%BD%BD-JVM%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/","content":"<p><a href=\"http://learnworld.iteye.com/blog/1381949\" target=\"_blank\" rel=\"external\">http://learnworld.iteye.com/blog/1381949</a></p>\n<p><a href=\"http://www.cnblogs.com/rainy-shurun/p/5732341.html\" target=\"_blank\" rel=\"external\">http://www.cnblogs.com/rainy-shurun/p/5732341.html</a></p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Learning"],"tags":["JVM"]},{"title":"Perfect Shell: zsh","url":"/2017/07/Perfect-Shell-zsh/","content":"<p>Recently, I bought a new laptop : HP Omen II Pro. Guess what? It is a <strong>GAME LAPTOP</strong>!!! Well, I confess that I couldn’t wait to download GTA5 as soon as I got the laptop in my hands. But wait. I stopped myself from doing that. I <strong>HAD TO</strong> get into work. I had been working as an intern developer in Qunar for two weeks, and, my <strong>old, slow, dumb</strong> laptop really drives me crazy. I really want to kick its ass and throw it to the ground, but I didn’t do that hahaha. I uninstalled the Windows 10 and took a flight to <strong>Ubuntu</strong>. It is the first time that I use Ubuntu as a standalone OS in my laptop. Cheers! </p>\n<p>Well, come to the point. I am a <strong>“Ubuntuer”</strong> from now on, so it’s time to get it up–try the <strong>perfect shell</strong> in the world–<strong>zsh</strong>!</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/19556676?columnSlug=mactalk\" target=\"_blank\" rel=\"external\">https://zhuanlan.zhihu.com/p/19556676?columnSlug=mactalk</a></p>\n<p><a href=\"https://www.zhihu.com/question/21418449\" target=\"_blank\" rel=\"external\">https://www.zhihu.com/question/21418449</a></p>\n<p><a href=\"http://blog.csdn.net/zxgdll/article/details/70858857\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/zxgdll/article/details/70858857</a></p>\n<p><a href=\"https://github.com/robbyrussell/oh-my-zsh\" target=\"_blank\" rel=\"external\">https://github.com/robbyrussell/oh-my-zsh</a></p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Tool"],"tags":["Linux","zsh","oh-my-zsh"]},{"title":"实习整理(五)","url":"/2017/07/%E5%AE%9E%E4%B9%A0%E6%95%B4%E7%90%86-%E4%BA%94/","content":"<p>实习第五周。这周的主要工作内容是协助开发和QA跑case，由于最近我所在的组任务不多，大家的工作主要是修修补补，或者是增加一些小功能。实习了一个多月，目前为止收获最大的地方就是更加熟悉了Linux开发，这点能从我最近写的实习总结中看出来。</p>\n<p>周四，leader让我把在线航空公司常见的接口错误统计出来，也就是把航司的错误从日志中搂出来，需要写shell脚本来实现，简单记录一下。</p>\n<p>先上脚本：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/bash</span></div><div class=\"line\"></div><div class=\"line\">atnodes <span class=\"string\">'zgrep -o \" Code=\\\"\\\\w\\&#123;3,\\&#125;\\\" \" &#123;logname&#125;.log.2017-07-0[8-9]-*.gz '</span> &#123;hostname1&#125;[3-4] &#123;hostname2&#125;[3-6] &gt; icaair_provider.log</div><div class=\"line\"></div><div class=\"line\">gawk <span class=\"string\">'&#123; print $2 &#125;'</span> icaair_provider.log | gawk -F <span class=\"string\">'='</span> <span class=\"string\">'&#123; print $2 &#125;'</span> | sort &gt; icaair_provider.code</div><div class=\"line\"></div><div class=\"line\">cat icaair_provider.code | uniq -c</div></pre></td></tr></table></figure>\n<p>atnodes 把{hostname1}[3-4] {hostname2}[3-6]这些机器上的日志全都取出来，当然要通过zgrep正则表达式的过滤，不然日志太多，最后把得到的日志写到文件icaair_provider.log里。</p>\n<p>awk是一个强大的文本分析工具，它把文件逐行读入，按照分隔符(默认空格)将每行切片，然后再对切开的部分进行各种分析处理，非常适合处理日志数据。具体见<a href=\"http://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858470.html\" target=\"_blank\" rel=\"external\">这篇文章</a>。总之第二行就是根据第一步得到的文件icaair_provider.log切分日志，得到想要的那一列，然后用sort排序，最后写入文件icaair_provider.code里。</p>\n<p>最后一行，用uniq统计在icaair_provider.code中的所有错误出现的次数。</p>\n<p><strong>Note:</strong><br>这里我要说的是写正则表达式需要注意的问题。首先看看<a href=\"https://en.wikipedia.org/wiki/Regular_expression\" target=\"_blank\" rel=\"external\">维基百科</a>是怎么描述正则表达式的。</p>\n<p><img src=\"hexo-1.png\" alt=\"regular expression\"></p>\n<p>总结起来就是，正则表达式是一个美国数学家搞出来的一门语言，也可以说是一门科学。你想啊，它能被称作是科学，一定是严谨的正确的不容质疑的，但是它偏偏有两套标准，也可以叫两套语法，分别是POSIX standard和Perl syntax。这两套语法都是对的，按照任何一个语法写出来的正则都是对的。重点是最后一句话，很多编程语言提供对正则表达式的支持，或者内置，或者通过引用包。举个例子来讲，上帝说，人要住在房子里，于是给出房子的定义：能遮风挡雨抵挡野兽的建筑就是房子。虽然有了房子的定义，但是不够具体，于是上帝手下的两个天使开始制定标准，也就是POSIX和Perl。至于编程语言就是建房子的工人，它按照制定的标准实现了正则表达式，但是每个编程语言实现正则的方式方法不尽相同。</p>\n<p>理解了这点就明白了为什么我在<a href=\"http://regexr.com/\" target=\"_blank\" rel=\"external\">http://regexr.com/</a> 上写的正则明明是对的为啥放在java里或者shell里就不好使了。<a href=\"http://regexr.com/\" target=\"_blank\" rel=\"external\">http://regexr.com/</a> 是对正则标准的检查，它不是language-specific的。</p>\n<hr>\n<p>最后记录一段脚本，功能是统计file2中的每行在file1中出现的次数。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/bash</span></div><div class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$#</span> <span class=\"_\">-lt</span> 2 ]</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"Usage:<span class=\"variable\">$0</span> args error\"</span></div><div class=\"line\"><span class=\"built_in\">exit</span> 0</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#get the first file</span></div><div class=\"line\">file1=<span class=\"variable\">$1</span></div><div class=\"line\"><span class=\"comment\">#get the second file</span></div><div class=\"line\">file2=<span class=\"variable\">$2</span></div><div class=\"line\"><span class=\"keyword\">while</span> <span class=\"built_in\">read</span> myline</div><div class=\"line\"><span class=\"keyword\">do</span></div><div class=\"line\">grep -E -o <span class=\"string\">\"<span class=\"variable\">$&#123;myline&#125;</span>\"</span> <span class=\"variable\">$file1</span> | awk <span class=\"string\">' &#123; count[$0]++ &#125; </span></div><div class=\"line\">END&#123;printf(\"%-20s%s\\n\",\"Word\",\"Count\");</div><div class=\"line\">for(word in count)</div><div class=\"line\">&#123;printf(\"%-20s\\t%s\\n\",word,count[word])&#125;</div><div class=\"line\">&#125;'</div><div class=\"line\"><span class=\"keyword\">done</span> &lt; <span class=\"variable\">$2</span></div></pre></td></tr></table></figure>\n<hr>\n<p>最后的最后，总结bash脚本里面大于/等于…关键词:</p>\n<table>\n<thead>\n<tr>\n<th>Item</th>\n<th>Value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-eq</td>\n<td>等于</td>\n</tr>\n<tr>\n<td>-ne</td>\n<td>不等于</td>\n</tr>\n<tr>\n<td>-le</td>\n<td>小于等于</td>\n</tr>\n<tr>\n<td>-ge</td>\n<td>大于等于</td>\n</tr>\n<tr>\n<td>-lt</td>\n<td>小于</td>\n</tr>\n<tr>\n<td>-gt</td>\n<td>大于</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Internship"],"tags":["Linux","正则表达式","bash"]},{"title":"实习整理(四)","url":"/2017/07/%E5%AE%9E%E4%B9%A0%E6%95%B4%E7%90%86-%E5%9B%9B/","content":"<h3 id=\"Linux命令之：more-or-less\"><a href=\"#Linux命令之：more-or-less\" class=\"headerlink\" title=\"Linux命令之：more or less?\"></a>Linux命令之：more or less?</h3><p>more 主要的作用是把输出结果显示在屏幕上，它会一屏停止一下，等待按空格键才继续往上卷。但是，如果看完了这页，想要回头看上一页，是不行的，必须从头再来！</p>\n<p>less 最主要是改进了more 不能回头看的问题。<br>除了能够随意上下翻页之外，less还提供了非常方便的搜索功能，这在查看很长的日志时是很有用的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">按h查看help</div><div class=\"line\">按g直接跳到第一行</div><div class=\"line\">按G直接跳到最后</div><div class=\"line\">按/ search forward</div><div class=\"line\">按? search backward</div></pre></td></tr></table></figure>\n<h3 id=\"IDEA集成SonarLint检查代码bug\"><a href=\"#IDEA集成SonarLint检查代码bug\" class=\"headerlink\" title=\"IDEA集成SonarLint检查代码bug\"></a>IDEA集成SonarLint检查代码bug</h3><p>Sonar是一款代码检查工具，可以从七个维度检查代码问题：不遵循代码标准，潜在的缺陷，糟糕的复杂度分布，重复，注释不足或者过多，缺乏单元测试，糟糕的设计。<br>而SonarLint是一个IDEA插件，为开发人员提供实时的代码质量检查，尽早发现问题，有助于提高项目质量。</p>\n<p>IDEA集成SonarLint的具体方法参加下面文章：<br><a href=\"http://www.cnblogs.com/0201zcr/p/6722932.html\" target=\"_blank\" rel=\"external\">http://www.cnblogs.com/0201zcr/p/6722932.html</a></p>\n<h3 id=\"Ubuntu下sublime-text无法输入中文问题\"><a href=\"#Ubuntu下sublime-text无法输入中文问题\" class=\"headerlink\" title=\"Ubuntu下sublime text无法输入中文问题\"></a>Ubuntu下sublime text无法输入中文问题</h3><p>在Ubuntu下安装了sublime text，发现无法输入中文，上网搜索发现很多人遇到了这个问题，于是照搬照抄，参考下面文章：<br><a href=\"https://www.sinosky.org/linux-sublime-text-fcitx.html\" target=\"_blank\" rel=\"external\">https://www.sinosky.org/linux-sublime-text-fcitx.html</a></p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Internship"],"tags":["Linux","Ubuntu","SonarLint"]},{"title":"实习整理(三)","url":"/2017/07/%E5%AE%9E%E4%B9%A0%E6%95%B4%E7%90%86-%E4%B8%89/","content":"<p>实习第三周，下面整理一下这周遇到的一些问题。</p>\n<h3 id=\"Ubuntu下快捷键-System-Settings-gt-keyboard编辑\"><a href=\"#Ubuntu下快捷键-System-Settings-gt-keyboard编辑\" class=\"headerlink\" title=\"Ubuntu下快捷键(System Settings-&gt;keyboard编辑)\"></a>Ubuntu下快捷键(System Settings-&gt;keyboard编辑)</h3><p>按住Super：查看所有快捷键<br>Super+方向键：切换工作区<br>Alt+F4：关闭当前窗口<br>Ctrl+PageDown/PageUp：切换终端Tab</p>\n<h3 id=\"Linux下添加软件的桌面快捷图标\"><a href=\"#Linux下添加软件的桌面快捷图标\" class=\"headerlink\" title=\"Linux下添加软件的桌面快捷图标\"></a>Linux下添加软件的桌面快捷图标</h3><p>以Intellij idea为例：<br>在桌面新建文档命名为：idea.desktop<br>内容为下：（Exec和Icon要用自己的路径）</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">[Desktop Entry]</div><div class=\"line\">Encoding=UTF-8</div><div class=\"line\">Name=idea</div><div class=\"line\">Comment=idea IDE</div><div class=\"line\">Exec=/home/idea/bin/idea.sh</div><div class=\"line\">Icon=/home/idea/bin/idea.png</div><div class=\"line\">Terminal=<span class=\"literal\">false</span></div><div class=\"line\">Type=Application</div><div class=\"line\">Categories=GNOME;Application;Development;</div><div class=\"line\">StartupNotify=<span class=\"literal\">true</span></div></pre></td></tr></table></figure>\n<p><strong>注意：将Name、Comment、Exec、Icon改成自己需要的东西</strong><br>这时双击idea.desktop，系统会提示“未信任的应用程序启动器”？<br>解决方法是：右键打开文件属性对话框，在权限页中，将“允许作为程序执行文件(E)”前的复选框选上，大功告成！<br>最后，将编辑好的idea.desktop文件拷贝到/usr/share/applications下面，这时候在dash下就能搜索到idea了。</p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Internship"],"tags":["Linux","Ubuntu"]},{"title":"实习整理(二)","url":"/2017/06/%E5%AE%9E%E4%B9%A0%E6%95%B4%E7%90%86-%E4%BA%8C/","content":"<p>实习第二周，下面整理一下这周遇到的一些问题。</p>\n<h3 id=\"Linux下head-tail命令\"><a href=\"#Linux下head-tail命令\" class=\"headerlink\" title=\"Linux下head/tail命令\"></a>Linux下head/tail命令</h3><p>顾名思义，head 与 tail 是用来显示开头或结尾某个数量的文字区块，head 用来显示文件的开头至标准输出中，而 tail 当然就是看文件的结尾</p>\n<p>具体用法如下：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">head -6 readme.txt <span class=\"comment\"># 显示文件的前6行</span></div><div class=\"line\">tail -25 mail.txt <span class=\"comment\"># 显示文件的最后25行</span></div><div class=\"line\">head -20 | tail 10 <span class=\"comment\"># 显示第11到第20行</span></div></pre></td></tr></table></figure>\n<p>另外，tail在查看log时特别有用<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">tail <span class=\"_\">-f</span> /var/logs/error.log</div></pre></td></tr></table></figure></p>\n<p>参数-f使tail不停地去读最新的内容，这样有实时监视的效果</p>\n<h3 id=\"IDEA常用快捷键-to-be-continued…\"><a href=\"#IDEA常用快捷键-to-be-continued…\" class=\"headerlink\" title=\"IDEA常用快捷键 (to be continued…)\"></a>IDEA常用快捷键 (to be continued…)</h3><p>连按两次Shift：全局查找<br>Ctrl+W：选择单词、语句、行、函数<br>Ctrl+Shift+/：代码块注释<br>Alt+方向键：左右切换文件<br>Alt+Shift+F10：运行<br>Shift+F10：运行<br>Alt+Enter：自动修正<br>Alt+Insert：生成Constructor/Getter/Setter等<br>Ctrl+E：最近文件</p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Internship"],"tags":["Linux","Ubuntu","IDEA"]},{"title":"实习整理(一)","url":"/2017/06/%E5%AE%9E%E4%B9%A0%E6%95%B4%E7%90%86-%E4%B8%80/","content":"<p>实习第一周结束了，下面整理一下这周遇到的一些问题。(所有操作均在Ubuntu系统下完成)</p>\n<h3 id=\"IDE配置：Intellij-IDEA\"><a href=\"#IDE配置：Intellij-IDEA\" class=\"headerlink\" title=\"IDE配置：Intellij IDEA\"></a>IDE配置：Intellij IDEA</h3><p>下载Ultimate版，下面网址生成license<br>生成各种软件注册码：<a href=\"http://www.98key.com\" target=\"_blank\" rel=\"external\">http://www.98key.com</a><br>在线注册服务器License Server: <a href=\"http://idea.iteblog.com/key.php\" target=\"_blank\" rel=\"external\">http://idea.iteblog.com/key.php</a></p>\n<h3 id=\"Java环境配置\"><a href=\"#Java环境配置\" class=\"headerlink\" title=\"Java环境配置\"></a>Java环境配置</h3><p>官网下载jdk，解压缩<br>将以下内容添加到/etc/profile文件结尾：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/home/wanghao/work/jdk</div><div class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</div><div class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></div></pre></td></tr></table></figure>\n<p>更新配置文件，执行：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">source</span> /etc/profile</div></pre></td></tr></table></figure></p>\n<p>测试java是否运行正常：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$JAVA_HOME</span></div><div class=\"line\">java -version</div></pre></td></tr></table></figure></p>\n<h3 id=\"安装tomcat\"><a href=\"#安装tomcat\" class=\"headerlink\" title=\"安装tomcat\"></a>安装tomcat</h3><p>官网下载tomcat源码，解压缩<br>打开bin目录下的startup.sh，添加以下几行：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">JAVA_HOME=/home/wanghao/work/jdk1.7.0_40</div><div class=\"line\">JRE_HOME=/home/wanghao/work/jdk1.7.0_40/jre</div><div class=\"line\">PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$JRE_HOME</span>:<span class=\"variable\">$PATH</span></div><div class=\"line\">CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib/dt.jar:<span class=\"variable\">$JAVA_HOME</span>/lib/tools.jar</div><div class=\"line\">TOMCAT_HOME=/home/wanghao/work/apache-tomcat</div></pre></td></tr></table></figure></p>\n<p>./startup.sh启动tomcat<br>./shutdown.sh关闭tomcat<br>启动之后不要马上关闭，否则可能因为tomcat还未完全启动就关闭，导致shutdown的时候报错：”Could not contact localhost:8005. Tomcat may not be running”</p>\n<h3 id=\"安装Git\"><a href=\"#安装Git\" class=\"headerlink\" title=\"安装Git\"></a>安装Git</h3><p>用命令“git –version”查看是否已安装，且版本为1.9.5或更高。若没安装或版本太低：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">sudo apt-get install git-core git-gui git-doc gitk</div></pre></td></tr></table></figure></p>\n<p>再用“git –version”查一下，如果安装的不是1.9.5版本，那是不是你的ubuntu太老了？试试下面的方法：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">sudo add-apt-repository ppa:git-core/ppa</div><div class=\"line\">sudo apt-get update</div><div class=\"line\">sudo apt-get install git</div></pre></td></tr></table></figure></p>\n<p>add-apt-repository 是由 python-software-properties 这个工具包提供的，如果使用 add-apt-repository显示“command not found”需要安装python-software-properties<br>安装方法：<br>1.首先需要安装software-properties-common<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">sudo apt-get install software-properties-common</div></pre></td></tr></table></figure></p>\n<p>2.然后安装python-software-properties<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">sudo apt-get install python-software-properties</div></pre></td></tr></table></figure></p>\n<h3 id=\"生成SSH-key\"><a href=\"#生成SSH-key\" class=\"headerlink\" title=\"生成SSH key\"></a>生成SSH key</h3><p>参考<a href=\"https://help.github.com/articles/connecting-to-github-with-ssh/\" target=\"_blank\" rel=\"external\">https://help.github.com/articles/connecting-to-github-with-ssh/</a></p>\n<h3 id=\"安装Maven\"><a href=\"#安装Maven\" class=\"headerlink\" title=\"安装Maven\"></a>安装Maven</h3><p>Maven是跨平台的，可以在任何一种主流的操作系统上运行，下面在基于Unix系统上安装Maven</p>\n<h4 id=\"1-检查JDK的安装-参照Java环境配置\"><a href=\"#1-检查JDK的安装-参照Java环境配置\" class=\"headerlink\" title=\"(1)检查JDK的安装,参照Java环境配置\"></a>(1)检查JDK的安装,参照Java环境配置</h4><h4 id=\"2-本地安装\"><a href=\"#2-本地安装\" class=\"headerlink\" title=\"(2)本地安装\"></a>(2)本地安装</h4><p> 下载压缩包，以版本3.0.5为例，解压缩到/usr/bin/apache-maven-3.0.5<br> 虽然直接使用该目录配置环境变量之后就能使用Maven了，但推荐做法是，在安装目录旁平行地创建一个符号链接，以方便日后的升级：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">ln <span class=\"_\">-s</span> apache-maven-3.0.5 apache-maven</div></pre></td></tr></table></figure></p>\n<p>设置环境变量M2_HOME，指向符号链接apache-maven，并且把Maven安装目录下的bin/文件夹添加到系统环境变量PATH中去。<br>修改文件 /etc/profile，添加两行：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> M2_HOME=/usr/bin/apache-maven</div><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$M2_HOME</span>/bin</div></pre></td></tr></table></figure></p>\n<p>别忘了<code>source /etc/profile</code>使配置生效。<br>检查Maven安装:<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$M2_HOME</span></div><div class=\"line\">mvn -v</div></pre></td></tr></table></figure></p>\n<h4 id=\"3-Maven版本的更改\"><a href=\"#3-Maven版本的更改\" class=\"headerlink\" title=\"(3)Maven版本的更改\"></a>(3)Maven版本的更改</h4><p>在基于Unix的系统上，可以利用符号链接这一工具来简化Maven的升级或降级，不必像在Windows上那样，每次更改版本都必须更新环境变量。<br>假设需要升级到新的Maven 3.1版本，将安装包解压到与前一版本平行的目录下，然后更新符号链接指向3.1版的目录便可：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">rm apache-maven</div><div class=\"line\">ln <span class=\"_\">-s</span> apache-maven-3.1 apache-maven</div></pre></td></tr></table></figure></p>\n<p>这样可以方便地切换到Maven的任意版本，切换完成后运行<code>mvn -v</code>进行检查。</p>\n<h3 id=\"ssh免跳板机登录开发机\"><a href=\"#ssh免跳板机登录开发机\" class=\"headerlink\" title=\"ssh免跳板机登录开发机\"></a>ssh免跳板机登录开发机</h3><p>企业为了服务器的安全，通常所有的ssh连接都是通过跳板机来完成，比便于对ssh连接进行验证和管理。跳板机通常至少配两块网卡，一个连接外网，用以对目标服务器远程登录及维护；另一个连接内网，便于内部网络的管理、控制和保护。通过网关服务提供从内网到外网、或从外网到内网的特殊协议路由服务。</p>\n<p>在企业内部，ssh登录开发机需要首先登录对应的跳板机，这样对于开发人员来说比较麻烦，因此可以设置免跳板机登录开发机，即只需第一次通过跳板机登录，以后可以直接登录开发机。</p>\n<p>以下操作的前提是可以从本地登录跳板机，同时可以从跳板机登录开发机。</p>\n<ul>\n<li>获取私钥<br>将跳板机上的私钥复制到本机，在<strong>本机</strong>上输入：<br><code>mkdir -p ~/.ssh/persist</code><br><code>scp [用户名]@[跳板机主机名]:~/.ssh/id_rsa ~/.ssh/id_rsa_[机房名]</code></li>\n<li>修改 ~/.ssh/config 文件<br>如果没有该文件就创建一个：<code>sudo touch ~/.ssh/config</code><br>然后拷贝下面内容到config文件中</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 将[机房名]、[跳板机主机名]、[用户名]替换成各自实际的名字</span></div><div class=\"line\"><span class=\"comment\"># gateway servers</span></div><div class=\"line\">Host [机房名]</div><div class=\"line\">    Hostname [跳板机主机名]</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># server</span></div><div class=\"line\">Host *.[机房名]</div><div class=\"line\">    ProxyCommand ssh [机房名] <span class=\"built_in\">exec</span> nc %h %p 2&gt;/dev/null</div><div class=\"line\">    IdentityFile ~/.ssh/id_rsa_[机房名]</div><div class=\"line\"></div><div class=\"line\">Host *</div><div class=\"line\">     User [用户名] <span class=\"comment\"># 你的本机的用户名如果和服务器上面的不一致，那需要配置这个，如果一致可以不用配置</span></div><div class=\"line\">     ServerAliveInterval 30</div><div class=\"line\">     ControlMaster auto</div><div class=\"line\">     ControlPath ~/.ssh/persist/master-%r@%h:%p</div><div class=\"line\">     ControlPersist yes</div><div class=\"line\"><span class=\"comment\"># 如果有多个机房的机器需要添加在这个文件中继续添加即可</span></div><div class=\"line\"><span class=\"comment\"># gateway servers</span></div><div class=\"line\">Host [机房名]</div><div class=\"line\">    Hostname [跳板机主机名]</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># server</span></div><div class=\"line\">Host *.[机房名]</div><div class=\"line\">    ProxyCommand ssh [机房名] <span class=\"built_in\">exec</span> nc %h %p 2&gt;/dev/null</div><div class=\"line\">    IdentityFile ~/.ssh/id_rsa_[机房名]</div><div class=\"line\"></div><div class=\"line\">Host *</div><div class=\"line\">     User [用户名]</div><div class=\"line\">     ServerAliveInterval 30</div><div class=\"line\">     ControlMaster auto</div><div class=\"line\">     ControlPath ~/.ssh/persist/master-%r@%h:%p</div><div class=\"line\">     ControlPersist yes</div></pre></td></tr></table></figure>\n<p>设置完成后，打开终端输入<code>ssh [开发机主机名]</code>，就可以直接登录了。</p>\n<h3 id=\"nginx-搭建\"><a href=\"#nginx-搭建\" class=\"headerlink\" title=\"nginx 搭建\"></a>nginx 搭建</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 安装</span></div><div class=\"line\">wget http://openresty.org/download/ngx_openresty-1.4.3.6.tar.gz</div><div class=\"line\">sudo yum -y install gcc make readline-devel pcre-devel openssl-devel</div><div class=\"line\">tar xzvf ngx_openresty-1.4.3.6.tar.gz</div><div class=\"line\"><span class=\"built_in\">cd</span> ngx_openresty-1.4.3.6</div><div class=\"line\">./configure --with-luajit --with-http_iconv_module</div><div class=\"line\">sudo gmake</div><div class=\"line\">sudo gmake install</div></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 启动</span></div><div class=\"line\">sudo /usr/<span class=\"built_in\">local</span>/openresty/nginx/sbin/nginx</div><div class=\"line\"><span class=\"comment\"># 重启</span></div><div class=\"line\">sudo /usr/<span class=\"built_in\">local</span>/openresty/nginx/sbin/nginx <span class=\"_\">-s</span> reload</div></pre></td></tr></table></figure>\n<h3 id=\"rsync的配置和使用\"><a href=\"#rsync的配置和使用\" class=\"headerlink\" title=\"rsync的配置和使用\"></a>rsync的配置和使用</h3><p>rsync实现网站的备份，文件的同步，不同系统的文件的同步，如果是windows的话，需要windows版本cwrsync</p>\n<p>配置参考<a href=\"http://blog.csdn.net/peisl/article/details/6931088\" target=\"_blank\" rel=\"external\">http://blog.csdn.net/peisl/article/details/6931088</a></p>\n<p>上传：<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">rsync -rzcv --chmod=<span class=\"string\">\"a=rX,u+w\"</span> --exclude=.svn --rsync-path=<span class=\"string\">\"sudo rsync\"</span> [FILENAME] [YOUR_HOST_NAME]:[YOUR_DIR_PATH]</div></pre></td></tr></table></figure></p>\n<p>下载：别忘了后面有一个点(.)<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">rsync -rzcv --chmod=<span class=\"string\">\"a=rX,u+w\"</span> --exclude=.svn --rsync-path=<span class=\"string\">\"sudo rsync\"</span> [YOUR_HOST_NAME]:[YOUR_DIR_PATH] .</div></pre></td></tr></table></figure></p>\n<h3 id=\"apt-file命令\"><a href=\"#apt-file命令\" class=\"headerlink\" title=\"apt-file命令\"></a>apt-file命令</h3><p>在Linux系统中安装软件时，常常会遇到缺少动态库依赖的问题，可以使用apt-file命令查看动态库所在的包，然后安装对应的包就可以了。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">sudo apt-get install apt-file <span class=\"comment\">#没有apt-file就安装一个</span></div><div class=\"line\">sudo apt-file update</div><div class=\"line\">sudo apt-file search libgstreamer-0.10.so.0 <span class=\"comment\">#查找动态库所在的包</span></div><div class=\"line\">sudo apt-get install libgstreamer-plugins-base0.10-0 <span class=\"comment\">#安装这个依赖包</span></div></pre></td></tr></table></figure>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Internship"],"tags":["Maven","Java","Ubuntu","nginx","IDEA","Git","rsync","免跳板机","缺少动态库依赖"]},{"title":"Frequently-used commands in Linux","url":"/2017/05/Frequently-used-commands-in-Linux/","content":"<p>This post concludes frequently-used commands in Linux, which might be functioning like a handy manual page for Linux commands.</p>\n<ul>\n<li>man</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ man [command] //manual page of [command]</div></pre></td></tr></table></figure>\n<ul>\n<li>ls</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ ls -a //display all files, including hidden files</div><div class=\"line\">$ ls -l //list detailed information</div><div class=\"line\">$ ls -r //list files according to name, in reversing order</div><div class=\"line\">$ ls -i //view inode number</div></pre></td></tr></table></figure>\n<ul>\n<li>cat</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ cat [filename] //print content of [filename]</div><div class=\"line\">$ cat -n [filename] //print content as well as line number</div><div class=\"line\">$ cat &gt; [filename] //create a new file and enter content from standard inputstream</div><div class=\"line\">$ cat [file1] [file2] &gt; [file3] //concat contents in [file1] and [file2], and then write to [file3]</div><div class=\"line\">$ cat [bigfile] | more //use pipeline and more to view [bigfile]</div><div class=\"line\">$ cat &gt;&gt; [filename] //add content to the end of [filename]</div></pre></td></tr></table></figure>\n<ul>\n<li>mv</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ mv [oldname] [newname] //change file name</div><div class=\"line\">$ mv [file] [directory] //move [file] to [directory]</div></pre></td></tr></table></figure>\n<ul>\n<li>rm</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ rm -i [file] //interactive mode, ask for confirmation before deleting</div><div class=\"line\">$ rm -f [file] //force to delete</div><div class=\"line\">$ rm -r [directory] //delete all sub-directories and files in [directory] recursively</div></pre></td></tr></table></figure>\n<ul>\n<li>grep (global regular expression print)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ grep [options] [PATTERN] [filename] //print contents which satisfy regular expression [PATTERN] in file [filename]</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">[options] includes: -n (display line number); -i (ignore character case); -v (display contents which don&apos;t satisfy regular expression)</div></pre></td></tr></table></figure>\n<ul>\n<li>find</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ find [path] [options] [expression] //find files whose name satisfies regular expression [expression] in the specific path [path]</div><div class=\"line\">e.g.: find . -name file.* //find files satisfying file.* in current directory</div><div class=\"line\">e.g.: find ./dir -name *.txt //find txt files in sub-directory ./dir</div></pre></td></tr></table></figure>\n<ul>\n<li>chmod</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ chmod u+x [file] //grant the user with execution authority</div><div class=\"line\">$ chmod a+r [file] //grant all users with reading authority</div><div class=\"line\">$ chmod 777 [file] //grant u(user),g(group),o(other) with reading(1), writing(2) and executing(4) authority (7=1+2+4)</div></pre></td></tr></table></figure>\n<ul>\n<li>tar</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ tar -czvf some.tar.gz file1 file2 file3 //compress file1, file2 and file3 using gzip</div><div class=\"line\">$ tar -xzvf some.tar.gz //uncompress some.tar.gz to current directory</div></pre></td></tr></table></figure>\n<ul>\n<li><p>pwd: print current working directory</p>\n</li>\n<li><p>diff</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ diff [file1] [file2] //compare two files and print differences</div></pre></td></tr></table></figure>\n<ul>\n<li>file: print the type of the file</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">e.g.: file test.txt</div><div class=\"line\">e.g.: file [directory]</div></pre></td></tr></table></figure>\n<ul>\n<li>ps</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ ps -a //display all processes, including other users&apos; processes</div><div class=\"line\">$ ps -u //display processes belonging to current user</div><div class=\"line\">$ ps -x //print complete information</div><div class=\"line\">$ ps -ef | grep tomcat //print all processes relevant to tomcat in standard way(more human-readable)</div><div class=\"line\">e.g.: ps -aux | grep &quot;google&quot; //print all processes relevant to &quot;google&quot; in BSD style</div></pre></td></tr></table></figure>\n<ul>\n<li><p>top: print processes in real time, similar to resources monitor in Windows</p>\n</li>\n<li><p>kill</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ kill -l //display all kill SIGNAL</div><div class=\"line\">$ kill -9 [PID] //force to kill process [PID]</div><div class=\"line\">$ kill -15 [PID] //kill process [PID] in a moderate way, which means reclaim resources of the process and then kill it</div><div class=\"line\">$ kill [PID] //same with kill -15 [PID]</div></pre></td></tr></table></figure>\n<ul>\n<li>more/less</li>\n</ul>\n<p>In general, both more and less print contents of a file to the screen. But they offer different functions. This <a href=\"http://www.cnblogs.com/aijianshi/p/5750911.html\" target=\"_blank\" rel=\"external\">article</a> is a good resource to understand them.</p>\n<ul>\n<li>uname</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ uname -a //check kernel version and name of the OS</div></pre></td></tr></table></figure>\n<ul>\n<li>netstat</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ netstat -a //display all possible columns</div><div class=\"line\">$ netstat -t //display TCP-relevant only</div><div class=\"line\">$ netstat -u //display UDP-relevant only</div><div class=\"line\">$ netstat -n //display number rather than name</div><div class=\"line\">$ netstat -l //display items which are in LISTEN status</div><div class=\"line\">$ netstat -p //display program names and PID of the connection</div><div class=\"line\">$ netstat</div><div class=\"line\"> -r //display kernel routing table</div><div class=\"line\">$ netstat -i //display kernel interface table</div><div class=\"line\">often used with grep:</div><div class=\"line\">netstat -anp | grep python //view connections relevant to python</div><div class=\"line\">netstat -anp | grep 8080 //view connections relevant to port 8080</div></pre></td></tr></table></figure>\n<ul>\n<li>touch</li>\n</ul>\n<p>Update the access and modification times of each FILE to the current time. But it is used to create a new file frequently.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ touch [OPTION] [FILE] //change file timestamps.</div></pre></td></tr></table></figure>\n<p>To be continued…</p>\n<hr>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Learning"],"tags":["Linux"]},{"title":"Wechat development with NodeJS","url":"/2017/02/Wechat-development-with-NodeJS/","content":"<p>I enjoyed the time with my family quite a lot during Chinese New Year. We made dumplings,  set off fireworks, watched Spring Festival Gala, and so on. However, happy time always runs fast. It’s time to finish the holiday and get back to work : )</p>\n<p>Now, I have a wechat public account(subscription account), and what I want to achieve is to implement a simple chatting robot with the help of <a href=\"https://cloud.baidu.com/product/bae.html\" target=\"_blank\" rel=\"external\">Baidu App Engine</a>.</p>\n<p>There are only 3 steps to go.</p>\n<h2 id=\"1-Create-Baidu-App-Engine\"><a href=\"#1-Create-Baidu-App-Engine\" class=\"headerlink\" title=\"#1 Create Baidu App Engine\"></a>#1 Create Baidu App Engine</h2><p>At first, I tried to use Heroku to host the server, but Heroku can’t pass the server url validation while configuring wechat public account. I guess the reason is that the IP of Heroku is in America, so I choose BAE as the server IP would be within mainland.</p>\n<p>Creating and managing a BAE app is concluded in this <a href=\"https://cloud.baidu.com/doc/BAE/GUIGettingStarted.html\" target=\"_blank\" rel=\"external\">tutorial</a>. </p>\n<p><img src=\"BAE-guide.png\" alt=\"guide for creating BAE\"></p>\n<h2 id=\"2-Configure-wechat-public-account\"><a href=\"#2-Configure-wechat-public-account\" class=\"headerlink\" title=\"#2 Configure wechat public account\"></a>#2 Configure wechat public account</h2><p>Before configuring wechat public account, it is essential to understand the work flow among <strong>user</strong>, <strong>wechat server</strong>, and <strong>my own server</strong>. This picture demonstrates the work flow very well.</p>\n<p><img src=\"workflow.png\" alt=\"workflow\"></p>\n<p>This is to say, wechat server stands between my server and the user. All messages between user and my server should go through wechat server first. Thus, as the server side, we need to tell wechat server the address of my server. This is where the below configuration comes from.</p>\n<p><img src=\"config.png\" alt=\"development configuration\"></p>\n<p>In this picture, URL is the route to send and receive messages in my own server. Token is an identity to tell wechat server that <strong>this is me</strong>. The encoding key is a key to encrypt and decrypt messages, and it can be generated randomly.</p>\n<h2 id=\"3-Build-server-with-Node-js\"><a href=\"#3-Build-server-with-Node-js\" class=\"headerlink\" title=\"#3 Build server with Node.js\"></a>#3 Build server with Node.js</h2><p>Firstly, wechat server will validate my server via a <code>GET</code> request, which contains 4 parameters: </p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>signature</td>\n<td>encrypted signature</td>\n</tr>\n<tr>\n<td>timestamp</td>\n<td>current time</td>\n</tr>\n<tr>\n<td>nonce</td>\n<td>random number</td>\n</tr>\n<tr>\n<td>echostr</td>\n<td>random string</td>\n</tr>\n</tbody>\n</table>\n<p>The signature is calculated by wechat server according to timestamp, nonce, and the specified token in last step. What should be done in my server is to calculate the signature again and compare it with the received one. If the two signatures are equal, the server should send the received <code>echostr</code> back to wechat server to tell that validation is success. If wechat server has not received the <code>echostr</code> or the received one is not correct, the valication is failed.</p>\n<p>If the validation is success, we can send and receive messages. This part is demonstrated in the <a href=\"http://mp.weixin.qq.com/wiki/17/f298879f8fb29ab98b2f2971d42552fd.html\" target=\"_blank\" rel=\"external\">official documentation</a>.</p>\n<p><strong>Note</strong>: The code can be accessed at <a href=\"https://github.com/xiangxianzui/wechat-nodejs\" target=\"_blank\" rel=\"external\">github</a>.</p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Learning"],"tags":["Node.JS","wechat","BAE"]},{"title":"LeetCode: Coin Change","url":"/2017/02/LeetCode-Coin-Change/","content":"<h2 id=\"Problem\"><a href=\"#Problem\" class=\"headerlink\" title=\"Problem\"></a>Problem</h2><p>You are given coins of different denominations and a total amount of money amount. Write a function to compute the fewest number of coins that you need to make up that amount. If that amount of money cannot be made up by any combination of the coins, return <code>-1</code>.</p>\n<p><strong>Example 1</strong>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">coins = [1, 2, 5], amount = 11</div><div class=\"line\">return 3 (11 = 5 + 5 + 1)</div></pre></td></tr></table></figure>\n<p><strong>Example 2</strong>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">coins = [2], amount = 3</div><div class=\"line\">return -1.</div></pre></td></tr></table></figure>\n<p><strong>Note</strong>: You may assume that you have an infinite number of each kind of coin.</p>\n<h2 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution\"></a>Solution</h2><p>This is a classic Dynamic Programming problem. Let’s take an example as usual. Given 3 types of coins with value <code>1</code>, <code>2</code>, <code>5</code> respectively, and the total money amount is <code>11</code>, try to select minimal number of coins to make up that amount.</p>\n<p>We denote that given money amount <code>s</code>, the number of coins being selected is <code>N(s)</code>. So the problem is to solve <code>N(11)</code>.</p>\n<p>At the beginning, it is easy to find that <code>N(0)=0</code>. Then,  if <code>s=1</code>, we can only select coin with value <code>1</code>, and we get <code>N(1)=1</code>. Then go to <code>s=2</code>. We can select coin with value <code>1</code> and value <code>2</code>. If select value <code>1</code>, the remaining amount is <code>1</code>, since we already know <code>N(1)=1</code>, so <code>N(2)=N(2-1)+1=2</code>; if select value <code>2</code>, the remaining amount is <code>0</code>, so <code>N(2)=N(2-2)+1=1</code>. The final <code>N(2)=min(2,1)=1</code>. Then we move on to <code>s=3</code>. We still can only select value <code>1</code> and value <code>2</code>. If select value <code>1</code>, <code>N(3)=N(3-1)+1=2</code>; if select value <code>2</code>, <code>N(3)=N(3-2)+1=2</code>. So the final <code>N(3)=min(2,2)=2</code>. We do this similarly until we reach <code>s=11</code>, and the answer is <code>N(11)=3</code>.</p>\n<p>From the above example, we can analyse this problem in a more general way. Given several types of coins with values <code>[V1, V2, ..., Vn]</code>, money amount <code>s</code>, and number of selected coins <code>N(s)</code>. If we already know <code>N(0), N(1), ..., N(s-1)</code>, we determine <code>N(s)</code> as <code>min{N(s-Vi)+1}</code>, where <code>1&lt;= i &lt;=n</code> and <code>Vi &lt;= s</code>. </p>\n<p>The java code could be like this:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">public class Solution &#123;</div><div class=\"line\">    public int coinChange(int[] coins, int amount) &#123;</div><div class=\"line\">        Map&lt;Integer,Integer&gt; map = new HashMap();</div><div class=\"line\">        map.put(0, 0);</div><div class=\"line\">        </div><div class=\"line\">        int a = 1;</div><div class=\"line\">        while(a&lt;=amount)&#123;</div><div class=\"line\">            int min = Integer.MAX_VALUE;</div><div class=\"line\">            boolean notPossible = true;</div><div class=\"line\">            for(int i=0; i&lt;coins.length; i++)&#123;</div><div class=\"line\">                if(a&gt;=coins[i])&#123;</div><div class=\"line\">                    if(map.get(a-coins[i])!=-1)&#123;</div><div class=\"line\">                        int temp = map.get(a-coins[i])+1;</div><div class=\"line\">                        if(temp&lt;min)    min = temp;</div><div class=\"line\">                        notPossible = false;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                    </div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">            if(notPossible==true)   map.put(a,-1);</div><div class=\"line\">            else&#123;</div><div class=\"line\">                map.put(a,min);</div><div class=\"line\">            &#125;</div><div class=\"line\">            a++;</div><div class=\"line\">        &#125;</div><div class=\"line\">        return map.get(amount);</div><div class=\"line\">        </div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["LeetCode"],"tags":["Dynamic Programming"]},{"title":"Learning LaTeX","url":"/2017/01/Learning-LaTeX/","content":"<h2 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h2><p><a href=\"http://www.latex-project.org/\" target=\"_blank\" rel=\"external\">LaTeX</a> is a document preparation system for high-quality typesetting, which is often used for technical and scientific documents. </p>\n<p>Let’s take an example first. Imagine you’re a writer, you want to write a new article and you start typing words in computer. When you open Microsoft Word, you find that you have to decide the font type, font size, layout … What you’re doing is not writing, but designing, which is definitely beyond the work of a writer! Well, this is where LaTeX comes. The biggest benefit of LaTeX is that it encourages authors to concentrate more on the document content but less on the document appearance. It makes authors work more efficiently.</p>\n<p>As a beginner, I often get confused by many terms in TeX world. The following picture really helped me out.</p>\n<p><img src=\"level-of-tex.png\" alt=\"Level of TeX\"></p>\n<p>To make LaTeX run on your computer, you need to intall it first. There are many free software in various platforms. Choose the one which suits your operating system. I am using <a href=\"https://miktex.org/\" target=\"_blank\" rel=\"external\">MiKTeX</a>, which is a Windows distribution.</p>\n<p>Next, I will go through two short, but powerful tutorials which could be accessed <a href=\"tutorial1.tex\">here</a> and <a href=\"tutorial2.tex\">here</a>. Paste each tutorial to <code>TexWorks</code> and press <code>CTRL + T</code> to view <code>PDF</code> result.</p>\n<h2 id=\"Tutorial-1\"><a href=\"#Tutorial-1\" class=\"headerlink\" title=\"Tutorial 1\"></a>Tutorial 1</h2><p>In tutorial1, the following knowledge could be concluded.</p>\n<ul>\n<li>Everything to the right of a  %  is a remark to you and is ignored by LaTeX.</li>\n<li>\\section{Section Title} makes a section title</li>\n<li>\\subsection{Subsection Title} makes a subsection title, and so as \\subsubsection and \\subsubsubsection …</li>\n<li>Words are separated by one or more spaces.  Paragraphs are separated by<br>one or more blank lines.  The output is not affected by adding extra<br>spaces or extra blank lines to the input file.</li>\n<li>Double quotes: ``quoted text’’</li>\n<li>Single quotes: `single-quoted text’</li>\n<li>Long dashes: like—this</li>\n<li>Emphasized text: \\emph{this is emphasized}</li>\n<li>Bold text: \\textbf{this is bold}</li>\n<li>The following seven are printed by typing a backslash in front of them:  \\$  \\&amp;  #  \\%  _  {  and  }.</li>\n</ul>\n<h2 id=\"Tutorial-2\"><a href=\"#Tutorial-2\" class=\"headerlink\" title=\"Tutorial 2\"></a>Tutorial 2</h2><p>In tutorial2, the following knowledge could be concluded.</p>\n<ul>\n<li>\\documentclass{article}: specifies the document class</li>\n<li>\\title{An Example Document}: declares the document’s title</li>\n<li>\\author{LesLie Lamport}: declares author name</li>\n<li>\\date{January 31, 2017}: declares date, deleting this command will produce today’s date</li>\n<li>\\maketitle: produces the title</li>\n<li>\\newcommand{\\ip}[2]{(#1, #2)}: defines new command with name ‘ip’ and two arguments</li>\n<li>\\LaTeX: generates the LaTeX logo</li>\n<li><p>Quotes within quotes: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">``\\,`this&apos; is what I just wrote, not `that&apos;\\,&apos;&apos; means &quot;&apos;this&apos; is what I just wrote, not &apos;that&apos;&quot;</div></pre></td></tr></table></figure>\n</li>\n<li><p>Intra word dash: intra-word (1 dash)</p>\n</li>\n<li>Medium dash: 1–2 (2 dashes)</li>\n<li>Long dash: like—this (3 dashes)</li>\n<li>Ellipsis: \\ldots</li>\n<li>TeX ignores spaces after command names</li>\n<li><p>Emphasize long sentence: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">\\begin&#123;em&#125;</div><div class=\"line\">  A long segment of text can also be emphasized </div><div class=\"line\">  in this way.  Text within such a segment can be </div><div class=\"line\">  given \\emph&#123;additional&#125; emphasis.</div><div class=\"line\">\\end&#123;em&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>Footnotes: Footnotes\\footnote{This is an example of a footnote.} pose no problem.</p>\n</li>\n<li>$ … $  and  ( … )  are equivalent, both denote a mathematical symbol</li>\n<li>Itemize &amp; Enumerate: <figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">\\begin&#123;itemize&#125;</div><div class=\"line\">  \\item This is the first item of an itemized list.</div><div class=\"line\">        Each item in the list is marked with a ``tick&apos;&apos;.</div><div class=\"line\">        You don&apos;t have to worry about what kind of tick</div><div class=\"line\">        mark is used.</div><div class=\"line\"></div><div class=\"line\">  \\item This is the second item of the list.  It</div><div class=\"line\">        contains another list nested inside it.  The inner</div><div class=\"line\">        list is an \\emph&#123;enumerated&#125; list.</div><div class=\"line\">        \\begin&#123;enumerate&#125;</div><div class=\"line\">           \\item This is the first item of an enumerated </div><div class=\"line\">                 list that is nested within the itemized list.</div><div class=\"line\"></div><div class=\"line\">           \\item This is the second item of the inner list.  </div><div class=\"line\">                 \\LaTeX\\ allows you to nest lists deeper than </div><div class=\"line\">                 you really should.</div><div class=\"line\">        \\end&#123;enumerate&#125;</div><div class=\"line\">        This is the rest of the second item of the outer</div><div class=\"line\">        list.  It is no more interesting than any other</div><div class=\"line\">        part of the item.</div><div class=\"line\">  \\item This is the third item of the list.</div><div class=\"line\">\\end&#123;itemize&#125;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Learning"],"tags":["LaTex"]},{"title":"Upload image to a Node.JS server","url":"/2017/01/Upload-image-to-a-Node-JS-server/","content":"<p>Recently, I came up with a problem that I need to upload images to a Node server and display the image instantly. I write this post to keep a record of what I have done.</p>\n<p>Generally, firstly I wrap the uploading image as a <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/FormData\" target=\"_blank\" rel=\"external\">FormData</a>. </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#'upload[]' is the name attr of #upload-input</span></div><div class=\"line\"><span class=\"comment\">#append the selected file to formData obj</span></div><div class=\"line\">formData.append(<span class=\"string\">'upload[]'</span>, file, file.name);</div></pre></td></tr></table></figure>\n<p>Then I use jquery <code>.ajax()</code> method to send <code>POST</code> request to the server. </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#processData:false means to stop jquery from converting the formData object to string</span></div><div class=\"line\"><span class=\"comment\">#contentType:false means to tell jquery not to add a Content-Type header</span></div><div class=\"line\">$.ajax(&#123;</div><div class=\"line\">\turl: <span class=\"string\">'/upload'</span>,</div><div class=\"line\">\t<span class=\"built_in\">type</span>: <span class=\"string\">'POST'</span>,</div><div class=\"line\">\tdata: formData,</div><div class=\"line\">\tprocessData: <span class=\"literal\">false</span>,</div><div class=\"line\">    contentType: <span class=\"literal\">false</span>,</div><div class=\"line\">\tsuccess: <span class=\"keyword\">function</span>(data)&#123;</div><div class=\"line\">\t\t<span class=\"comment\">#do something when success</span></div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;);</div></pre></td></tr></table></figure>\n<p>At server, <a href=\"https://github.com/felixge/node-formidable\" target=\"_blank\" rel=\"external\">formidable</a> middleware is used to handle the uploading file. </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">app.post(<span class=\"string\">'/upload'</span>, <span class=\"keyword\">function</span>(req, res)&#123;</div><div class=\"line\">  <span class=\"comment\">#create an incoming form object</span></div><div class=\"line\">  var form = new formidable.IncomingForm();</div><div class=\"line\">  <span class=\"comment\">#specify that we don't want user to upload multiple files at the same time; set true to allow.</span></div><div class=\"line\">  form.multiples = <span class=\"literal\">false</span>;</div><div class=\"line\">  <span class=\"comment\">#store uploads in /uploads directory</span></div><div class=\"line\">  form.uploadDir = path.join(process.cwd(), <span class=\"string\">'/uploads'</span>);</div><div class=\"line\">  <span class=\"comment\">#log any occured error</span></div><div class=\"line\">  form.on(<span class=\"string\">'error'</span>, <span class=\"keyword\">function</span>(err)&#123;</div><div class=\"line\">     console.log(<span class=\"string\">'File Uploading Error: '</span>+err);</div><div class=\"line\">  &#125;);</div><div class=\"line\">  <span class=\"comment\">#parse the incoming request containing form data</span></div><div class=\"line\">  form.parse(req, <span class=\"keyword\">function</span>(err, fields, files)&#123;</div><div class=\"line\">\t  var file = files[<span class=\"string\">'upload[]'</span>];</div><div class=\"line\">      <span class=\"comment\">#rename the uploaded file as its origin name</span></div><div class=\"line\">      fs.rename(file.path, path.join(form.uploadDir, file.name));</div><div class=\"line\">      res.send(<span class=\"string\">'success'</span>);</div><div class=\"line\">  &#125;);</div><div class=\"line\">&#125;);</div></pre></td></tr></table></figure>\n<p><strong>Note: A working demo is available in <a href=\"https://github.com/xiangxianzui/node-image-previewer-uploader\" target=\"_blank\" rel=\"external\">github</a>.</strong></p>\n<p>The demo could be used like this:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># clone the repo to local machine</span></div><div class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/xiangxianzui/node-image-previewer-uploader</div><div class=\"line\"><span class=\"comment\"># open code directory</span></div><div class=\"line\">$ <span class=\"built_in\">cd</span> node-image-previewer-uploader</div><div class=\"line\"><span class=\"comment\"># install node dependencies</span></div><div class=\"line\">$ npm install</div><div class=\"line\"><span class=\"comment\"># run the server</span></div><div class=\"line\">$ node server.js</div></pre></td></tr></table></figure>\n<h4 id=\"File-Structure\"><a href=\"#File-Structure\" class=\"headerlink\" title=\"File Structure\"></a>File Structure</h4><ul>\n<li><strong>server.js</strong> is Node server, which contains routes and main logic of back end</li>\n<li><strong>.env</strong> stores environmenal variable while developing. A node module called <code>dotenv</code> can be used to load variables in <code>.env</code> file to global variable <code>process</code></li>\n<li><strong>package.json</strong> contains information of this project and dependencies</li>\n<li><strong>/public</strong> contains javascript, css, fonts and images, which will be used in front end</li>\n<li><strong>/views</strong> contains HTML templates</li>\n<li><strong>/uploads</strong> stores uploaded images</li>\n</ul>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Learning"],"tags":["Node.JS"]},{"title":"LeetCode: Convert a Number to Hexadecimal","url":"/2017/01/LeetCode-Convert-a-Number-to-Hexadecimal/","content":"","categories":["LeetCode"],"tags":["Bit Manipulation"]},{"title":"LeetCode: Binary Watch","url":"/2017/01/LeetCode-Binary-Watch/","content":"<h2 id=\"Problem\"><a href=\"#Problem\" class=\"headerlink\" title=\"Problem\"></a>Problem</h2><p>A binary watch has 4 LEDs on the top which represent the <strong>hours (0-11)</strong>, and the 6 LEDs on the bottom represent the <strong>minutes (0-59)</strong>.</p>\n<p>Each LED represents a zero or one, with the least significant bit on the right.</p>\n<p><img src=\"Binary_clock_samui_moon.jpg\" alt=\"Binary Watch\"></p>\n<p>For example, the above binary watch reads “3:25”.</p>\n<p>Given a non-negative integer n which represents the number of LEDs that are currently on, return all possible times the watch could represent.</p>\n<p><strong>Example</strong>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">Input: n = 1</div><div class=\"line\">Return: [&quot;1:00&quot;, &quot;2:00&quot;, &quot;4:00&quot;, &quot;8:00&quot;, &quot;0:01&quot;, &quot;0:02&quot;, &quot;0:04&quot;, &quot;0:08&quot;, &quot;0:16&quot;, &quot;0:32&quot;]</div></pre></td></tr></table></figure>\n<p><strong>Note</strong>:</p>\n<ul>\n<li>The order of output does not matter.</li>\n<li>The hour must not contain a leading zero, for example “01:00” is not<br>valid, it should be “1:00”.</li>\n<li>The minute must be consist of two digits and may contain a leading<br>zero, for example “10:2” is not valid, it should be “10:02”.</li>\n</ul>\n<h2 id=\"Solution-1\"><a href=\"#Solution-1\" class=\"headerlink\" title=\"Solution 1\"></a>Solution 1</h2><p>The following code goes through all possible times, and checks if the time has correct number of one-bit.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">public List&lt;String&gt; readBinaryWatch(int num) &#123;</div><div class=\"line\">        List&lt;String&gt; result = new ArrayList();</div><div class=\"line\">        for(int h=0; h&lt;12; h++)&#123;</div><div class=\"line\">            for(int m=0; m&lt;60; m++)&#123;</div><div class=\"line\">                if(Integer.bitCount(h) + Integer.bitCount(m) == num)&#123;</div><div class=\"line\">                    result.add(String.format(&quot;%d:%02d&quot;, h, m));</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        return result;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<p><strong>Note</strong>:<br><code>Integer.bitCount(N)</code> returns the number of one-bits in the two’s complement binary representation of the specified int value N.</p>\n<h2 id=\"Solution-2\"><a href=\"#Solution-2\" class=\"headerlink\" title=\"Solution 2\"></a>Solution 2</h2><p>The following code describes the framework of the solution:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">int[] hours = new int[] &#123;8,4,2,1&#125;;</div><div class=\"line\">int[] minutes = new int[] &#123;32,16,8,4,2,1&#125;;</div><div class=\"line\">for(int i=0; i&lt;=nums; i++)&#123;</div><div class=\"line\">\t//select i elements from hours, add them to get the hour</div><div class=\"line\">\t//select (nums-i) elements from minutes, add them to get the minute</div><div class=\"line\">\t//then construct one possible time</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Thus, the first thing we need to solve is <strong>how to select r elements from an array with n elements?</strong></p>\n<p>My idea is to permutate the array, and select the first r elements.</p>\n<p><strong>Example</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">array = [1,2,3]</div><div class=\"line\">All permutations of the array are: [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1].</div><div class=\"line\">If we select the first 2 elements, we will get [1,2], [1,3], [2,1], [2,3], [3,1], [3,2].</div><div class=\"line\">[1,2] and [2,1] are same, so we need to remove duplicates.</div></pre></td></tr></table></figure>\n<p>The following code calculates all permutations of an array, select the first r elements of each permutation, and removes duplicates with the help of <code>HashSet</code>.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">public void permute(int[] nums, int start, int end, int r, Set&lt;List&lt;Integer&gt;&gt; results)&#123;</div><div class=\"line\">    if(start==end)&#123;</div><div class=\"line\">\t    //do something with a permutation here</div><div class=\"line\">\t    List&lt;Integer&gt; result = new ArrayList();</div><div class=\"line\">        for(int i=0; i&lt;r; i++)&#123;</div><div class=\"line\">\t        result.add(nums[i]);</div><div class=\"line\">        &#125;</div><div class=\"line\">        results.add(result);</div><div class=\"line\">    &#125;</div><div class=\"line\">        </div><div class=\"line\">    for(int i=start; i&lt;=end; i++)&#123;</div><div class=\"line\">\t    //swap the current element with start element</div><div class=\"line\">        int temp = nums[i];</div><div class=\"line\">        nums[i] = nums[start];</div><div class=\"line\">        nums[start] = temp;</div><div class=\"line\">        //recursively permute all latter elements</div><div class=\"line\">        permute(nums, start+1, end, r);</div><div class=\"line\">        //after one permutation, swap back</div><div class=\"line\">        temp = nums[i];</div><div class=\"line\">        nums[i] = nums[start];</div><div class=\"line\">        nums[start] = temp;   </div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>The above code is an important framework of <strong>permutation problems</strong>. It could be explained as: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">Let &#123;a,b,c&#125; denote all permutations of [a,b,c]</div><div class=\"line\">then, &#123;a,b,c&#125; = a&#123;b,c&#125; + b&#123;a,c&#125; + c&#123;a,b&#125;</div><div class=\"line\">and permute &#123;b,c&#125;, &#123;a,c&#125;, &#123;a,b&#125; recursively.</div></pre></td></tr></table></figure>\n<p>After solving <strong>selecting r elements from an array with n elements</strong>, we can move on to construct the time with the hour and minute we get.</p>\n<p>The complete code is as follows:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">public class Solution &#123;</div><div class=\"line\">    public List&lt;String&gt; readBinaryWatch(int num) &#123;</div><div class=\"line\">        List&lt;String&gt; result = new ArrayList();</div><div class=\"line\">        int[] hours = new int[] &#123;8,4,2,1&#125;;</div><div class=\"line\">        int[] minutes = new int[] &#123;32,16,8,4,2,1&#125;;</div><div class=\"line\">        Set&lt;Integer&gt; selectedHours = new HashSet();</div><div class=\"line\">        Set&lt;Integer&gt; selectedMinutes = new HashSet();</div><div class=\"line\">        for(int i=0; i&lt;=num; i++)&#123;</div><div class=\"line\">            if(i&lt;=4 &amp;&amp; num-i&lt;=6)&#123;</div><div class=\"line\">                selectFromHours(hours, 0, hours.length-1, i, selectedHours);</div><div class=\"line\">                selectFromMinutes(minutes, 0, minutes.length-1, num-i, selectedMinutes);</div><div class=\"line\">                for(int h : selectedHours)&#123;</div><div class=\"line\">                    for(int m : selectedMinutes)&#123;</div><div class=\"line\">                        String m_str = (m&lt;10) ? (&quot;0&quot;+m) : (&quot;&quot;+m);</div><div class=\"line\">                        result.add(h+&quot;:&quot;+m_str);</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">                selectedHours.clear();</div><div class=\"line\">                selectedMinutes.clear();</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        </div><div class=\"line\">        return result;</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">    public void selectFromHours(int[] hours, int start, int end, int r, Set&lt;Integer&gt; selectedHours)&#123;</div><div class=\"line\">        if(r==0)&#123;</div><div class=\"line\">            selectedHours.add(0);</div><div class=\"line\">            return;</div><div class=\"line\">        &#125;</div><div class=\"line\">        if(start==end)&#123;</div><div class=\"line\">            int sum = 0;</div><div class=\"line\">            for(int j=0; j&lt;r; j++)&#123;</div><div class=\"line\">                sum += hours[j];</div><div class=\"line\">            &#125;</div><div class=\"line\">            if(sum&lt;=11)&#123;</div><div class=\"line\">                selectedHours.add(sum);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        </div><div class=\"line\">        for(int i=start; i&lt;=end; i++)&#123;</div><div class=\"line\">            int temp = hours[i];</div><div class=\"line\">            hours[i] = hours[start];</div><div class=\"line\">            hours[start] = temp;</div><div class=\"line\">            selectFromHours(hours, start+1, end, r, selectedHours);</div><div class=\"line\">            temp = hours[i];</div><div class=\"line\">            hours[i] = hours[start];</div><div class=\"line\">            hours[start] = temp;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">    public void selectFromMinutes(int[] minutes, int start, int end, int r, Set&lt;Integer&gt; selectedMinutes)&#123;</div><div class=\"line\">        if(r==0)&#123;</div><div class=\"line\">            selectedMinutes.add(0);</div><div class=\"line\">            return;</div><div class=\"line\">        &#125;</div><div class=\"line\">        if(start==end)&#123;</div><div class=\"line\">            int sum = 0;</div><div class=\"line\">            for(int j=0; j&lt;r; j++)&#123;</div><div class=\"line\">                sum += minutes[j];</div><div class=\"line\">            &#125;</div><div class=\"line\">            if(sum&lt;=59)&#123;</div><div class=\"line\">                selectedMinutes.add(sum);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        </div><div class=\"line\">        for(int i=start; i&lt;=end; i++)&#123;</div><div class=\"line\">            int temp = minutes[i];</div><div class=\"line\">            minutes[i] = minutes[start];</div><div class=\"line\">            minutes[start] = temp;</div><div class=\"line\">            selectFromMinutes(minutes, start+1, end, r, selectedMinutes);</div><div class=\"line\">            temp = minutes[i];</div><div class=\"line\">            minutes[i] = minutes[start];</div><div class=\"line\">            minutes[start] = temp;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["LeetCode"],"tags":["Backtracking"]},{"title":"LeetCode: Delete Node in a Linked List","url":"/2017/01/LeetCode-Delete-Node-in-a-Linked-List/","content":"<h2 id=\"Problem\"><a href=\"#Problem\" class=\"headerlink\" title=\"Problem\"></a>Problem</h2><p>Write a function to delete a node (except the tail) in a singly linked list, given only access to that node.</p>\n<p>Supposed the linked list is <code>1 -&gt; 2 -&gt; 3 -&gt; 4</code> and you are given the third node with value <code>3</code>, the linked list should become <code>1 -&gt; 2 -&gt; 4</code> after calling your function.</p>\n<h2 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution\"></a>Solution</h2><p>The solution is a little tricky. Normally, when we delete a node from a linked list, we should know the previous node of the one we want to delete. However, at this time, we only have access to the node to be deleted. So, we have to “<strong>sacrifice</strong>“ the next node! Here is the java code:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">public class Solution &#123;</div><div class=\"line\">    public void deleteNode(ListNode node) &#123;</div><div class=\"line\">        if(node!=null)&#123;</div><div class=\"line\">            node.val = node.next.val;</div><div class=\"line\">            node.next = node.next.next;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>This problem is quite easy, but tricky. I just want to record this trick to guarantee I won’t forget it someday :)</p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["LeetCode"],"tags":["Linked List"]},{"title":"LeetCode: Move Zeroes","url":"/2017/01/LeetCode-Move-Zeroes/","content":"<h2 id=\"Problem\"><a href=\"#Problem\" class=\"headerlink\" title=\"Problem\"></a>Problem</h2><p>Given an array nums, write a function to move all 0’s to the end of it while maintaining the relative order of the non-zero elements.</p>\n<p>For example, given <code>nums = [0, 1, 0, 3, 12]</code>, after calling your function, <code>nums</code> should be <code>[1, 3, 12, 0, 0]</code>.</p>\n<p><strong>Note</strong>:<br>You must do this in-place without making a copy of the array.<br>Minimize the total number of operations.</p>\n<h2 id=\"Solution-1-–-59ms\"><a href=\"#Solution-1-–-59ms\" class=\"headerlink\" title=\"Solution 1 – 59ms\"></a>Solution 1 – 59ms</h2><p>Go through the array. If <code>ith</code> element is 0, then move all elements within [i+1,nums,length-1] one place ahead, and set the last element of the array to 0. To prevent endless loop when <code>nums=[0,0,...,0]</code>, set a variable <code>reapeatCount</code>.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">public void moveZeroes(int[] nums) &#123;</div><div class=\"line\">    int repeatCount = 0;</div><div class=\"line\">    for(int i=0; i&lt;nums.length; i++)&#123;</div><div class=\"line\">        if(nums[i]==0)&#123;</div><div class=\"line\">            for(int j=i; j&lt;nums.length-1; j++)&#123;</div><div class=\"line\">                nums[j] = nums[j+1];</div><div class=\"line\">            &#125;</div><div class=\"line\">            nums[nums.length-1] = 0;</div><div class=\"line\">            i--;</div><div class=\"line\">            repeatCount++;</div><div class=\"line\">        &#125;</div><div class=\"line\">        if(repeatCount==nums.length)    break;</div><div class=\"line\">            </div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"Solution-2-–-19ms\"><a href=\"#Solution-2-–-19ms\" class=\"headerlink\" title=\"Solution 2 – 19ms\"></a>Solution 2 – 19ms</h2><p>Go through the array. If <code>ith</code> element is 0, then find the first non-zero element within range [i+1,nums.length-1] and swap it with current element; if there is no such non-zero element, it means all non-zero elements are before zeroes – done! If current element is non-zero, just go on to the next.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">public void moveZeroes(int[] nums) &#123;</div><div class=\"line\">    if(nums != null)&#123;</div><div class=\"line\">        for(int i=0; i&lt;nums.length; i++)&#123;</div><div class=\"line\">            if(nums[i]==0)&#123;</div><div class=\"line\">                //find the first non-zero element within range [i+1,nums.length-1]</div><div class=\"line\">                int firstNonZeroIdx = -1;</div><div class=\"line\">                for(int j=i+1; j&lt;nums.length; j++)&#123;</div><div class=\"line\">                    if(nums[j]!=0)&#123;</div><div class=\"line\">                        firstNonZeroIdx = j;</div><div class=\"line\">                        break;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">                if(firstNonZeroIdx==-1) break;</div><div class=\"line\">                else&#123;</div><div class=\"line\">                    int temp = nums[i];</div><div class=\"line\">                    nums[i] = nums[firstNonZeroIdx];</div><div class=\"line\">                    nums[firstNonZeroIdx] = temp;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Solution 2 is better than Solution 1. This is because in Solution 1, it is unnecessary to move all elements after a non-zero element one place ahead. </p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["LeetCode"],"tags":["Array"]},{"title":"LeetCode: Sum of Two Integers","url":"/2017/01/LeetCode-Sum-of-Two-Integers/","content":"<h2 id=\"Problem\"><a href=\"#Problem\" class=\"headerlink\" title=\"Problem\"></a>Problem</h2><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">Calculate the sum of two integers a and b, but you are not allowed to use the operator + and -.</div><div class=\"line\"></div><div class=\"line\">Example:</div><div class=\"line\">Given a = 1 and b = 2, return 3.</div></pre></td></tr></table></figure>\n<h2 id=\"Solution\"><a href=\"#Solution\" class=\"headerlink\" title=\"Solution\"></a>Solution</h2><p>Think this problem with an example. </p>\n<p>Consider 15+9=24.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#XOR holds the remaining part of the result</span></div><div class=\"line\">     00001111</div><div class=\"line\">XOR  00001001</div><div class=\"line\">-------------</div><div class=\"line\">     00000110</div></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#AND holds the carry part of the result</span></div><div class=\"line\">     00001111</div><div class=\"line\">AND  00001001</div><div class=\"line\">-------------</div><div class=\"line\">     00001001</div></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># shift the carry to left for 1 place, and add with the remaining</span></div><div class=\"line\">     00000110</div><div class=\"line\"> +   00010010</div><div class=\"line\">-------------</div><div class=\"line\">     00011000</div></pre></td></tr></table></figure>\n<p>Thus, for any integer <code>a</code> and <code>b</code>, <code>a + b = a^b + (a&amp;b)&lt;&lt;1</code>. Because <code>+</code> operator is not allowed, we can regard <code>a^b</code> as new <code>a</code>, and <code>(a&amp;b)&lt;&lt;1</code> as new <code>b</code>. Repeat this until current carry is <code>0</code>.</p>\n<p>The java implementation is like this:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Java solution</span></div><div class=\"line\">public class Solution &#123;</div><div class=\"line\">    public int getSum(int a, int b) &#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(b==0)    <span class=\"built_in\">return</span> a;</div><div class=\"line\">        <span class=\"keyword\">while</span>(b!=0)&#123;</div><div class=\"line\">            int carry = (a&amp;b)&lt;&lt;1;</div><div class=\"line\">            int remain = a^b;</div><div class=\"line\">            b = carry;</div><div class=\"line\">            a = remain;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">return</span> a;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["LeetCode"],"tags":["Bit Manipulation"]},{"title":"Customize hexo blogs","url":"/2017/01/Customize-hexo-blogs/","content":"<p>In my previous <a href=\"https://xiangxianzui.github.io/2017/01/Build-blogs-with-Hexo/\">post</a>, I introduced how to build personal blog site with the help of <a href=\"https://hexo.io\" target=\"_blank\" rel=\"external\">Hexo</a> and <a href=\"https://pages.github.com/\" target=\"_blank\" rel=\"external\">Github Pages</a>. Now it’s time to customize the hexo blog to show some personalities.</p>\n<h2 id=\"config-yml\"><a href=\"#config-yml\" class=\"headerlink\" title=\"_config.yml\"></a>_config.yml</h2><p><em>_config.yml</em> is the configuration file of your hexo blog (in project root dir).</p>\n<p>Hexo lets you define your site information, customize date/time format, pagination behaviour, language settings, etc. Most configs are not necessary, but it will make your site look more like <em>yours</em> if you specify them properly.</p>\n<p>Here is my site config:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Site</span></div><div class=\"line\">title: Muser</div><div class=\"line\">subtitle: Coding While Thinking</div><div class=\"line\">description: thinking <span class=\"keyword\">in</span> a different way</div><div class=\"line\">author: xiangxianzui</div><div class=\"line\">email: xiangxianzui@gmail.com</div></pre></td></tr></table></figure>\n<p>Url config: </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># URL</span></div><div class=\"line\"><span class=\"comment\">## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'</span></div><div class=\"line\">url: https://xiangxianzui.github.io</div><div class=\"line\">root: /</div><div class=\"line\">permalink: :year/:month/:title/</div></pre></td></tr></table></figure>\n<h2 id=\"Tags-amp-Categories\"><a href=\"#Tags-amp-Categories\" class=\"headerlink\" title=\"Tags &amp; Categories\"></a>Tags &amp; Categories</h2><p>Tags and Categories can be defined in the front matter of every post you create. Front matter is in the very beginning of your post. You can define tags and categories like this:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">tags: [Hexo, node.js]</div><div class=\"line\">categories: [Guides]</div></pre></td></tr></table></figure>\n<p>To delete a tag or category, firstly you need to delete it from the front matter of your post, then clean the hexo database (db.json in project root) and /public folder by typing:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#Delete database</span></div><div class=\"line\"><span class=\"comment\">#Delete public folder</span></div><div class=\"line\">hexo clean</div></pre></td></tr></table></figure>\n<p>And then, regenerate the database and public folder by typing:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">hexo generate</div></pre></td></tr></table></figure>\n<h2 id=\"Asset-Folders\"><a href=\"#Asset-Folders\" class=\"headerlink\" title=\"Asset Folders\"></a>Asset Folders</h2><p>As usual, you can reference online images in your markdown like this: <code>![image-title](http://some-image-site/some-image.png)</code>. But how to reference local images? Hexo gives you two options.</p>\n<p>The first is to create a global asset folder. For example, create /images folder in /source directory, and put all your images into it. Then, you can reference them in this way: <code>![image-title](/images/image.png)</code>.</p>\n<p>If you want to put your images according to post, which means one asset folder per post, you can set <code>post_asset_folder</code> to true in <em>_config.yml</em>. And when you <code>$ hexo new post [new-post]</code>, an asset folder will be created by hexo automatically.</p>\n<h2 id=\"Enabling-Comments\"><a href=\"#Enabling-Comments\" class=\"headerlink\" title=\"Enabling Comments\"></a>Enabling Comments</h2><p>The default theme (landscape) of Hexo already supports <a href=\"https://disqus.com/\" target=\"_blank\" rel=\"external\">Disqus</a>. So, just go to Disqus, register an account, and click <em>install Disqus on site</em>. Follow the guideline, and specify a unique disqus shortname. After that, add this to your <em>_config.yml</em>.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Disqus comments</span></div><div class=\"line\">disqus_shortname: [your-disqus-shortname]</div></pre></td></tr></table></figure>\n<h2 id=\"RSS-amp-Sitemap-plugin\"><a href=\"#RSS-amp-Sitemap-plugin\" class=\"headerlink\" title=\"RSS &amp; Sitemap plugin\"></a>RSS &amp; Sitemap plugin</h2><p>Use the official tool <em>hexo-generator-feed</em> to generate RSS feed. Firstly intall it:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ npm install hexo-generator-feed --save</div></pre></td></tr></table></figure>\n<p>Configure options in <em>_config.yml</em>:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># RSS feed</span></div><div class=\"line\">feed:</div><div class=\"line\">  <span class=\"built_in\">type</span>: atom</div><div class=\"line\">  path: atom.xml</div><div class=\"line\">  <span class=\"built_in\">limit</span>: 20</div><div class=\"line\">  hub:</div><div class=\"line\">  content:</div></pre></td></tr></table></figure>\n<ul>\n<li>type - Feed type. (atom/rss2)</li>\n<li>path - Feed path. (Default: atom.xml/rss2.xml)</li>\n<li>limit - Maximum number of posts in the feed (Use 0 or false to show<br>all posts)</li>\n<li>hub - URL of the PubSubHubbub hubs (Leave it empty if you don’t use<br>it)</li>\n<li>content - (optional) set to ‘true’ to include the contents of the<br>entire post in the feed.</li>\n</ul>\n<p>A <em>atom.xml</em> file will be generated automatically when you run <code>hexo generate</code>.</p>\n<p>To generate sitemap, use the official <a href=\"https://github.com/hexojs/hexo-generator-sitemap\" target=\"_blank\" rel=\"external\">hexo-generator-sitemap</a> plugin. </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">A sitemap is a file <span class=\"built_in\">where</span> you can list the web pages of your site to tell Google and other search engines about the organization of your site content. Search engine web crawlers like Googlebot <span class=\"built_in\">read</span> this file to more intelligently crawl your site.</div></pre></td></tr></table></figure>\n<p>–From Google</p>\n<h2 id=\"Customize-default-theme\"><a href=\"#Customize-default-theme\" class=\"headerlink\" title=\"Customize default theme\"></a>Customize default theme</h2><h3 id=\"Add-icons-to-navigation-bar\"><a href=\"#Add-icons-to-navigation-bar\" class=\"headerlink\" title=\"Add icons to navigation bar\"></a>Add icons to navigation bar</h3><p>I will explain how to add icons to the navigation bar in the default theme.</p>\n<p>Open directory <code>/themes/landscape/source/css/_partial</code>, and find <code>header.styl</code>. Add following code:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">#nav-github-link</div><div class=\"line\">  &amp;:before</div><div class=\"line\">    content: &quot;\\f09b&quot;</div></pre></td></tr></table></figure>\n<p>Then, open directory <code>/themes/landscape/layout/_partial</code>, find <code>header.ejs</code> and open it. Find the following section:</p>\n<p><img src=\"hexo-1.png\" alt=\"Edit header.ejs\"></p>\n<p><strong>Note:</strong> <code>theme</code> is a JavaScript object representation of the theme’s <code>_config.yml</code> </p>\n<p>Add the code from line 22 to 24 to your header.ejs.</p>\n<p>Finally, open <code>_config.yml</code> in <code>themes/landscape</code>, add code:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><div class=\"line\">github: [your-github-address]</div></pre></td></tr></table></figure>\n<p>It may looks like this:</p>\n<p><img src=\"hexo-2.png\" alt=\"Edit _config.yml\"></p>\n<p>Yess! Your navigation bar will look like this:</p>\n<p><img src=\"hexo-3.png\" alt=\"new navigation bar\"></p>\n<h3 id=\"Change-banner\"><a href=\"#Change-banner\" class=\"headerlink\" title=\"Change banner\"></a>Change banner</h3><p>In addition, you can change the banner of the page. The <em>banner.jpg</em> is in <code>/themes/landscape/source/css/images</code>, and you can replace it with your own.</p>\n<h3 id=\"Show-category-count\"><a href=\"#Show-category-count\" class=\"headerlink\" title=\"Show category count\"></a>Show category count</h3><p>Again, open the theme’s <code>_config.yml</code>, set <code>show_count</code> to <code>true</code>.</p>\n<p>Then, it will be looking like this:</p>\n<p><img src=\"hexo-4.png\" alt=\"show category count\"></p>\n<h2 id=\"Google-Analytics\"><a href=\"#Google-Analytics\" class=\"headerlink\" title=\"Google Analytics\"></a>Google Analytics</h2><p>Google Analytics tell the site owner about how many people have visited the website, how long they averagely stay and what kind of people visit (male or female? Asian or American?). It is a brilliant tool for site owners to grasp the whole picture.</p>\n<p>The default theme, Landscape, is already supporting Google Analytics. If you are using Landscape or another theme which supports Google Analytics,  you can simply add your Google Analytics tracking ID (get tracking ID <a href=\"https://support.google.com/analytics/answer/1008080?hl=en\" target=\"_blank\" rel=\"external\">here</a>) to the theme’s <code>_config.yml</code> like this:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">google_analytics: [your-tracking-id]</div></pre></td></tr></table></figure>\n<p>If your theme does not support Google Analytics, check <a href=\"http://www.codeblocq.com/2015/12/Add-Google-Analytics-to-your-hexo-blog/\" target=\"_blank\" rel=\"external\">this post</a>.</p>\n<p>Until now, you have enabled Google Analytics in your site, but the question is you can’t see it. To display the analytics from Google, you need to use Embed API. This <a href=\"https://developers.google.com/analytics/devguides/reporting/embed/v1/getting-started\" target=\"_blank\" rel=\"external\">official guide</a> is very helpful. Go through the guide and you’ll make it!</p>\n<p>Mine is like this:</p>\n<p><img src=\"hexo-5.png\" alt=\"diplay-google-analytics\"></p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Hexo"],"tags":["Blog"]},{"title":"Build blogs with Hexo!","url":"/2017/01/Build-blogs-with-Hexo/","content":"<p>Welcome to my blog! In this my very first post, I will record my experience of building this blog with the help of <a href=\"https://pages.github.com/\" target=\"_blank\" rel=\"external\">Github Pages</a> and the amazing <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This not only keeps a record of what I did, but also may help those who want to build a personal blog site. Ok, let’s get down to the business. </p>\n<h2 id=\"Prerequisite\"><a href=\"#Prerequisite\" class=\"headerlink\" title=\"Prerequisite\"></a>Prerequisite</h2><ul>\n<li>Node.js</li>\n<li>Git</li>\n</ul>\n<p>Node.js and Git should be installed properly on your machine.<br>If not, download <a href=\"https://nodejs.org/en/download/\" target=\"_blank\" rel=\"external\">Node.js</a> and <a href=\"https://git-scm.com/downloads\" target=\"_blank\" rel=\"external\">Git</a>, then choose the version you want.</p>\n<h2 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ npm install -g hexo-cli</div></pre></td></tr></table></figure>\n<h2 id=\"Set-up-Hexo\"><a href=\"#Set-up-Hexo\" class=\"headerlink\" title=\"Set up Hexo\"></a>Set up Hexo</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo init [your-site-directory]</div><div class=\"line\">$ <span class=\"built_in\">cd</span> [your-site-directory]</div><div class=\"line\">$ npm install</div></pre></td></tr></table></figure>\n<p>If [your-site-directory] is not specified, hexo will create the project in the current working directory.</p>\n<h2 id=\"Create-a-post\"><a href=\"#Create-a-post\" class=\"headerlink\" title=\"Create a post\"></a>Create a post</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo new post [your-post-title]</div></pre></td></tr></table></figure>\n<p>Will find a new post is created in /source/_posts</p>\n<p>All posts created by hexo is written in Markdown. You can edit in favorite editor or I recommend to use this online editor – <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n<h2 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>This will create a /public folder in the root of your project, and it contains all static html, css, js, fonts, images, etc. </p>\n<h2 id=\"Run-hexo-server-locally\"><a href=\"#Run-hexo-server-locally\" class=\"headerlink\" title=\"Run hexo server locally\"></a>Run hexo server locally</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>The server will be running in <a href=\"http://localhost:4000/\" target=\"_blank\" rel=\"external\">http://localhost:4000/</a> And this offers a convenient way for you to view what you have changed with the look of your website.</p>\n<h2 id=\"From-offline-to-online\"><a href=\"#From-offline-to-online\" class=\"headerlink\" title=\"From offline to online\"></a>From offline to online</h2><p>Hexo provides many ways to deploy the website to your real server. I choose to deploy to Github Pages.</p>\n<h4 id=\"Create-a-github-repository\"><a href=\"#Create-a-github-repository\" class=\"headerlink\" title=\"Create a github repository\"></a>Create a github repository</h4><p>Go to github and create a repository named: <code>[your-github-username]-github.io</code>, mine is <code>xiangxianzui.github.io</code>.</p>\n<p>Go to <em>settings</em> of created repository, pull down the page and you find:</p>\n<p><img src=\"hexo-1.png\" alt=\"GitHub Page Setting\"> </p>\n<p>Next, deploy a SSH key to this repository. This <a href=\"https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/\" target=\"_blank\" rel=\"external\">article</a> is helpful.</p>\n<h4 id=\"Git-deploy-strategy-for-Hexo\"><a href=\"#Git-deploy-strategy-for-Hexo\" class=\"headerlink\" title=\"Git deploy strategy for Hexo\"></a>Git deploy strategy for Hexo</h4><p>Install the official git deploy strategy for hexo.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ npm install hexo-deployer-git --save</div></pre></td></tr></table></figure>\n<p>After that, edit deploy config in your <em>_config.yml</em> (located in project root).</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">deploy:</div><div class=\"line\">  <span class=\"built_in\">type</span>: git</div><div class=\"line\">  repo: [your-ssh-repo]</div><div class=\"line\">  branch: master</div><div class=\"line\">  message: <span class=\"string\">\"Site updated: &#123;&#123; now('YYYY-MM-DD HH:mm:ss') &#125;&#125;\"</span></div></pre></td></tr></table></figure>\n<p>Then, deploy website to git repository</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p><strong>Note</strong>: If you are using Windows, it is recommended to run deploy command in Git Bash.</p>\n<h4 id=\"Take-off\"><a href=\"#Take-off\" class=\"headerlink\" title=\"Take off!\"></a>Take off!</h4><p>Browse <a href=\"https://[your-github-username].github.io/\" target=\"_blank\" rel=\"external\">https://[your-github-username].github.io/</a> and enjoy your flight with Hexo!</p>\n<hr>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\" target=\"_blank\" rel=\"external\">StackEdit</a>.</p>\n</blockquote>\n","categories":["Hexo"],"tags":["Blog"]}]